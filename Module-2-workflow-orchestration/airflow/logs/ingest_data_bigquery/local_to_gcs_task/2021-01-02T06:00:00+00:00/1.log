[2024-03-29 07:24:38,163] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:38,266] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:38,266] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:38,266] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:24:38,266] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:38,557] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-01-02 06:00:00+00:00
[2024-03-29 07:24:38,602] {standard_task_runner.py:52} INFO - Started process 566 to run task
[2024-03-29 07:24:38,659] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-01-02T06:00:00+00:00', '--job-id', '1453', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpbgn557fu', '--error-file', '/tmp/tmppic1bkhi']
[2024-03-29 07:24:38,694] {standard_task_runner.py:77} INFO - Job 1453: Subtask local_to_gcs_task
[2024-03-29 07:24:39,085] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:24:39,945] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:24:40,071] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-01-02T06:00:00+00:00
[2024-03-29 07:24:40,918] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-01.parquet uploaded to yellowtaxi_tripdata/2021-01.parquet.
[2024-03-29 07:24:40,919] {python.py:175} INFO - Done. Returned value was: None
[2024-03-29 07:24:40,966] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210102T060000, start_date=20240329T072438, end_date=20240329T072440
[2024-03-29 07:24:41,144] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:24:41,260] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:30:49,390] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-29 07:30:49,420] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-29 07:30:49,421] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:30:49,421] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:30:49,421] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:30:49,442] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-01-02 06:00:00+00:00
[2024-03-29 07:30:49,451] {standard_task_runner.py:52} INFO - Started process 1045 to run task
[2024-03-29 07:30:49,467] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-01-02T06:00:00+00:00', '--job-id', '1514', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpllkn0zy0', '--error-file', '/tmp/tmpa3l71m1s']
[2024-03-29 07:30:49,473] {standard_task_runner.py:77} INFO - Job 1514: Subtask local_to_gcs_task
[2024-03-29 07:30:49,586] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:30:49,672] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:30:49,711] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-01-02T06:00:00+00:00
[2024-03-29 07:30:50,199] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-01.parquet uploaded to yellowtaxi_tripdata/2021-01.parquet.
[2024-03-29 07:30:50,199] {python.py:175} INFO - Done. Returned value was: None
[2024-03-29 07:30:50,406] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210102T060000, start_date=20240329T073049, end_date=20240329T073050
[2024-03-29 07:30:50,459] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:30:50,537] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:37:34,831] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:34,878] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:34,878] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:34,878] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:37:34,878] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:34,901] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-01-02 06:00:00+00:00
[2024-03-29 07:37:34,914] {standard_task_runner.py:52} INFO - Started process 1571 to run task
[2024-03-29 07:37:34,935] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-01-02T06:00:00+00:00', '--job-id', '1574', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpdo846105', '--error-file', '/tmp/tmp44c17mum']
[2024-03-29 07:37:34,943] {standard_task_runner.py:77} INFO - Job 1574: Subtask local_to_gcs_task
[2024-03-29 07:37:35,119] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:37:35,235] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:37:35,301] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-01-02T06:00:00+00:00
[2024-03-29 07:37:36,181] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-01.parquet uploaded to yellowtaxi_tripdata/2021-01.parquet.
[2024-03-29 07:37:36,181] {python.py:175} INFO - Done. Returned value was: None
[2024-03-29 07:37:36,363] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210102T060000, start_date=20240329T073734, end_date=20240329T073736
[2024-03-29 07:37:36,486] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:37:36,580] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:08:41,087] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:41,128] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:41,133] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:41,134] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:08:41,134] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:41,187] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-01-02 06:00:00+00:00
[2024-03-29 08:08:41,204] {standard_task_runner.py:52} INFO - Started process 281 to run task
[2024-03-29 08:08:41,214] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-01-02T06:00:00+00:00', '--job-id', '1639', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpw7fz_gfi', '--error-file', '/tmp/tmp_6nnv4mj']
[2024-03-29 08:08:41,237] {standard_task_runner.py:77} INFO - Job 1639: Subtask local_to_gcs_task
[2024-03-29 08:08:41,368] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:08:41,442] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:08:41,569] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-01-02T06:00:00+00:00
[2024-03-29 08:08:42,583] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-01.parquet uploaded to yellowtaxi_tripdata/{TABLE_NAME_TEMPLATE}.parquet.
[2024-03-29 08:08:42,583] {python.py:175} INFO - Done. Returned value was: None
[2024-03-29 08:08:42,619] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210102T060000, start_date=20240329T080841, end_date=20240329T080842
[2024-03-29 08:08:42,703] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:08:42,833] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:11:01,109] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-29 08:11:01,184] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-29 08:11:01,185] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:11:01,185] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:11:01,185] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:11:01,298] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-01-02 06:00:00+00:00
[2024-03-29 08:11:01,326] {standard_task_runner.py:52} INFO - Started process 538 to run task
[2024-03-29 08:11:01,356] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-01-02T06:00:00+00:00', '--job-id', '1685', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpwb6n3h94', '--error-file', '/tmp/tmp366p58cw']
[2024-03-29 08:11:01,380] {standard_task_runner.py:77} INFO - Job 1685: Subtask local_to_gcs_task
[2024-03-29 08:11:01,580] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:11:01,707] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:11:01,766] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-01-02T06:00:00+00:00
[2024-03-29 08:11:02,441] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-01.parquet uploaded to yellowtaxi_tripdata/yellow_taxi_2021_01.parquet.
[2024-03-29 08:11:02,442] {python.py:175} INFO - Done. Returned value was: None
[2024-03-29 08:11:02,478] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210102T060000, start_date=20240329T081101, end_date=20240329T081102
[2024-03-29 08:11:02,613] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:11:02,688] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:30:11,360] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:11,387] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:11,388] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:11,388] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:30:11,388] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:11,408] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-01-02 06:00:00+00:00
[2024-03-30 03:30:11,417] {standard_task_runner.py:52} INFO - Started process 489 to run task
[2024-03-30 03:30:11,424] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-01-02T06:00:00+00:00', '--job-id', '1829', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpb0il46ts', '--error-file', '/tmp/tmpypwr0ra1']
[2024-03-30 03:30:11,430] {standard_task_runner.py:77} INFO - Job 1829: Subtask local_to_gcs_task
[2024-03-30 03:30:11,511] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:30:11,566] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:30:11,603] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-01-02T06:00:00+00:00
[2024-03-30 03:30:12,210] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-01.parquet uploaded to yellowtaxi_tripdata/yellow_taxi_2021_01.parquet.
[2024-03-30 03:30:12,214] {python.py:175} INFO - Done. Returned value was: None
[2024-03-30 03:30:12,255] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210102T060000, start_date=20240330T033011, end_date=20240330T033012
[2024-03-30 03:30:12,375] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:30:12,573] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:42:03,264] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-30 03:42:03,343] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-30 03:42:03,345] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:42:03,349] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:42:03,349] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:42:03,394] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-01-02 06:00:00+00:00
[2024-03-30 03:42:03,425] {standard_task_runner.py:52} INFO - Started process 1324 to run task
[2024-03-30 03:42:03,481] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-01-02T06:00:00+00:00', '--job-id', '1908', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpauo9fx1p', '--error-file', '/tmp/tmp6rady2fu']
[2024-03-30 03:42:03,503] {standard_task_runner.py:77} INFO - Job 1908: Subtask local_to_gcs_task
[2024-03-30 03:42:03,717] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:42:03,920] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:42:04,027] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-01-02T06:00:00+00:00
[2024-03-30 03:42:04,982] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-01.parquet uploaded to yellowtaxi_tripdata/yellow_taxi_2021_01.parquet.
[2024-03-30 03:42:04,982] {python.py:175} INFO - Done. Returned value was: None
[2024-03-30 03:42:05,040] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210102T060000, start_date=20240330T034203, end_date=20240330T034205
[2024-03-30 03:42:05,365] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:42:05,987] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:18:12,054] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:12,106] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:12,107] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:12,107] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:18:12,107] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:12,146] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-01-02 06:00:00+00:00
[2024-03-30 04:18:12,171] {standard_task_runner.py:52} INFO - Started process 3562 to run task
[2024-03-30 04:18:12,199] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-01-02T06:00:00+00:00', '--job-id', '2088', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmptsvvye_b', '--error-file', '/tmp/tmp9hr700cf']
[2024-03-30 04:18:12,236] {standard_task_runner.py:77} INFO - Job 2088: Subtask local_to_gcs_task
[2024-03-30 04:18:12,408] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:18:12,478] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:18:12,527] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-01-02T06:00:00+00:00
[2024-03-30 04:18:13,029] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-01.parquet uploaded to yellowtaxi_tripdata/yellow_taxi_2021_01.parquet.
[2024-03-30 04:18:13,029] {python.py:175} INFO - Done. Returned value was: None
[2024-03-30 04:18:13,061] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210102T060000, start_date=20240330T041812, end_date=20240330T041813
[2024-03-30 04:18:13,174] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:18:13,301] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:24:48,571] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-30 04:24:48,651] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-30 04:24:48,651] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:24:48,652] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:24:48,654] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:24:48,733] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-01-02 06:00:00+00:00
[2024-03-30 04:24:48,758] {standard_task_runner.py:52} INFO - Started process 4194 to run task
[2024-03-30 04:24:48,809] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-01-02T06:00:00+00:00', '--job-id', '2169', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpdkgyuk5e', '--error-file', '/tmp/tmpz5yl3861']
[2024-03-30 04:24:48,834] {standard_task_runner.py:77} INFO - Job 2169: Subtask local_to_gcs_task
[2024-03-30 04:24:49,078] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:24:49,225] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:24:49,335] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-01-02T06:00:00+00:00
[2024-03-30 04:24:50,137] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-01.parquet uploaded to yellowtaxi_tripdata/yellow_taxi_2021_01.parquet.
[2024-03-30 04:24:50,138] {python.py:175} INFO - Done. Returned value was: None
[2024-03-30 04:24:50,198] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210102T060000, start_date=20240330T042448, end_date=20240330T042450
[2024-03-30 04:24:50,319] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:24:50,543] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:38:56,388] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-30 04:38:56,608] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-30 04:38:56,609] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:38:56,609] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:38:56,609] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:38:56,814] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-01-02 06:00:00+00:00
[2024-03-30 04:38:56,957] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-01-02T06:00:00+00:00', '--job-id', '2286', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmplv_rx8ic', '--error-file', '/tmp/tmpne4i0w13']
[2024-03-30 04:38:57,031] {standard_task_runner.py:77} INFO - Job 2286: Subtask local_to_gcs_task
[2024-03-30 04:38:56,900] {standard_task_runner.py:52} INFO - Started process 5268 to run task
[2024-03-30 04:38:57,616] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:38:57,705] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:38:57,834] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-01-02T06:00:00+00:00
[2024-03-30 04:38:59,557] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-01.parquet uploaded to yellowtaxi_tripdata/yellow_taxi_2021_01.parquet.
[2024-03-30 04:38:59,557] {python.py:175} INFO - Done. Returned value was: None
[2024-03-30 04:38:59,764] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210102T060000, start_date=20240330T043856, end_date=20240330T043859
[2024-03-30 04:38:59,857] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:39:00,287] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:59:30,863] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:30,884] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:30,885] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:30,885] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:59:30,885] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:30,908] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-01-02 06:00:00+00:00
[2024-03-30 04:59:30,933] {standard_task_runner.py:52} INFO - Started process 6653 to run task
[2024-03-30 04:59:30,971] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-01-02T06:00:00+00:00', '--job-id', '2415', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpjtejh9h2', '--error-file', '/tmp/tmphtqh3_vi']
[2024-03-30 04:59:30,979] {standard_task_runner.py:77} INFO - Job 2415: Subtask local_to_gcs_task
[2024-03-30 04:59:31,160] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:59:31,416] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:59:31,503] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-01-02T06:00:00+00:00
[2024-03-30 04:59:32,276] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-01.parquet uploaded to yellowtaxi_tripdata/yellow_taxi_2021_01.parquet.
[2024-03-30 04:59:32,276] {python.py:175} INFO - Done. Returned value was: None
[2024-03-30 04:59:32,400] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210102T060000, start_date=20240330T045930, end_date=20240330T045932
[2024-03-30 04:59:32,537] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:59:32,689] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:01:35,232] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:35,270] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:35,271] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:35,271] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:01:35,271] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:35,301] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-01-02 06:00:00+00:00
[2024-03-30 09:01:35,316] {standard_task_runner.py:52} INFO - Started process 18160 to run task
[2024-03-30 09:01:35,333] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-01-02T06:00:00+00:00', '--job-id', '2530', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpl8vum7ca', '--error-file', '/tmp/tmp6ni47v6z']
[2024-03-30 09:01:35,358] {standard_task_runner.py:77} INFO - Job 2530: Subtask local_to_gcs_task
[2024-03-30 09:01:35,558] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:01:35,709] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:01:35,773] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-01-02T06:00:00+00:00
[2024-03-30 09:01:36,393] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-01.parquet uploaded to yellowtaxi_tripdata/yellow_taxi_2021_01.parquet.
[2024-03-30 09:01:36,395] {python.py:175} INFO - Done. Returned value was: None
[2024-03-30 09:01:36,427] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210102T060000, start_date=20240330T090135, end_date=20240330T090136
[2024-03-30 09:01:36,718] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:01:37,030] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:04:07,436] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-30 11:04:07,566] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-30 11:04:07,569] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:04:07,569] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:04:07,571] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:04:07,653] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-01-02 06:00:00+00:00
[2024-03-30 11:04:07,713] {standard_task_runner.py:52} INFO - Started process 24411 to run task
[2024-03-30 11:04:07,768] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-01-02T06:00:00+00:00', '--job-id', '2688', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpfzn3s5a0', '--error-file', '/tmp/tmp3vbf247p']
[2024-03-30 11:04:07,828] {standard_task_runner.py:77} INFO - Job 2688: Subtask local_to_gcs_task
[2024-03-30 11:04:08,348] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:04:08,607] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:04:08,878] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-01-02T06:00:00+00:00
[2024-03-30 11:04:50,924] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 59, in upload_to_gcs
    index=False,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/util/_decorators.py", line 199, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/frame.py", line 2372, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 276, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 101, in write
    table = self.api.Table.from_pandas(df, **from_pandas_kwargs)
  File "pyarrow/table.pxi", line 1561, in pyarrow.lib.Table.from_pandas
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 607, in dataframe_to_arrays
    arrays[i] = maybe_fut.result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 425, in result
    return self.__get_result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.6/concurrent/futures/thread.py", line 56, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 581, in convert_column
    raise e
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 575, in convert_column
    result = pa.array(col, type=type_, from_pandas=True, safe=safe)
  File "pyarrow/array.pxi", line 302, in pyarrow.lib.array
  File "pyarrow/array.pxi", line 83, in pyarrow.lib._ndarray_to_array
  File "pyarrow/error.pxi", line 122, in pyarrow.lib.check_status
pyarrow.lib.ArrowTypeError: ("Expected bytes, got a 'int' object", 'Conversion failed for column store_and_fwd_flag with type object')
[2024-03-30 11:04:51,775] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210102T060000, start_date=20240330T110407, end_date=20240330T110451
[2024-03-30 11:04:52,102] {standard_task_runner.py:92} ERROR - Failed to execute job 2688 for task local_to_gcs_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 59, in upload_to_gcs
    index=False,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/util/_decorators.py", line 199, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/frame.py", line 2372, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 276, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 101, in write
    table = self.api.Table.from_pandas(df, **from_pandas_kwargs)
  File "pyarrow/table.pxi", line 1561, in pyarrow.lib.Table.from_pandas
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 607, in dataframe_to_arrays
    arrays[i] = maybe_fut.result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 425, in result
    return self.__get_result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.6/concurrent/futures/thread.py", line 56, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 581, in convert_column
    raise e
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 575, in convert_column
    result = pa.array(col, type=type_, from_pandas=True, safe=safe)
  File "pyarrow/array.pxi", line 302, in pyarrow.lib.array
  File "pyarrow/array.pxi", line 83, in pyarrow.lib._ndarray_to_array
  File "pyarrow/error.pxi", line 122, in pyarrow.lib.check_status
pyarrow.lib.ArrowTypeError: ("Expected bytes, got a 'int' object", 'Conversion failed for column store_and_fwd_flag with type object')
[2024-03-30 11:04:52,713] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 11:04:53,017] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:15:12,965] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-30 11:15:13,024] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-30 11:15:13,024] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:15:13,024] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:15:13,024] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:15:13,074] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-01-02 06:00:00+00:00
[2024-03-30 11:15:13,086] {standard_task_runner.py:52} INFO - Started process 25303 to run task
[2024-03-30 11:15:13,147] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-01-02T06:00:00+00:00', '--job-id', '2733', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpuxc9x683', '--error-file', '/tmp/tmpsj6k34fm']
[2024-03-30 11:15:13,169] {standard_task_runner.py:77} INFO - Job 2733: Subtask local_to_gcs_task
[2024-03-30 11:15:13,408] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:15:13,563] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:15:13,685] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-01-02T06:00:00+00:00
[2024-03-30 11:15:23,816] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 65, in upload_to_gcs
    index=False,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/util/_decorators.py", line 199, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/frame.py", line 2372, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 276, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 101, in write
    table = self.api.Table.from_pandas(df, **from_pandas_kwargs)
  File "pyarrow/table.pxi", line 1561, in pyarrow.lib.Table.from_pandas
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 607, in dataframe_to_arrays
    arrays[i] = maybe_fut.result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 425, in result
    return self.__get_result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.6/concurrent/futures/thread.py", line 56, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 581, in convert_column
    raise e
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 575, in convert_column
    result = pa.array(col, type=type_, from_pandas=True, safe=safe)
  File "pyarrow/array.pxi", line 302, in pyarrow.lib.array
  File "pyarrow/array.pxi", line 83, in pyarrow.lib._ndarray_to_array
  File "pyarrow/error.pxi", line 122, in pyarrow.lib.check_status
pyarrow.lib.ArrowTypeError: ("Expected bytes, got a 'int' object", 'Conversion failed for column store_and_fwd_flag with type object')
[2024-03-30 11:15:23,869] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210102T060000, start_date=20240330T111512, end_date=20240330T111523
[2024-03-30 11:15:23,894] {standard_task_runner.py:92} ERROR - Failed to execute job 2733 for task local_to_gcs_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 65, in upload_to_gcs
    index=False,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/util/_decorators.py", line 199, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/frame.py", line 2372, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 276, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 101, in write
    table = self.api.Table.from_pandas(df, **from_pandas_kwargs)
  File "pyarrow/table.pxi", line 1561, in pyarrow.lib.Table.from_pandas
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 607, in dataframe_to_arrays
    arrays[i] = maybe_fut.result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 425, in result
    return self.__get_result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.6/concurrent/futures/thread.py", line 56, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 581, in convert_column
    raise e
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 575, in convert_column
    result = pa.array(col, type=type_, from_pandas=True, safe=safe)
  File "pyarrow/array.pxi", line 302, in pyarrow.lib.array
  File "pyarrow/array.pxi", line 83, in pyarrow.lib._ndarray_to_array
  File "pyarrow/error.pxi", line 122, in pyarrow.lib.check_status
pyarrow.lib.ArrowTypeError: ("Expected bytes, got a 'int' object", 'Conversion failed for column store_and_fwd_flag with type object')
[2024-03-30 11:15:23,977] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 11:15:24,109] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:33:56,001] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-30 11:33:56,042] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-03-30 11:33:56,043] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:33:56,044] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:33:56,046] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:33:56,081] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-01-02 06:00:00+00:00
[2024-03-30 11:33:56,091] {standard_task_runner.py:52} INFO - Started process 26874 to run task
[2024-03-30 11:33:56,115] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-01-02T06:00:00+00:00', '--job-id', '2811', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp0pnxu4w9', '--error-file', '/tmp/tmp7nxnsaj0']
[2024-03-30 11:33:56,125] {standard_task_runner.py:77} INFO - Job 2811: Subtask local_to_gcs_task
[2024-03-30 11:33:56,309] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:33:56,400] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:33:56,461] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-01-02T06:00:00+00:00
[2024-03-30 11:34:00,716] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 68, in upload_to_gcs
    df.to_parquet(clean_file_name, index=False)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/util/_decorators.py", line 199, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/frame.py", line 2372, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 276, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 101, in write
    table = self.api.Table.from_pandas(df, **from_pandas_kwargs)
  File "pyarrow/table.pxi", line 1561, in pyarrow.lib.Table.from_pandas
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 607, in dataframe_to_arrays
    arrays[i] = maybe_fut.result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 425, in result
    return self.__get_result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.6/concurrent/futures/thread.py", line 56, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 581, in convert_column
    raise e
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 575, in convert_column
    result = pa.array(col, type=type_, from_pandas=True, safe=safe)
  File "pyarrow/array.pxi", line 302, in pyarrow.lib.array
  File "pyarrow/array.pxi", line 83, in pyarrow.lib._ndarray_to_array
  File "pyarrow/error.pxi", line 122, in pyarrow.lib.check_status
pyarrow.lib.ArrowTypeError: ("Expected bytes, got a 'int' object", 'Conversion failed for column store_and_fwd_flag with type object')
[2024-03-30 11:34:00,840] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210102T060000, start_date=20240330T113356, end_date=20240330T113400
[2024-03-30 11:34:01,112] {standard_task_runner.py:92} ERROR - Failed to execute job 2811 for task local_to_gcs_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 68, in upload_to_gcs
    df.to_parquet(clean_file_name, index=False)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/util/_decorators.py", line 199, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/frame.py", line 2372, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 276, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 101, in write
    table = self.api.Table.from_pandas(df, **from_pandas_kwargs)
  File "pyarrow/table.pxi", line 1561, in pyarrow.lib.Table.from_pandas
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 607, in dataframe_to_arrays
    arrays[i] = maybe_fut.result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 425, in result
    return self.__get_result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.6/concurrent/futures/thread.py", line 56, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 581, in convert_column
    raise e
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 575, in convert_column
    result = pa.array(col, type=type_, from_pandas=True, safe=safe)
  File "pyarrow/array.pxi", line 302, in pyarrow.lib.array
  File "pyarrow/array.pxi", line 83, in pyarrow.lib._ndarray_to_array
  File "pyarrow/error.pxi", line 122, in pyarrow.lib.check_status
pyarrow.lib.ArrowTypeError: ("Expected bytes, got a 'int' object", 'Conversion failed for column store_and_fwd_flag with type object')
[2024-03-30 11:34:01,383] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 11:34:01,627] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-04-28 09:15:37,799] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:37,823] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:37,823] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:37,823] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-28 09:15:37,823] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:38,266] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-01-02 06:00:00+00:00
[2024-04-28 09:15:38,420] {standard_task_runner.py:52} INFO - Started process 1453 to run task
[2024-04-28 09:15:38,455] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-01-02T06:00:00+00:00', '--job-id', '3005', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp_nmyapds', '--error-file', '/tmp/tmpipjg9cny']
[2024-04-28 09:15:38,489] {standard_task_runner.py:77} INFO - Job 3005: Subtask local_to_gcs_task
[2024-04-28 09:15:39,303] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [running]> on host 6c6a4ca9ff8e
[2024-04-28 09:15:39,503] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-28 09:15:39,707] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-01-02T06:00:00+00:00
[2024-04-28 09:15:47,971] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 68, in upload_to_gcs
    df.to_parquet(clean_file_name, index=False)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/util/_decorators.py", line 199, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/frame.py", line 2372, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 276, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 101, in write
    table = self.api.Table.from_pandas(df, **from_pandas_kwargs)
  File "pyarrow/table.pxi", line 1561, in pyarrow.lib.Table.from_pandas
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 607, in dataframe_to_arrays
    arrays[i] = maybe_fut.result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 425, in result
    return self.__get_result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.6/concurrent/futures/thread.py", line 56, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 581, in convert_column
    raise e
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 575, in convert_column
    result = pa.array(col, type=type_, from_pandas=True, safe=safe)
  File "pyarrow/array.pxi", line 302, in pyarrow.lib.array
  File "pyarrow/array.pxi", line 83, in pyarrow.lib._ndarray_to_array
  File "pyarrow/error.pxi", line 122, in pyarrow.lib.check_status
pyarrow.lib.ArrowTypeError: ("Expected bytes, got a 'int' object", 'Conversion failed for column store_and_fwd_flag with type object')
[2024-04-28 09:15:48,036] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210102T060000, start_date=20240428T091537, end_date=20240428T091548
[2024-04-28 09:15:48,132] {standard_task_runner.py:92} ERROR - Failed to execute job 3005 for task local_to_gcs_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 68, in upload_to_gcs
    df.to_parquet(clean_file_name, index=False)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/util/_decorators.py", line 199, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/frame.py", line 2372, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 276, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 101, in write
    table = self.api.Table.from_pandas(df, **from_pandas_kwargs)
  File "pyarrow/table.pxi", line 1561, in pyarrow.lib.Table.from_pandas
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 607, in dataframe_to_arrays
    arrays[i] = maybe_fut.result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 425, in result
    return self.__get_result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.6/concurrent/futures/thread.py", line 56, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 581, in convert_column
    raise e
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 575, in convert_column
    result = pa.array(col, type=type_, from_pandas=True, safe=safe)
  File "pyarrow/array.pxi", line 302, in pyarrow.lib.array
  File "pyarrow/array.pxi", line 83, in pyarrow.lib._ndarray_to_array
  File "pyarrow/error.pxi", line 122, in pyarrow.lib.check_status
pyarrow.lib.ArrowTypeError: ("Expected bytes, got a 'int' object", 'Conversion failed for column store_and_fwd_flag with type object')
[2024-04-28 09:15:48,407] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-04-28 09:15:48,590] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:14:02,300] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-04-30 02:14:02,397] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-04-30 02:14:02,404] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:14:02,406] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-30 02:14:02,410] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:14:02,485] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-01-02 06:00:00+00:00
[2024-04-30 02:14:02,525] {standard_task_runner.py:52} INFO - Started process 421 to run task
[2024-04-30 02:14:02,582] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-01-02T06:00:00+00:00', '--job-id', '3045', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpik2snjdt', '--error-file', '/tmp/tmpe1dum9fe']
[2024-04-30 02:14:02,640] {standard_task_runner.py:77} INFO - Job 3045: Subtask local_to_gcs_task
[2024-04-30 02:14:03,174] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [running]> on host a1ae6a0259c5
[2024-04-30 02:14:03,779] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:14:04,129] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-01-02T06:00:00+00:00
[2024-04-30 02:14:46,048] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 75, in upload_to_gcs
    __clean_file(raw_file_name, clean_file_name)
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 61, in __clean_file
    df.to_parquet(clean_file_name, index=False)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/util/_decorators.py", line 199, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/frame.py", line 2372, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 276, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 101, in write
    table = self.api.Table.from_pandas(df, **from_pandas_kwargs)
  File "pyarrow/table.pxi", line 1561, in pyarrow.lib.Table.from_pandas
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 607, in dataframe_to_arrays
    arrays[i] = maybe_fut.result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 425, in result
    return self.__get_result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.6/concurrent/futures/thread.py", line 56, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 581, in convert_column
    raise e
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 575, in convert_column
    result = pa.array(col, type=type_, from_pandas=True, safe=safe)
  File "pyarrow/array.pxi", line 302, in pyarrow.lib.array
  File "pyarrow/array.pxi", line 83, in pyarrow.lib._ndarray_to_array
  File "pyarrow/error.pxi", line 122, in pyarrow.lib.check_status
pyarrow.lib.ArrowTypeError: ("Expected bytes, got a 'int' object", 'Conversion failed for column store_and_fwd_flag with type object')
[2024-04-30 02:14:53,055] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210102T060000, start_date=20240430T021402, end_date=20240430T021453
[2024-04-30 02:14:53,387] {standard_task_runner.py:92} ERROR - Failed to execute job 3045 for task local_to_gcs_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 75, in upload_to_gcs
    __clean_file(raw_file_name, clean_file_name)
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 61, in __clean_file
    df.to_parquet(clean_file_name, index=False)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/util/_decorators.py", line 199, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/frame.py", line 2372, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 276, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 101, in write
    table = self.api.Table.from_pandas(df, **from_pandas_kwargs)
  File "pyarrow/table.pxi", line 1561, in pyarrow.lib.Table.from_pandas
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 607, in dataframe_to_arrays
    arrays[i] = maybe_fut.result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 425, in result
    return self.__get_result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.6/concurrent/futures/thread.py", line 56, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 581, in convert_column
    raise e
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 575, in convert_column
    result = pa.array(col, type=type_, from_pandas=True, safe=safe)
  File "pyarrow/array.pxi", line 302, in pyarrow.lib.array
  File "pyarrow/array.pxi", line 83, in pyarrow.lib._ndarray_to_array
  File "pyarrow/error.pxi", line 122, in pyarrow.lib.check_status
pyarrow.lib.ArrowTypeError: ("Expected bytes, got a 'int' object", 'Conversion failed for column store_and_fwd_flag with type object')
[2024-04-30 02:14:53,843] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-04-30 02:14:54,200] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:58:21,353] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:21,482] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:21,486] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:21,486] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 02:58:21,487] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:21,626] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-01-02 06:00:00+00:00
[2024-04-30 02:58:21,728] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-01-02T06:00:00+00:00', '--job-id', '3107', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpt_7kbqk9', '--error-file', '/tmp/tmpu4hoxdso']
[2024-04-30 02:58:21,774] {standard_task_runner.py:77} INFO - Job 3107: Subtask local_to_gcs_task
[2024-04-30 02:58:21,710] {standard_task_runner.py:52} INFO - Started process 454 to run task
[2024-04-30 02:58:22,088] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 02:58:22,188] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:58:22,292] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-01-02T06:00:00+00:00
[2024-04-30 02:58:22,369] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 92, in upload_to_gcs
    blob.upload_from_filename(clean_file_name)
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/storage/blob.py", line 2720, in upload_from_filename
    with open(filename, "rb") as file_obj:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/cleaned_data/yellowtaxi_tripdata_2021-01.parquet'
[2024-04-30 02:58:22,423] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210102T060000, start_date=20240430T025821, end_date=20240430T025822
[2024-04-30 02:58:22,808] {standard_task_runner.py:92} ERROR - Failed to execute job 3107 for task local_to_gcs_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 92, in upload_to_gcs
    blob.upload_from_filename(clean_file_name)
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/storage/blob.py", line 2720, in upload_from_filename
    with open(filename, "rb") as file_obj:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/cleaned_data/yellowtaxi_tripdata_2021-01.parquet'
[2024-04-30 02:58:22,853] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-04-30 02:58:23,006] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:01:11,242] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:11,375] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:11,375] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:11,386] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:01:11,387] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:11,445] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-01-02 06:00:00+00:00
[2024-04-30 03:01:11,474] {standard_task_runner.py:52} INFO - Started process 705 to run task
[2024-04-30 03:01:11,513] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-01-02T06:00:00+00:00', '--job-id', '3139', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpuordaaau', '--error-file', '/tmp/tmp0v1it36j']
[2024-04-30 03:01:11,539] {standard_task_runner.py:77} INFO - Job 3139: Subtask local_to_gcs_task
[2024-04-30 03:01:11,912] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:01:12,171] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:01:12,336] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-01-02T06:00:00+00:00
[2024-04-30 03:01:13,777] {python.py:175} INFO - Done. Returned value was: None
[2024-04-30 03:01:13,980] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210102T060000, start_date=20240430T030111, end_date=20240430T030113
[2024-04-30 03:01:14,123] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:01:14,248] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:30:07,303] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-04-30 04:30:07,341] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [queued]>
[2024-04-30 04:30:07,341] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:30:07,341] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:30:07,341] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:30:07,368] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-01-02 06:00:00+00:00
[2024-04-30 04:30:07,380] {standard_task_runner.py:52} INFO - Started process 5242 to run task
[2024-04-30 04:30:07,402] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-01-02T06:00:00+00:00', '--job-id', '3254', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpb3yh0fd9', '--error-file', '/tmp/tmp16r4h9mi']
[2024-04-30 04:30:07,413] {standard_task_runner.py:77} INFO - Job 3254: Subtask local_to_gcs_task
[2024-04-30 04:30:07,553] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-01-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:30:07,683] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:30:07,841] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-01-02T06:00:00+00:00
[2024-04-30 04:30:46,910] {python.py:175} INFO - Done. Returned value was: None
[2024-04-30 04:30:57,069] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210102T060000, start_date=20240430T043007, end_date=20240430T043057
[2024-04-30 04:30:57,541] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 04:30:59,023] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
