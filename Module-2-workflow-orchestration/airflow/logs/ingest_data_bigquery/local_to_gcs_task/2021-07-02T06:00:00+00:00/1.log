[2024-03-29 07:24:41,673] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:41,797] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:41,808] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:41,809] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:24:41,809] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:41,900] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-07-02 06:00:00+00:00
[2024-03-29 07:24:41,935] {standard_task_runner.py:52} INFO - Started process 579 to run task
[2024-03-29 07:24:41,972] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '1455', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp6bml6k5u', '--error-file', '/tmp/tmp0o616u8e']
[2024-03-29 07:24:42,022] {standard_task_runner.py:77} INFO - Job 1455: Subtask local_to_gcs_task
[2024-03-29 07:24:42,431] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:24:42,715] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:24:42,821] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-29 07:24:44,759] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-07.parquet uploaded to yellowtaxi_tripdata/2021-07.parquet.
[2024-03-29 07:24:44,759] {python.py:175} INFO - Done. Returned value was: None
[2024-03-29 07:24:44,801] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210702T060000, start_date=20240329T072441, end_date=20240329T072444
[2024-03-29 07:24:45,037] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:24:45,365] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:31:00,998] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-29 07:31:01,167] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-29 07:31:01,167] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:31:01,167] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:31:01,167] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:31:01,285] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-07-02 06:00:00+00:00
[2024-03-29 07:31:01,411] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '1522', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp21l22av2', '--error-file', '/tmp/tmpajusgnod']
[2024-03-29 07:31:01,437] {standard_task_runner.py:77} INFO - Job 1522: Subtask local_to_gcs_task
[2024-03-29 07:31:01,353] {standard_task_runner.py:52} INFO - Started process 1088 to run task
[2024-03-29 07:31:01,807] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:31:02,027] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:31:02,119] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-29 07:31:03,098] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-07.parquet uploaded to yellowtaxi_tripdata/2021-07.parquet.
[2024-03-29 07:31:03,098] {python.py:175} INFO - Done. Returned value was: None
[2024-03-29 07:31:03,149] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210702T060000, start_date=20240329T073101, end_date=20240329T073103
[2024-03-29 07:31:03,338] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:31:03,480] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:37:42,032] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:42,109] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:42,109] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:42,109] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:37:42,109] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:42,273] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-07-02 06:00:00+00:00
[2024-03-29 07:37:42,358] {standard_task_runner.py:52} INFO - Started process 1606 to run task
[2024-03-29 07:37:42,452] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '1582', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp3_23mb_m', '--error-file', '/tmp/tmpvtjbewsj']
[2024-03-29 07:37:42,505] {standard_task_runner.py:77} INFO - Job 1582: Subtask local_to_gcs_task
[2024-03-29 07:37:42,860] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:37:43,218] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:37:43,466] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-29 07:37:45,197] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-07.parquet uploaded to yellowtaxi_tripdata/2021-07.parquet.
[2024-03-29 07:37:45,216] {python.py:175} INFO - Done. Returned value was: None
[2024-03-29 07:37:45,435] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210702T060000, start_date=20240329T073742, end_date=20240329T073745
[2024-03-29 07:37:45,569] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:37:45,728] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:08:45,933] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:45,986] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:45,986] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:45,987] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:08:45,987] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:46,128] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-07-02 06:00:00+00:00
[2024-03-29 08:08:46,224] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '1647', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpw5yf249f', '--error-file', '/tmp/tmpfi6anbqe']
[2024-03-29 08:08:46,266] {standard_task_runner.py:77} INFO - Job 1647: Subtask local_to_gcs_task
[2024-03-29 08:08:46,171] {standard_task_runner.py:52} INFO - Started process 301 to run task
[2024-03-29 08:08:47,080] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:08:47,520] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:08:47,708] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-29 08:08:48,977] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-07.parquet uploaded to yellowtaxi_tripdata/{TABLE_NAME_TEMPLATE}.parquet.
[2024-03-29 08:08:48,977] {python.py:175} INFO - Done. Returned value was: None
[2024-03-29 08:08:49,055] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210702T060000, start_date=20240329T080845, end_date=20240329T080849
[2024-03-29 08:08:49,157] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:08:49,422] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:11:16,957] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-29 08:11:17,012] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-29 08:11:17,015] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:11:17,016] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:11:17,017] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:11:17,058] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-07-02 06:00:00+00:00
[2024-03-29 08:11:17,067] {standard_task_runner.py:52} INFO - Started process 592 to run task
[2024-03-29 08:11:17,082] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '1692', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp4djy_8c5', '--error-file', '/tmp/tmp4z57v5n1']
[2024-03-29 08:11:17,107] {standard_task_runner.py:77} INFO - Job 1692: Subtask local_to_gcs_task
[2024-03-29 08:11:17,501] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:11:17,804] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:11:18,000] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-29 08:11:19,068] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-07.parquet uploaded to yellowtaxi_tripdata/yellow_taxi_2021_07.parquet.
[2024-03-29 08:11:19,069] {python.py:175} INFO - Done. Returned value was: None
[2024-03-29 08:11:19,143] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210702T060000, start_date=20240329T081116, end_date=20240329T081119
[2024-03-29 08:11:19,228] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:11:19,412] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:30:21,388] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:21,485] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:21,485] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:21,485] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:30:21,485] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:21,610] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-07-02 06:00:00+00:00
[2024-03-30 03:30:21,724] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '1839', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpz3tirh6s', '--error-file', '/tmp/tmpqreppzao']
[2024-03-30 03:30:21,800] {standard_task_runner.py:77} INFO - Job 1839: Subtask local_to_gcs_task
[2024-03-30 03:30:21,712] {standard_task_runner.py:52} INFO - Started process 539 to run task
[2024-03-30 03:30:22,130] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:30:22,409] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:30:22,575] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-30 03:30:24,833] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-07.parquet uploaded to yellowtaxi_tripdata/yellow_taxi_2021_07.parquet.
[2024-03-30 03:30:24,833] {python.py:175} INFO - Done. Returned value was: None
[2024-03-30 03:30:24,885] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210702T060000, start_date=20240330T033021, end_date=20240330T033024
[2024-03-30 03:30:25,085] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:30:25,324] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:42:11,635] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 03:42:11,787] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 03:42:11,787] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:42:11,787] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:42:11,788] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:42:11,922] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-07-02 06:00:00+00:00
[2024-03-30 03:42:12,015] {standard_task_runner.py:52} INFO - Started process 1354 to run task
[2024-03-30 03:42:12,032] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '1914', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp2nx7fdtq', '--error-file', '/tmp/tmp0tqz_rs2']
[2024-03-30 03:42:12,056] {standard_task_runner.py:77} INFO - Job 1914: Subtask local_to_gcs_task
[2024-03-30 03:42:12,347] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:42:12,531] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:42:12,648] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-30 03:42:14,056] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-07.parquet uploaded to yellowtaxi_tripdata/yellow_taxi_2021_07.parquet.
[2024-03-30 03:42:14,057] {python.py:175} INFO - Done. Returned value was: None
[2024-03-30 03:42:14,101] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210702T060000, start_date=20240330T034211, end_date=20240330T034214
[2024-03-30 03:42:14,372] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:42:14,550] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:18:17,939] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:17,994] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:17,994] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:17,995] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:18:17,995] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:18,086] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-07-02 06:00:00+00:00
[2024-03-30 04:18:18,107] {standard_task_runner.py:52} INFO - Started process 3585 to run task
[2024-03-30 04:18:18,145] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '2094', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpybd_3ofe', '--error-file', '/tmp/tmpf8kwg25j']
[2024-03-30 04:18:18,205] {standard_task_runner.py:77} INFO - Job 2094: Subtask local_to_gcs_task
[2024-03-30 04:18:18,547] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:18:18,761] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:18:18,965] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-30 04:18:20,553] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-07.parquet uploaded to yellowtaxi_tripdata/yellow_taxi_2021_07.parquet.
[2024-03-30 04:18:20,553] {python.py:175} INFO - Done. Returned value was: None
[2024-03-30 04:18:20,648] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210702T060000, start_date=20240330T041817, end_date=20240330T041820
[2024-03-30 04:18:20,875] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:18:21,207] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:25:01,309] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:25:01,419] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:25:01,422] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:25:01,430] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:25:01,431] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:25:01,555] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-07-02 06:00:00+00:00
[2024-03-30 04:25:01,602] {standard_task_runner.py:52} INFO - Started process 4253 to run task
[2024-03-30 04:25:01,640] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '2183', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpiqktex8b', '--error-file', '/tmp/tmpjuwxc3zj']
[2024-03-30 04:25:01,694] {standard_task_runner.py:77} INFO - Job 2183: Subtask local_to_gcs_task
[2024-03-30 04:25:02,030] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:25:02,216] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:25:02,286] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-30 04:25:03,706] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-07.parquet uploaded to yellowtaxi_tripdata/yellow_taxi_2021_07.parquet.
[2024-03-30 04:25:03,706] {python.py:175} INFO - Done. Returned value was: None
[2024-03-30 04:25:03,745] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210702T060000, start_date=20240330T042501, end_date=20240330T042503
[2024-03-30 04:25:03,859] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:25:04,184] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:39:11,703] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:39:11,795] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:39:11,806] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:39:11,807] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:39:11,808] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:39:11,932] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-07-02 06:00:00+00:00
[2024-03-30 04:39:11,941] {standard_task_runner.py:52} INFO - Started process 5299 to run task
[2024-03-30 04:39:12,056] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '2292', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpvbs6pxpj', '--error-file', '/tmp/tmpnrhiwqcz']
[2024-03-30 04:39:12,190] {standard_task_runner.py:77} INFO - Job 2292: Subtask local_to_gcs_task
[2024-03-30 04:39:12,521] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:39:12,755] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:39:12,855] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-30 04:39:14,313] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-07.parquet uploaded to yellowtaxi_tripdata/yellow_taxi_2021_07.parquet.
[2024-03-30 04:39:14,314] {python.py:175} INFO - Done. Returned value was: None
[2024-03-30 04:39:14,625] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210702T060000, start_date=20240330T043911, end_date=20240330T043914
[2024-03-30 04:39:14,786] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:39:15,230] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:59:40,001] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:40,105] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:40,105] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:40,105] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:59:40,105] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:40,211] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-07-02 06:00:00+00:00
[2024-03-30 04:59:40,268] {standard_task_runner.py:52} INFO - Started process 6690 to run task
[2024-03-30 04:59:40,302] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '2422', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp1oupldxd', '--error-file', '/tmp/tmpvx_egout']
[2024-03-30 04:59:40,349] {standard_task_runner.py:77} INFO - Job 2422: Subtask local_to_gcs_task
[2024-03-30 04:59:40,753] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:59:40,965] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:59:41,211] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-30 04:59:42,712] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-07.parquet uploaded to yellowtaxi_tripdata/yellow_taxi_2021_07.parquet.
[2024-03-30 04:59:42,714] {python.py:175} INFO - Done. Returned value was: None
[2024-03-30 04:59:42,888] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210702T060000, start_date=20240330T045940, end_date=20240330T045942
[2024-03-30 04:59:43,085] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:59:43,291] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:01:45,584] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:45,789] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:45,802] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:45,811] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:01:45,812] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:45,967] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-07-02 06:00:00+00:00
[2024-03-30 09:01:46,029] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '2537', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpa76l8zrs', '--error-file', '/tmp/tmp6xheglsl']
[2024-03-30 09:01:46,079] {standard_task_runner.py:77} INFO - Job 2537: Subtask local_to_gcs_task
[2024-03-30 09:01:46,018] {standard_task_runner.py:52} INFO - Started process 18203 to run task
[2024-03-30 09:01:46,280] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:01:46,386] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:01:46,459] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-30 09:01:47,669] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-07.parquet uploaded to yellowtaxi_tripdata/yellow_taxi_2021_07.parquet.
[2024-03-30 09:01:47,670] {python.py:175} INFO - Done. Returned value was: None
[2024-03-30 09:01:47,732] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210702T060000, start_date=20240330T090145, end_date=20240330T090147
[2024-03-30 09:01:47,916] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:01:48,115] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:04:17,517] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 11:04:17,943] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 11:04:17,944] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:04:17,944] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:04:17,945] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:04:18,341] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-07-02 06:00:00+00:00
[2024-03-30 11:04:18,508] {standard_task_runner.py:52} INFO - Started process 24470 to run task
[2024-03-30 11:04:18,813] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '2696', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpxmsghj6q', '--error-file', '/tmp/tmp4mjs1znm']
[2024-03-30 11:04:19,173] {standard_task_runner.py:77} INFO - Job 2696: Subtask local_to_gcs_task
[2024-03-30 11:04:20,470] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:04:20,712] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:04:20,920] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-30 11:05:10,564] {local_task_job.py:154} INFO - Task exited with return code Negsignal.SIGKILL
[2024-03-30 11:05:10,792] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210702T060000, start_date=20240330T110417, end_date=20240330T110510
[2024-03-30 11:05:14,169] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:15:25,640] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 11:15:25,787] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 11:15:25,790] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:15:25,794] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:15:25,802] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:15:25,957] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-07-02 06:00:00+00:00
[2024-03-30 11:15:26,160] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '2740', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpcffu3mph', '--error-file', '/tmp/tmp4d40z45t']
[2024-03-30 11:15:26,219] {standard_task_runner.py:77} INFO - Job 2740: Subtask local_to_gcs_task
[2024-03-30 11:15:26,081] {standard_task_runner.py:52} INFO - Started process 25376 to run task
[2024-03-30 11:15:27,006] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:15:27,340] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:15:27,457] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-30 11:15:54,360] {local_task_job.py:154} INFO - Task exited with return code Negsignal.SIGKILL
[2024-03-30 11:15:54,737] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210702T060000, start_date=20240330T111525, end_date=20240330T111554
[2024-03-30 11:15:54,902] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:34:10,588] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 11:34:10,623] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 11:34:10,623] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:34:10,624] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:34:10,624] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:34:10,655] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-07-02 06:00:00+00:00
[2024-03-30 11:34:10,665] {standard_task_runner.py:52} INFO - Started process 26957 to run task
[2024-03-30 11:34:10,732] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '2817', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpb7r56w26', '--error-file', '/tmp/tmpdhqg1f16']
[2024-03-30 11:34:10,791] {standard_task_runner.py:77} INFO - Job 2817: Subtask local_to_gcs_task
[2024-03-30 11:34:11,321] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:34:11,597] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:34:11,759] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-30 11:40:32,596] {base_job.py:230} ERROR - LocalTaskJob heartbeat got an exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/impl.py", line 241, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 508, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/base_job.py", line 220, in heartbeat
    session.merge(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2171, in merge
    _resolve_conflict_map=_resolve_conflict_map,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2244, in _merge
    merged = self.query(mapper.class_).get(key[1])
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 1018, in get
    return self._get_impl(ident, loading.load_on_pk_identity)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 1135, in _get_impl
    return db_load_fn(self, primary_key_identity)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/loading.py", line 286, in load_on_pk_identity
    return q.one()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 3490, in one
    ret = self.one_or_none()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 3459, in one_or_none
    ret = list(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 3535, in __iter__
    return self._execute_and_instances(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 3557, in _execute_and_instances
    querycontext, self._connection_from_session, close_with_result=True
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 3572, in _get_bind_args
    mapper=self._bind_mapper(), clause=querycontext.statement, **kw
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 3550, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1145, in connection
    execution_options=execution_options,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1151, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 433, in _connection_for_bind
    conn = bind._contextual_connect()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2302, in _contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2340, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1584, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/impl.py", line 241, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 508, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

(Background on this error at: http://sqlalche.me/e/13/e3q8)
[2024-03-30 11:40:32,716] {local_task_job.py:142} ERROR - Heartbeat time limit exceeded!
[2024-03-30 11:40:32,716] {standard_task_runner.py:135} ERROR - Job 2817 was killed before it finished (likely due to running out of memory)
[2024-04-28 09:15:41,519] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:41,684] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:41,692] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:41,696] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-28 09:15:41,696] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:41,804] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-07-02 06:00:00+00:00
[2024-04-28 09:15:41,890] {standard_task_runner.py:52} INFO - Started process 1486 to run task
[2024-04-28 09:15:41,945] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '3008', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpxeewywxj', '--error-file', '/tmp/tmpifr2oe3m']
[2024-04-28 09:15:41,992] {standard_task_runner.py:77} INFO - Job 3008: Subtask local_to_gcs_task
[2024-04-28 09:15:42,530] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 6c6a4ca9ff8e
[2024-04-28 09:15:42,830] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-28 09:15:43,062] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-04-28 09:16:35,796] {local_task_job.py:154} INFO - Task exited with return code Negsignal.SIGKILL
[2024-04-28 09:16:36,104] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210702T060000, start_date=20240428T091541, end_date=20240428T091636
[2024-04-28 09:16:36,469] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:14:06,098] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-04-30 02:14:06,237] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-04-30 02:14:06,243] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:14:06,244] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-30 02:14:06,244] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:14:06,432] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-07-02 06:00:00+00:00
[2024-04-30 02:14:06,472] {standard_task_runner.py:52} INFO - Started process 475 to run task
[2024-04-30 02:14:06,682] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '3055', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp7to_i5kp', '--error-file', '/tmp/tmp3osoj3_c']
[2024-04-30 02:14:06,864] {standard_task_runner.py:77} INFO - Job 3055: Subtask local_to_gcs_task
[2024-04-30 02:14:07,261] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host a1ae6a0259c5
[2024-04-30 02:14:07,616] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:14:07,663] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-04-30 02:14:57,430] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 75, in upload_to_gcs
    __clean_file(raw_file_name, clean_file_name)
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 61, in __clean_file
    df.to_parquet(clean_file_name, index=False)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/util/_decorators.py", line 199, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/frame.py", line 2372, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 276, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 101, in write
    table = self.api.Table.from_pandas(df, **from_pandas_kwargs)
  File "pyarrow/table.pxi", line 1561, in pyarrow.lib.Table.from_pandas
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 607, in dataframe_to_arrays
    arrays[i] = maybe_fut.result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 425, in result
    return self.__get_result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.6/concurrent/futures/thread.py", line 56, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 581, in convert_column
    raise e
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 575, in convert_column
    result = pa.array(col, type=type_, from_pandas=True, safe=safe)
  File "pyarrow/array.pxi", line 302, in pyarrow.lib.array
  File "pyarrow/array.pxi", line 83, in pyarrow.lib._ndarray_to_array
  File "pyarrow/error.pxi", line 122, in pyarrow.lib.check_status
pyarrow.lib.ArrowTypeError: ("Expected bytes, got a 'int' object", 'Conversion failed for column store_and_fwd_flag with type object')
[2024-04-30 02:14:57,474] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210702T060000, start_date=20240430T021406, end_date=20240430T021457
[2024-04-30 02:14:57,510] {standard_task_runner.py:92} ERROR - Failed to execute job 3055 for task local_to_gcs_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 75, in upload_to_gcs
    __clean_file(raw_file_name, clean_file_name)
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 61, in __clean_file
    df.to_parquet(clean_file_name, index=False)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/util/_decorators.py", line 199, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/frame.py", line 2372, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 276, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 101, in write
    table = self.api.Table.from_pandas(df, **from_pandas_kwargs)
  File "pyarrow/table.pxi", line 1561, in pyarrow.lib.Table.from_pandas
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 607, in dataframe_to_arrays
    arrays[i] = maybe_fut.result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 425, in result
    return self.__get_result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.6/concurrent/futures/thread.py", line 56, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 581, in convert_column
    raise e
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 575, in convert_column
    result = pa.array(col, type=type_, from_pandas=True, safe=safe)
  File "pyarrow/array.pxi", line 302, in pyarrow.lib.array
  File "pyarrow/array.pxi", line 83, in pyarrow.lib._ndarray_to_array
  File "pyarrow/error.pxi", line 122, in pyarrow.lib.check_status
pyarrow.lib.ArrowTypeError: ("Expected bytes, got a 'int' object", 'Conversion failed for column store_and_fwd_flag with type object')
[2024-04-30 02:14:57,668] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-04-30 02:14:57,835] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:58:25,091] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:25,166] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:25,167] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:25,174] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 02:58:25,175] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:25,681] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-07-02 06:00:00+00:00
[2024-04-30 02:58:25,724] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '3110', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpxy5ypmlq', '--error-file', '/tmp/tmpzylugj0n']
[2024-04-30 02:58:25,745] {standard_task_runner.py:77} INFO - Job 3110: Subtask local_to_gcs_task
[2024-04-30 02:58:25,712] {standard_task_runner.py:52} INFO - Started process 475 to run task
[2024-04-30 02:58:26,417] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 02:58:26,831] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:58:27,534] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-04-30 02:58:27,601] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 92, in upload_to_gcs
    blob.upload_from_filename(clean_file_name)
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/storage/blob.py", line 2720, in upload_from_filename
    with open(filename, "rb") as file_obj:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/cleaned_data/yellowtaxi_tripdata_2021-07.parquet'
[2024-04-30 02:58:27,686] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210702T060000, start_date=20240430T025825, end_date=20240430T025827
[2024-04-30 02:58:27,777] {standard_task_runner.py:92} ERROR - Failed to execute job 3110 for task local_to_gcs_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 92, in upload_to_gcs
    blob.upload_from_filename(clean_file_name)
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/storage/blob.py", line 2720, in upload_from_filename
    with open(filename, "rb") as file_obj:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/cleaned_data/yellowtaxi_tripdata_2021-07.parquet'
[2024-04-30 02:58:27,867] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-04-30 02:58:28,007] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:01:19,805] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:19,894] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:19,894] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:19,894] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:01:19,894] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:19,976] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-07-02 06:00:00+00:00
[2024-04-30 03:01:20,072] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '3146', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp1a0cewae', '--error-file', '/tmp/tmp1kbdjjbd']
[2024-04-30 03:01:20,087] {standard_task_runner.py:77} INFO - Job 3146: Subtask local_to_gcs_task
[2024-04-30 03:01:20,021] {standard_task_runner.py:52} INFO - Started process 744 to run task
[2024-04-30 03:01:20,664] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:01:21,014] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:01:21,196] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-04-30 03:01:22,799] {python.py:175} INFO - Done. Returned value was: None
[2024-04-30 03:01:23,270] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210702T060000, start_date=20240430T030119, end_date=20240430T030123
[2024-04-30 03:01:23,462] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:01:23,798] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:30:17,797] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-04-30 04:30:17,863] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-04-30 04:30:17,864] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:30:17,864] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:30:17,864] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:30:17,948] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-07-02 06:00:00+00:00
[2024-04-30 04:30:17,982] {standard_task_runner.py:52} INFO - Started process 5309 to run task
[2024-04-30 04:30:18,036] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '3257', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpy43sfvkn', '--error-file', '/tmp/tmpxjfmko4v']
[2024-04-30 04:30:18,065] {standard_task_runner.py:77} INFO - Job 3257: Subtask local_to_gcs_task
[2024-04-30 04:30:18,341] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:30:18,491] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:30:18,666] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-04-30 04:30:57,247] {local_task_job.py:154} INFO - Task exited with return code Negsignal.SIGKILL
[2024-04-30 04:30:57,678] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210702T060000, start_date=20240430T043017, end_date=20240430T043057
[2024-04-30 04:30:59,306] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
