[2024-03-29 07:24:42,369] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:42,544] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:42,556] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:42,557] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:24:42,557] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:42,653] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-03-02 06:00:00+00:00
[2024-03-29 07:24:42,710] {standard_task_runner.py:52} INFO - Started process 585 to run task
[2024-03-29 07:24:42,763] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '1458', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpo7b391he', '--error-file', '/tmp/tmp7uk2v4t6']
[2024-03-29 07:24:42,795] {standard_task_runner.py:77} INFO - Job 1458: Subtask local_to_gcs_task
[2024-03-29 07:24:43,114] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:24:43,517] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:24:43,664] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-29 07:24:44,476] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-03.parquet uploaded to yellowtaxi_tripdata/2021-03.parquet.
[2024-03-29 07:24:44,476] {python.py:175} INFO - Done. Returned value was: None
[2024-03-29 07:24:44,546] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210302T060000, start_date=20240329T072442, end_date=20240329T072444
[2024-03-29 07:24:44,652] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:24:44,840] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:31:00,109] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-29 07:31:00,164] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-29 07:31:00,167] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:31:00,168] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:31:00,169] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:31:00,237] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-03-02 06:00:00+00:00
[2024-03-29 07:31:00,270] {standard_task_runner.py:52} INFO - Started process 1079 to run task
[2024-03-29 07:31:00,322] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '1517', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpp_wczihv', '--error-file', '/tmp/tmplb9fc42e']
[2024-03-29 07:31:00,367] {standard_task_runner.py:77} INFO - Job 1517: Subtask local_to_gcs_task
[2024-03-29 07:31:00,668] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:31:00,837] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:31:00,953] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-29 07:31:02,012] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-03.parquet uploaded to yellowtaxi_tripdata/2021-03.parquet.
[2024-03-29 07:31:02,013] {python.py:175} INFO - Done. Returned value was: None
[2024-03-29 07:31:02,052] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210302T060000, start_date=20240329T073100, end_date=20240329T073102
[2024-03-29 07:31:02,177] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:31:02,320] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:37:36,383] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:36,475] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:36,486] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:36,487] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:37:36,488] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:36,513] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-03-02 06:00:00+00:00
[2024-03-29 07:37:36,536] {standard_task_runner.py:52} INFO - Started process 1584 to run task
[2024-03-29 07:37:36,598] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '1578', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpt9lqeusx', '--error-file', '/tmp/tmpxwf_5zw6']
[2024-03-29 07:37:36,628] {standard_task_runner.py:77} INFO - Job 1578: Subtask local_to_gcs_task
[2024-03-29 07:37:36,746] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:37:36,875] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:37:36,933] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-29 07:37:37,574] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-03.parquet uploaded to yellowtaxi_tripdata/2021-03.parquet.
[2024-03-29 07:37:37,575] {python.py:175} INFO - Done. Returned value was: None
[2024-03-29 07:37:37,630] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210302T060000, start_date=20240329T073736, end_date=20240329T073737
[2024-03-29 07:37:37,751] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:37:37,839] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:08:43,989] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:44,124] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:44,132] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:44,136] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:08:44,137] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:44,891] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-03-02 06:00:00+00:00
[2024-03-29 08:08:44,924] {standard_task_runner.py:52} INFO - Started process 295 to run task
[2024-03-29 08:08:44,942] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '1642', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpt6r2jw4s', '--error-file', '/tmp/tmpcou_mxhg']
[2024-03-29 08:08:44,993] {standard_task_runner.py:77} INFO - Job 1642: Subtask local_to_gcs_task
[2024-03-29 08:08:45,540] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:08:45,957] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:08:46,095] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-29 08:08:46,715] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-03.parquet uploaded to yellowtaxi_tripdata/{TABLE_NAME_TEMPLATE}.parquet.
[2024-03-29 08:08:46,755] {python.py:175} INFO - Done. Returned value was: None
[2024-03-29 08:08:47,419] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210302T060000, start_date=20240329T080844, end_date=20240329T080847
[2024-03-29 08:08:47,577] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:08:47,752] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:11:04,881] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-29 08:11:05,100] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-29 08:11:05,102] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:11:05,102] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:11:05,102] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:11:05,488] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-03-02 06:00:00+00:00
[2024-03-29 08:11:05,631] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '1687', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp_9nqsy8w', '--error-file', '/tmp/tmpv5s1aa_a']
[2024-03-29 08:11:05,693] {standard_task_runner.py:77} INFO - Job 1687: Subtask local_to_gcs_task
[2024-03-29 08:11:05,666] {standard_task_runner.py:52} INFO - Started process 549 to run task
[2024-03-29 08:11:06,296] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:11:06,822] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:11:06,950] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-29 08:11:08,970] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-03.parquet uploaded to yellowtaxi_tripdata/yellow_taxi_2021_03.parquet.
[2024-03-29 08:11:08,970] {python.py:175} INFO - Done. Returned value was: None
[2024-03-29 08:11:09,622] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210302T060000, start_date=20240329T081104, end_date=20240329T081109
[2024-03-29 08:11:09,891] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:11:10,271] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:30:19,678] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:19,729] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:19,730] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:19,731] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:30:19,734] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:19,810] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-03-02 06:00:00+00:00
[2024-03-30 03:30:19,823] {standard_task_runner.py:52} INFO - Started process 531 to run task
[2024-03-30 03:30:19,848] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '1832', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpmwdudnbd', '--error-file', '/tmp/tmpd1a2vy7j']
[2024-03-30 03:30:19,865] {standard_task_runner.py:77} INFO - Job 1832: Subtask local_to_gcs_task
[2024-03-30 03:30:20,358] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:30:20,833] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:30:21,082] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-30 03:30:22,753] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-03.parquet uploaded to yellowtaxi_tripdata/yellow_taxi_2021_03.parquet.
[2024-03-30 03:30:22,754] {python.py:175} INFO - Done. Returned value was: None
[2024-03-30 03:30:23,197] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210302T060000, start_date=20240330T033019, end_date=20240330T033023
[2024-03-30 03:30:23,497] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:30:23,749] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:42:06,816] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 03:42:06,935] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 03:42:06,935] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:42:06,935] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:42:06,935] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:42:06,968] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-03-02 06:00:00+00:00
[2024-03-30 03:42:06,977] {standard_task_runner.py:52} INFO - Started process 1332 to run task
[2024-03-30 03:42:07,004] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '1909', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmplak1ynqg', '--error-file', '/tmp/tmp_2r4koqk']
[2024-03-30 03:42:07,019] {standard_task_runner.py:77} INFO - Job 1909: Subtask local_to_gcs_task
[2024-03-30 03:42:07,186] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:42:07,309] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:42:07,407] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-30 03:42:08,184] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-03.parquet uploaded to yellowtaxi_tripdata/yellow_taxi_2021_03.parquet.
[2024-03-30 03:42:08,184] {python.py:175} INFO - Done. Returned value was: None
[2024-03-30 03:42:08,275] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210302T060000, start_date=20240330T034206, end_date=20240330T034208
[2024-03-30 03:42:08,386] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:42:08,537] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:18:14,170] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:14,329] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:14,330] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:14,330] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:18:14,333] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:14,407] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-03-02 06:00:00+00:00
[2024-03-30 04:18:14,539] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '2090', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp4f1j9_53', '--error-file', '/tmp/tmp1spli631']
[2024-03-30 04:18:14,577] {standard_task_runner.py:77} INFO - Job 2090: Subtask local_to_gcs_task
[2024-03-30 04:18:14,451] {standard_task_runner.py:52} INFO - Started process 3575 to run task
[2024-03-30 04:18:15,042] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:18:15,387] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:18:15,528] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-30 04:18:16,217] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-03.parquet uploaded to yellowtaxi_tripdata/yellow_taxi_2021_03.parquet.
[2024-03-30 04:18:16,218] {python.py:175} INFO - Done. Returned value was: None
[2024-03-30 04:18:16,260] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210302T060000, start_date=20240330T041814, end_date=20240330T041816
[2024-03-30 04:18:16,463] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:18:16,795] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:24:49,799] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:24:49,891] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:24:49,891] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:24:49,891] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:24:49,892] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:24:49,933] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-03-02 06:00:00+00:00
[2024-03-30 04:24:49,944] {standard_task_runner.py:52} INFO - Started process 4198 to run task
[2024-03-30 04:24:50,005] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '2171', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpd7vkdw9y', '--error-file', '/tmp/tmpb72ecswd']
[2024-03-30 04:24:50,029] {standard_task_runner.py:77} INFO - Job 2171: Subtask local_to_gcs_task
[2024-03-30 04:24:50,352] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:24:50,509] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:24:50,604] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-30 04:24:51,217] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-03.parquet uploaded to yellowtaxi_tripdata/yellow_taxi_2021_03.parquet.
[2024-03-30 04:24:51,217] {python.py:175} INFO - Done. Returned value was: None
[2024-03-30 04:24:51,367] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210302T060000, start_date=20240330T042449, end_date=20240330T042451
[2024-03-30 04:24:51,503] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:24:51,812] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:39:06,789] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:39:06,980] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:39:06,981] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:39:06,995] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:39:06,995] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:39:07,267] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-03-02 06:00:00+00:00
[2024-03-30 04:39:07,393] {standard_task_runner.py:52} INFO - Started process 5287 to run task
[2024-03-30 04:39:07,424] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '2289', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp_7q23dz8', '--error-file', '/tmp/tmp3fove6l4']
[2024-03-30 04:39:07,619] {standard_task_runner.py:77} INFO - Job 2289: Subtask local_to_gcs_task
[2024-03-30 04:39:08,889] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:39:09,656] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:39:10,232] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-30 04:39:12,247] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-03.parquet uploaded to yellowtaxi_tripdata/yellow_taxi_2021_03.parquet.
[2024-03-30 04:39:12,248] {python.py:175} INFO - Done. Returned value was: None
[2024-03-30 04:39:12,292] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210302T060000, start_date=20240330T043906, end_date=20240330T043912
[2024-03-30 04:39:12,507] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:39:12,619] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:59:34,509] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:34,624] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:34,627] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:34,630] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:59:34,631] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:34,756] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-03-02 06:00:00+00:00
[2024-03-30 04:59:34,792] {standard_task_runner.py:52} INFO - Started process 6666 to run task
[2024-03-30 04:59:34,833] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '2417', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpthzuqeog', '--error-file', '/tmp/tmp6ydx40rg']
[2024-03-30 04:59:34,865] {standard_task_runner.py:77} INFO - Job 2417: Subtask local_to_gcs_task
[2024-03-30 04:59:35,220] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:59:35,406] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:59:35,543] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-30 04:59:36,533] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-03.parquet uploaded to yellowtaxi_tripdata/yellow_taxi_2021_03.parquet.
[2024-03-30 04:59:36,534] {python.py:175} INFO - Done. Returned value was: None
[2024-03-30 04:59:36,576] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210302T060000, start_date=20240330T045934, end_date=20240330T045936
[2024-03-30 04:59:36,678] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:59:36,783] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:01:39,478] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:39,538] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:39,539] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:39,540] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:01:39,540] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:39,586] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-03-02 06:00:00+00:00
[2024-03-30 09:01:39,612] {standard_task_runner.py:52} INFO - Started process 18174 to run task
[2024-03-30 09:01:39,670] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '2533', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp8c2sniok', '--error-file', '/tmp/tmp8i5cmk9j']
[2024-03-30 09:01:39,729] {standard_task_runner.py:77} INFO - Job 2533: Subtask local_to_gcs_task
[2024-03-30 09:01:40,122] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:01:40,398] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:01:40,669] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-30 09:01:41,856] {logging_mixin.py:109} INFO - File /opt/***/yellowtaxi_tripdata_2021-03.parquet uploaded to yellowtaxi_tripdata/yellow_taxi_2021_03.parquet.
[2024-03-30 09:01:41,856] {python.py:175} INFO - Done. Returned value was: None
[2024-03-30 09:01:41,936] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210302T060000, start_date=20240330T090139, end_date=20240330T090141
[2024-03-30 09:01:42,047] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:01:42,202] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:04:07,823] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 11:04:07,928] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 11:04:07,930] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:04:07,935] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:04:07,935] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:04:08,016] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-03-02 06:00:00+00:00
[2024-03-30 11:04:08,069] {standard_task_runner.py:52} INFO - Started process 24417 to run task
[2024-03-30 11:04:08,174] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '2690', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpyvpefsxd', '--error-file', '/tmp/tmpsp4nx_xr']
[2024-03-30 11:04:08,280] {standard_task_runner.py:77} INFO - Job 2690: Subtask local_to_gcs_task
[2024-03-30 11:04:08,844] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:04:08,957] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:04:09,087] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-30 11:04:39,459] {local_task_job.py:154} INFO - Task exited with return code Negsignal.SIGKILL
[2024-03-30 11:04:43,962] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210302T060000, start_date=20240330T110407, end_date=20240330T110443
[2024-03-30 11:04:44,608] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:15:14,576] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 11:15:14,734] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 11:15:14,736] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:15:14,736] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:15:14,737] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:15:14,848] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-03-02 06:00:00+00:00
[2024-03-30 11:15:14,933] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '2736', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpv556wfe4', '--error-file', '/tmp/tmp7izsw9v3']
[2024-03-30 11:15:14,994] {standard_task_runner.py:77} INFO - Job 2736: Subtask local_to_gcs_task
[2024-03-30 11:15:14,910] {standard_task_runner.py:52} INFO - Started process 25325 to run task
[2024-03-30 11:15:15,430] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:15:15,615] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:15:15,737] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-30 11:15:32,232] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 65, in upload_to_gcs
    index=False,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/util/_decorators.py", line 199, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/frame.py", line 2372, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 276, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 101, in write
    table = self.api.Table.from_pandas(df, **from_pandas_kwargs)
  File "pyarrow/table.pxi", line 1561, in pyarrow.lib.Table.from_pandas
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 607, in dataframe_to_arrays
    arrays[i] = maybe_fut.result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 425, in result
    return self.__get_result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.6/concurrent/futures/thread.py", line 56, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 581, in convert_column
    raise e
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 575, in convert_column
    result = pa.array(col, type=type_, from_pandas=True, safe=safe)
  File "pyarrow/array.pxi", line 302, in pyarrow.lib.array
  File "pyarrow/array.pxi", line 83, in pyarrow.lib._ndarray_to_array
  File "pyarrow/error.pxi", line 122, in pyarrow.lib.check_status
pyarrow.lib.ArrowTypeError: ("Expected bytes, got a 'int' object", 'Conversion failed for column store_and_fwd_flag with type object')
[2024-03-30 11:15:32,334] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210302T060000, start_date=20240330T111514, end_date=20240330T111532
[2024-03-30 11:15:32,540] {standard_task_runner.py:92} ERROR - Failed to execute job 2736 for task local_to_gcs_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 65, in upload_to_gcs
    index=False,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/util/_decorators.py", line 199, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/frame.py", line 2372, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 276, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 101, in write
    table = self.api.Table.from_pandas(df, **from_pandas_kwargs)
  File "pyarrow/table.pxi", line 1561, in pyarrow.lib.Table.from_pandas
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 607, in dataframe_to_arrays
    arrays[i] = maybe_fut.result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 425, in result
    return self.__get_result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.6/concurrent/futures/thread.py", line 56, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 581, in convert_column
    raise e
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 575, in convert_column
    result = pa.array(col, type=type_, from_pandas=True, safe=safe)
  File "pyarrow/array.pxi", line 302, in pyarrow.lib.array
  File "pyarrow/array.pxi", line 83, in pyarrow.lib._ndarray_to_array
  File "pyarrow/error.pxi", line 122, in pyarrow.lib.check_status
pyarrow.lib.ArrowTypeError: ("Expected bytes, got a 'int' object", 'Conversion failed for column store_and_fwd_flag with type object')
[2024-03-30 11:15:32,922] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 11:15:33,147] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:33:58,290] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 11:33:58,362] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 11:33:58,365] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:33:58,366] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:33:58,366] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:33:58,426] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-03-02 06:00:00+00:00
[2024-03-30 11:33:58,528] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '2813', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpj54rbsq6', '--error-file', '/tmp/tmp6a6_rra_']
[2024-03-30 11:33:58,508] {standard_task_runner.py:52} INFO - Started process 26894 to run task
[2024-03-30 11:33:58,579] {standard_task_runner.py:77} INFO - Job 2813: Subtask local_to_gcs_task
[2024-03-30 11:33:58,769] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:33:59,017] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:33:59,140] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-30 11:34:05,725] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 68, in upload_to_gcs
    df.to_parquet(clean_file_name, index=False)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/util/_decorators.py", line 199, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/frame.py", line 2372, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 276, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 101, in write
    table = self.api.Table.from_pandas(df, **from_pandas_kwargs)
  File "pyarrow/table.pxi", line 1561, in pyarrow.lib.Table.from_pandas
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 607, in dataframe_to_arrays
    arrays[i] = maybe_fut.result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 425, in result
    return self.__get_result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.6/concurrent/futures/thread.py", line 56, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 581, in convert_column
    raise e
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 575, in convert_column
    result = pa.array(col, type=type_, from_pandas=True, safe=safe)
  File "pyarrow/array.pxi", line 302, in pyarrow.lib.array
  File "pyarrow/array.pxi", line 83, in pyarrow.lib._ndarray_to_array
  File "pyarrow/error.pxi", line 122, in pyarrow.lib.check_status
pyarrow.lib.ArrowTypeError: ("Expected bytes, got a 'int' object", 'Conversion failed for column store_and_fwd_flag with type object')
[2024-03-30 11:34:05,773] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210302T060000, start_date=20240330T113358, end_date=20240330T113405
[2024-03-30 11:34:05,935] {standard_task_runner.py:92} ERROR - Failed to execute job 2813 for task local_to_gcs_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 68, in upload_to_gcs
    df.to_parquet(clean_file_name, index=False)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/util/_decorators.py", line 199, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/frame.py", line 2372, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 276, in to_parquet
    **kwargs,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parquet.py", line 101, in write
    table = self.api.Table.from_pandas(df, **from_pandas_kwargs)
  File "pyarrow/table.pxi", line 1561, in pyarrow.lib.Table.from_pandas
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 607, in dataframe_to_arrays
    arrays[i] = maybe_fut.result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 425, in result
    return self.__get_result()
  File "/usr/local/lib/python3.6/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.6/concurrent/futures/thread.py", line 56, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 581, in convert_column
    raise e
  File "/home/airflow/.local/lib/python3.6/site-packages/pyarrow/pandas_compat.py", line 575, in convert_column
    result = pa.array(col, type=type_, from_pandas=True, safe=safe)
  File "pyarrow/array.pxi", line 302, in pyarrow.lib.array
  File "pyarrow/array.pxi", line 83, in pyarrow.lib._ndarray_to_array
  File "pyarrow/error.pxi", line 122, in pyarrow.lib.check_status
pyarrow.lib.ArrowTypeError: ("Expected bytes, got a 'int' object", 'Conversion failed for column store_and_fwd_flag with type object')
[2024-03-30 11:34:06,375] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 11:34:06,963] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-04-28 09:15:38,499] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:38,519] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:38,519] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:38,519] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-28 09:15:38,519] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:38,808] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-03-02 06:00:00+00:00
[2024-04-28 09:15:39,038] {standard_task_runner.py:52} INFO - Started process 1460 to run task
[2024-04-28 09:15:39,087] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '3006', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpfqz144pr', '--error-file', '/tmp/tmp14_sykzp']
[2024-04-28 09:15:39,105] {standard_task_runner.py:77} INFO - Job 3006: Subtask local_to_gcs_task
[2024-04-28 09:15:39,677] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 6c6a4ca9ff8e
[2024-04-28 09:15:39,828] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-28 09:15:39,906] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-04-28 09:15:59,657] {local_task_job.py:154} INFO - Task exited with return code Negsignal.SIGKILL
[2024-04-28 09:16:35,583] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210302T060000, start_date=20240428T091538, end_date=20240428T091635
[2024-04-28 09:16:36,398] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:14:00,357] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-04-30 02:14:00,564] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-04-30 02:14:00,564] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:14:00,564] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-30 02:14:00,565] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:14:00,657] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-03-02 06:00:00+00:00
[2024-04-30 02:14:00,706] {standard_task_runner.py:52} INFO - Started process 411 to run task
[2024-04-30 02:14:00,753] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '3040', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp3rwwrjyn', '--error-file', '/tmp/tmpmt_ntg_4']
[2024-04-30 02:14:00,800] {standard_task_runner.py:77} INFO - Job 3040: Subtask local_to_gcs_task
[2024-04-30 02:14:01,156] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host a1ae6a0259c5
[2024-04-30 02:14:01,240] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:14:01,360] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-04-30 02:14:53,231] {local_task_job.py:154} INFO - Task exited with return code Negsignal.SIGKILL
[2024-04-30 02:14:53,513] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210302T060000, start_date=20240430T021400, end_date=20240430T021453
[2024-04-30 02:14:54,141] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:58:23,841] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:23,994] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:24,002] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:24,002] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 02:58:24,003] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:24,374] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-03-02 06:00:00+00:00
[2024-04-30 02:58:24,400] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '3108', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpep6cm37w', '--error-file', '/tmp/tmp6y1e6iyb']
[2024-04-30 02:58:24,419] {standard_task_runner.py:77} INFO - Job 3108: Subtask local_to_gcs_task
[2024-04-30 02:58:24,383] {standard_task_runner.py:52} INFO - Started process 462 to run task
[2024-04-30 02:58:25,048] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 02:58:25,802] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:58:26,786] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-04-30 02:58:26,884] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 92, in upload_to_gcs
    blob.upload_from_filename(clean_file_name)
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/storage/blob.py", line 2720, in upload_from_filename
    with open(filename, "rb") as file_obj:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/cleaned_data/yellowtaxi_tripdata_2021-03.parquet'
[2024-04-30 02:58:26,959] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210302T060000, start_date=20240430T025823, end_date=20240430T025826
[2024-04-30 02:58:27,381] {standard_task_runner.py:92} ERROR - Failed to execute job 3108 for task local_to_gcs_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 92, in upload_to_gcs
    blob.upload_from_filename(clean_file_name)
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/storage/blob.py", line 2720, in upload_from_filename
    with open(filename, "rb") as file_obj:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/cleaned_data/yellowtaxi_tripdata_2021-03.parquet'
[2024-04-30 02:58:27,411] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-04-30 02:58:27,667] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:01:12,741] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:12,914] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:12,917] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:12,917] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:01:12,918] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:13,080] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-03-02 06:00:00+00:00
[2024-04-30 03:01:13,181] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '3140', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp_v19_cxc', '--error-file', '/tmp/tmpxur342sy']
[2024-04-30 03:01:13,203] {standard_task_runner.py:77} INFO - Job 3140: Subtask local_to_gcs_task
[2024-04-30 03:01:13,156] {standard_task_runner.py:52} INFO - Started process 709 to run task
[2024-04-30 03:01:13,596] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:01:13,814] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:01:14,040] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-04-30 03:01:14,825] {python.py:175} INFO - Done. Returned value was: None
[2024-04-30 03:01:14,859] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210302T060000, start_date=20240430T030112, end_date=20240430T030114
[2024-04-30 03:01:14,968] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:01:15,407] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:30:07,063] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-04-30 04:30:07,087] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-04-30 04:30:07,087] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:30:07,088] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:30:07,088] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:30:07,113] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2021-03-02 06:00:00+00:00
[2024-04-30 04:30:07,123] {standard_task_runner.py:52} INFO - Started process 5240 to run task
[2024-04-30 04:30:07,144] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'local_to_gcs_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '3252', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpzio8025o', '--error-file', '/tmp/tmpnkdpm4ng']
[2024-04-30 04:30:07,150] {standard_task_runner.py:77} INFO - Job 3252: Subtask local_to_gcs_task
[2024-04-30 04:30:07,253] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.local_to_gcs_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:30:07,333] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:30:07,404] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-04-30 04:30:39,431] {local_task_job.py:154} INFO - Task exited with return code Negsignal.SIGKILL
[2024-04-30 04:30:57,086] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=local_to_gcs_task, execution_date=20210302T060000, start_date=20240430T043007, end_date=20240430T043057
[2024-04-30 04:30:57,909] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
