[2024-03-29 07:24:25,499] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:25,534] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:25,540] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:25,540] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:24:25,541] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:25,588] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-07-02 06:00:00+00:00
[2024-03-29 07:24:25,632] {standard_task_runner.py:52} INFO - Started process 468 to run task
[2024-03-29 07:24:25,653] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '1438', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpgirkyqqz', '--error-file', '/tmp/tmp4m6g18kl']
[2024-03-29 07:24:25,708] {standard_task_runner.py:77} INFO - Job 1438: Subtask download_dataset_task
[2024-03-29 07:24:26,064] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:24:26,230] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:24:26,368] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-29 07:24:26,370] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:24:26,375] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet > /opt/***/yellowtaxi_tripdata_2021-07.parquet']
[2024-03-29 07:24:26,505] {subprocess.py:85} INFO - Output:
[2024-03-29 07:24:32,098] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:24:32,595] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210702T060000, start_date=20240329T072425, end_date=20240329T072432
[2024-03-29 07:24:32,811] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:24:33,834] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:30:45,725] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-29 07:30:45,778] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-29 07:30:45,779] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:30:45,780] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:30:45,780] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:30:45,829] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-07-02 06:00:00+00:00
[2024-03-29 07:30:45,846] {standard_task_runner.py:52} INFO - Started process 1000 to run task
[2024-03-29 07:30:45,879] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '1505', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp0cu_28aj', '--error-file', '/tmp/tmp_tw7z5f3']
[2024-03-29 07:30:45,899] {standard_task_runner.py:77} INFO - Job 1505: Subtask download_dataset_task
[2024-03-29 07:30:46,098] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:30:46,171] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:30:46,224] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-29 07:30:46,225] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:30:46,226] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet > /opt/***/yellowtaxi_tripdata_2021-07.parquet']
[2024-03-29 07:30:46,271] {subprocess.py:85} INFO - Output:
[2024-03-29 07:30:51,842] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:30:51,969] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210702T060000, start_date=20240329T073045, end_date=20240329T073051
[2024-03-29 07:30:52,043] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:30:52,203] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:37:27,984] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:28,047] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:28,047] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:28,047] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:37:28,048] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:28,091] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-07-02 06:00:00+00:00
[2024-03-29 07:37:28,099] {standard_task_runner.py:52} INFO - Started process 1515 to run task
[2024-03-29 07:37:28,164] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '1567', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmps90bc4dn', '--error-file', '/tmp/tmp9ns0xifb']
[2024-03-29 07:37:28,182] {standard_task_runner.py:77} INFO - Job 1567: Subtask download_dataset_task
[2024-03-29 07:37:28,431] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:37:28,545] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:37:28,632] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-29 07:37:28,634] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:37:28,640] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet > /opt/***/yellowtaxi_tripdata_2021-07.parquet']
[2024-03-29 07:37:28,736] {subprocess.py:85} INFO - Output:
[2024-03-29 07:37:34,553] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:37:34,676] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210702T060000, start_date=20240329T073727, end_date=20240329T073734
[2024-03-29 07:37:34,742] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:37:34,937] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:08:28,446] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:28,500] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:28,501] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:28,504] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:08:28,505] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:28,577] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-07-02 06:00:00+00:00
[2024-03-29 08:08:28,622] {standard_task_runner.py:52} INFO - Started process 194 to run task
[2024-03-29 08:08:28,697] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '1630', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpl761ddr5', '--error-file', '/tmp/tmp8w5xju9n']
[2024-03-29 08:08:28,792] {standard_task_runner.py:77} INFO - Job 1630: Subtask download_dataset_task
[2024-03-29 08:08:29,262] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:08:29,571] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:08:29,679] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-29 08:08:29,681] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:08:29,682] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet > /opt/***/yellowtaxi_tripdata_2021-07.parquet']
[2024-03-29 08:08:29,717] {subprocess.py:85} INFO - Output:
[2024-03-29 08:08:35,474] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:08:35,589] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210702T060000, start_date=20240329T080828, end_date=20240329T080835
[2024-03-29 08:08:35,770] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:08:36,285] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:10:56,507] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-29 08:10:56,628] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-29 08:10:56,636] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:10:56,637] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:10:56,637] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:10:56,719] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-07-02 06:00:00+00:00
[2024-03-29 08:10:56,783] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '1673', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp5oden9wn', '--error-file', '/tmp/tmp_5xi1ih4']
[2024-03-29 08:10:56,806] {standard_task_runner.py:77} INFO - Job 1673: Subtask download_dataset_task
[2024-03-29 08:10:56,757] {standard_task_runner.py:52} INFO - Started process 489 to run task
[2024-03-29 08:10:57,222] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:10:57,598] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:10:57,734] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-29 08:10:57,737] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:10:57,744] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet > /opt/***/yellowtaxi_tripdata_2021-07.parquet']
[2024-03-29 08:10:57,857] {subprocess.py:85} INFO - Output:
[2024-03-29 08:11:04,037] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:11:04,218] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210702T060000, start_date=20240329T081056, end_date=20240329T081104
[2024-03-29 08:11:04,423] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:11:04,995] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:30:03,826] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:03,927] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:03,927] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:03,927] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:30:03,927] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:04,080] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-07-02 06:00:00+00:00
[2024-03-30 03:30:04,167] {standard_task_runner.py:52} INFO - Started process 430 to run task
[2024-03-30 03:30:04,245] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '1815', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpsu6l79ta', '--error-file', '/tmp/tmpylq8e3en']
[2024-03-30 03:30:04,317] {standard_task_runner.py:77} INFO - Job 1815: Subtask download_dataset_task
[2024-03-30 03:30:04,885] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:30:05,252] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:30:05,395] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-30 03:30:05,396] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:30:05,397] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet > /opt/***/yellowtaxi_tripdata_2021-07.parquet']
[2024-03-30 03:30:05,458] {subprocess.py:85} INFO - Output:
[2024-03-30 03:30:11,301] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:30:11,693] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210702T060000, start_date=20240330T033003, end_date=20240330T033011
[2024-03-30 03:30:11,778] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:30:11,872] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:41:57,034] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 03:41:57,123] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 03:41:57,123] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:41:57,124] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:41:57,124] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:41:57,203] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-07-02 06:00:00+00:00
[2024-03-30 03:41:57,253] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '1898', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpk9za_j5n', '--error-file', '/tmp/tmp4sx3c6ye']
[2024-03-30 03:41:57,282] {standard_task_runner.py:77} INFO - Job 1898: Subtask download_dataset_task
[2024-03-30 03:41:57,262] {standard_task_runner.py:52} INFO - Started process 1274 to run task
[2024-03-30 03:41:57,509] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:41:57,656] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:41:57,779] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-30 03:41:57,780] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:41:57,781] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet > /opt/***/yellowtaxi_tripdata_2021-07.parquet']
[2024-03-30 03:41:57,876] {subprocess.py:85} INFO - Output:
[2024-03-30 03:42:03,719] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:42:04,173] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210702T060000, start_date=20240330T034157, end_date=20240330T034204
[2024-03-30 03:42:04,392] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:42:05,106] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:18:03,859] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:04,071] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:04,071] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:04,071] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:18:04,071] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:04,339] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-07-02 06:00:00+00:00
[2024-03-30 04:18:04,405] {standard_task_runner.py:52} INFO - Started process 3507 to run task
[2024-03-30 04:18:04,480] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '2078', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpyh01f3yv', '--error-file', '/tmp/tmpxt4n_9o3']
[2024-03-30 04:18:04,595] {standard_task_runner.py:77} INFO - Job 2078: Subtask download_dataset_task
[2024-03-30 04:18:04,999] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:18:05,233] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:18:05,339] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-30 04:18:05,341] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:18:05,342] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet > /opt/***/yellowtaxi_tripdata_2021-07.parquet']
[2024-03-30 04:18:05,465] {subprocess.py:85} INFO - Output:
[2024-03-30 04:18:11,194] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:18:11,488] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210702T060000, start_date=20240330T041803, end_date=20240330T041811
[2024-03-30 04:18:11,591] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:18:11,730] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:24:44,173] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:24:44,312] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:24:44,312] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:24:44,312] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:24:44,312] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:24:44,411] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-07-02 06:00:00+00:00
[2024-03-30 04:24:44,463] {standard_task_runner.py:52} INFO - Started process 4151 to run task
[2024-03-30 04:24:44,537] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '2160', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpu5_giaz6', '--error-file', '/tmp/tmpsovei9ig']
[2024-03-30 04:24:44,574] {standard_task_runner.py:77} INFO - Job 2160: Subtask download_dataset_task
[2024-03-30 04:24:44,905] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:24:45,146] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:24:45,232] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-30 04:24:45,234] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:24:45,235] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet > /opt/***/yellowtaxi_tripdata_2021-07.parquet']
[2024-03-30 04:24:45,325] {subprocess.py:85} INFO - Output:
[2024-03-30 04:24:51,062] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:24:51,383] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210702T060000, start_date=20240330T042444, end_date=20240330T042451
[2024-03-30 04:24:51,475] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:24:51,674] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:38:41,638] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:38:41,809] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:38:41,810] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:38:41,810] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:38:41,810] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:38:42,017] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-07-02 06:00:00+00:00
[2024-03-30 04:38:42,085] {standard_task_runner.py:52} INFO - Started process 5200 to run task
[2024-03-30 04:38:42,163] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '2274', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp_gan7fvd', '--error-file', '/tmp/tmpvb8_nnn3']
[2024-03-30 04:38:42,320] {standard_task_runner.py:77} INFO - Job 2274: Subtask download_dataset_task
[2024-03-30 04:38:43,054] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:38:43,223] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:38:43,335] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-30 04:38:43,337] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:38:43,337] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet > /opt/***/yellowtaxi_tripdata_2021-07.parquet']
[2024-03-30 04:38:43,640] {subprocess.py:85} INFO - Output:
[2024-03-30 04:38:49,829] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:38:50,420] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210702T060000, start_date=20240330T043841, end_date=20240330T043850
[2024-03-30 04:38:50,691] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:38:51,371] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:59:24,686] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:24,773] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:24,774] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:24,774] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:59:24,774] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:24,854] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-07-02 06:00:00+00:00
[2024-03-30 04:59:24,863] {standard_task_runner.py:52} INFO - Started process 6600 to run task
[2024-03-30 04:59:24,882] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '2407', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpk8qhjpxm', '--error-file', '/tmp/tmpaxkkpscl']
[2024-03-30 04:59:24,890] {standard_task_runner.py:77} INFO - Job 2407: Subtask download_dataset_task
[2024-03-30 04:59:25,343] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:59:25,626] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:59:25,721] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-30 04:59:25,722] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:59:25,723] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet > /opt/***/yellowtaxi_tripdata_2021-07.parquet']
[2024-03-30 04:59:25,742] {subprocess.py:85} INFO - Output:
[2024-03-30 04:59:31,519] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:59:31,646] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210702T060000, start_date=20240330T045924, end_date=20240330T045931
[2024-03-30 04:59:31,720] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:59:31,914] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:01:28,366] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:28,539] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:28,539] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:28,539] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:01:28,539] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:28,707] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-07-02 06:00:00+00:00
[2024-03-30 09:01:28,841] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '2520', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpmkw693yo', '--error-file', '/tmp/tmp685ye9on']
[2024-03-30 09:01:28,901] {standard_task_runner.py:77} INFO - Job 2520: Subtask download_dataset_task
[2024-03-30 09:01:28,815] {standard_task_runner.py:52} INFO - Started process 18109 to run task
[2024-03-30 09:01:29,196] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:01:29,441] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:01:29,571] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-30 09:01:29,572] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 09:01:29,573] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet > /opt/***/yellowtaxi_tripdata_2021-07.parquet']
[2024-03-30 09:01:29,666] {subprocess.py:85} INFO - Output:
[2024-03-30 09:01:35,832] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 09:01:36,366] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210702T060000, start_date=20240330T090128, end_date=20240330T090136
[2024-03-30 09:01:36,448] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:01:36,678] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 10:49:59,109] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 10:49:59,235] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 10:49:59,235] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:49:59,235] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 10:49:59,235] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:49:59,371] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-07-02 06:00:00+00:00
[2024-03-30 10:49:59,430] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '2630', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpb4tniva_', '--error-file', '/tmp/tmp8ohgyf2f']
[2024-03-30 10:49:59,476] {standard_task_runner.py:77} INFO - Job 2630: Subtask download_dataset_task
[2024-03-30 10:49:59,439] {standard_task_runner.py:52} INFO - Started process 23470 to run task
[2024-03-30 10:49:59,758] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 10:49:59,903] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 10:49:59,999] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-30 10:50:00,000] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 10:50:00,001] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet > /opt/***raw_data/yellowtaxi_tripdata_2021-07.parquet']
[2024-03-30 10:50:00,100] {subprocess.py:85} INFO - Output:
[2024-03-30 10:50:00,124] {subprocess.py:89} INFO - bash: /opt/***raw_data/yellowtaxi_tripdata_2021-07.parquet: No such file or directory
[2024-03-30 10:50:00,131] {subprocess.py:93} INFO - Command exited with return code 1
[2024-03-30 10:50:00,525] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:50:00,552] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210702T060000, start_date=20240330T104959, end_date=20240330T105000
[2024-03-30 10:50:00,670] {standard_task_runner.py:92} ERROR - Failed to execute job 2630 for task download_dataset_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:50:00,745] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 10:50:00,891] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 10:54:53,377] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 10:54:53,471] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 10:54:53,471] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:54:53,471] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 10:54:53,471] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:54:53,575] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-07-02 06:00:00+00:00
[2024-03-30 10:54:53,606] {standard_task_runner.py:52} INFO - Started process 23779 to run task
[2024-03-30 10:54:53,625] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '2648', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpilqa2cv6', '--error-file', '/tmp/tmpgkaoa0bf']
[2024-03-30 10:54:53,656] {standard_task_runner.py:77} INFO - Job 2648: Subtask download_dataset_task
[2024-03-30 10:54:53,890] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 10:54:54,070] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 10:54:54,192] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-30 10:54:54,194] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 10:54:54,206] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet > /opt/***raw_data/yellowtaxi_tripdata_2021-07.parquet']
[2024-03-30 10:54:54,260] {subprocess.py:85} INFO - Output:
[2024-03-30 10:54:54,298] {subprocess.py:89} INFO - bash: /opt/***raw_data/yellowtaxi_tripdata_2021-07.parquet: No such file or directory
[2024-03-30 10:54:54,299] {subprocess.py:93} INFO - Command exited with return code 1
[2024-03-30 10:54:54,351] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:54:54,392] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210702T060000, start_date=20240330T105453, end_date=20240330T105454
[2024-03-30 10:54:54,451] {standard_task_runner.py:92} ERROR - Failed to execute job 2648 for task download_dataset_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:54:54,485] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 10:54:54,651] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:03:56,978] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 11:03:57,071] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 11:03:57,071] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:03:57,071] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:03:57,071] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:03:57,147] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-07-02 06:00:00+00:00
[2024-03-30 11:03:57,191] {standard_task_runner.py:52} INFO - Started process 24343 to run task
[2024-03-30 11:03:57,260] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '2679', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpguq8ch8r', '--error-file', '/tmp/tmpovo83_ve']
[2024-03-30 11:03:57,320] {standard_task_runner.py:77} INFO - Job 2679: Subtask download_dataset_task
[2024-03-30 11:03:57,626] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:03:57,810] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:03:57,949] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-30 11:03:57,954] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:03:57,956] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-07.parquet']
[2024-03-30 11:03:58,070] {subprocess.py:85} INFO - Output:
[2024-03-30 11:04:03,818] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:04:04,049] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210702T060000, start_date=20240330T110356, end_date=20240330T110404
[2024-03-30 11:04:04,180] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:04:04,680] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:15:08,964] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 11:15:09,060] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 11:15:09,060] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:15:09,060] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:15:09,060] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:15:09,095] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-07-02 06:00:00+00:00
[2024-03-30 11:15:09,117] {standard_task_runner.py:52} INFO - Started process 25264 to run task
[2024-03-30 11:15:09,190] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '2726', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp_bd3j5jl', '--error-file', '/tmp/tmpnzylei6u']
[2024-03-30 11:15:09,198] {standard_task_runner.py:77} INFO - Job 2726: Subtask download_dataset_task
[2024-03-30 11:15:09,369] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:15:09,509] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:15:09,606] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-30 11:15:09,615] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:15:09,620] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-07.parquet']
[2024-03-30 11:15:09,707] {subprocess.py:85} INFO - Output:
[2024-03-30 11:15:15,345] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:15:15,507] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210702T060000, start_date=20240330T111508, end_date=20240330T111515
[2024-03-30 11:15:15,729] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:15:15,901] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:33:52,520] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 11:33:52,583] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-03-30 11:33:52,583] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:33:52,583] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:33:52,583] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:33:52,613] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-07-02 06:00:00+00:00
[2024-03-30 11:33:52,631] {standard_task_runner.py:52} INFO - Started process 26841 to run task
[2024-03-30 11:33:52,664] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '2802', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp0ber_unp', '--error-file', '/tmp/tmp4u2w3_bb']
[2024-03-30 11:33:52,681] {standard_task_runner.py:77} INFO - Job 2802: Subtask download_dataset_task
[2024-03-30 11:33:52,797] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:33:52,884] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:33:52,927] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-03-30 11:33:52,929] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:33:52,930] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-07.parquet']
[2024-03-30 11:33:53,041] {subprocess.py:85} INFO - Output:
[2024-03-30 11:33:58,826] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:33:58,964] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210702T060000, start_date=20240330T113352, end_date=20240330T113358
[2024-03-30 11:33:59,049] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:33:59,322] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-28 09:15:29,795] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:29,977] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:29,993] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:29,994] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-28 09:15:29,996] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:30,115] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-07-02 06:00:00+00:00
[2024-04-28 09:15:30,328] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '2996', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp1frcvd72', '--error-file', '/tmp/tmpofgebi68']
[2024-04-28 09:15:30,333] {standard_task_runner.py:77} INFO - Job 2996: Subtask download_dataset_task
[2024-04-28 09:15:30,221] {standard_task_runner.py:52} INFO - Started process 1383 to run task
[2024-04-28 09:15:30,649] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 6c6a4ca9ff8e
[2024-04-28 09:15:30,865] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-28 09:15:31,074] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-04-28 09:15:31,076] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-28 09:15:31,077] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-07.parquet']
[2024-04-28 09:15:31,247] {subprocess.py:85} INFO - Output:
[2024-04-28 09:15:35,736] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-28 09:15:35,872] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210702T060000, start_date=20240428T091529, end_date=20240428T091535
[2024-04-28 09:15:36,374] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-28 09:15:36,952] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:13:46,738] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-04-30 02:13:46,865] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-04-30 02:13:46,866] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:13:46,866] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-30 02:13:46,866] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:13:46,988] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-07-02 06:00:00+00:00
[2024-04-30 02:13:47,044] {standard_task_runner.py:52} INFO - Started process 313 to run task
[2024-04-30 02:13:47,106] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '3024', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpx2r8qehn', '--error-file', '/tmp/tmpqlx8un14']
[2024-04-30 02:13:47,150] {standard_task_runner.py:77} INFO - Job 3024: Subtask download_dataset_task
[2024-04-30 02:13:47,520] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host a1ae6a0259c5
[2024-04-30 02:13:47,763] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:13:47,882] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-04-30 02:13:47,883] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 02:13:47,884] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-07.parquet']
[2024-04-30 02:13:47,948] {subprocess.py:85} INFO - Output:
[2024-04-30 02:13:52,289] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 02:13:52,764] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210702T060000, start_date=20240430T021346, end_date=20240430T021352
[2024-04-30 02:13:52,899] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 02:13:53,204] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:58:12,616] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:12,750] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:12,750] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:12,750] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 02:58:12,750] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:12,850] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-07-02 06:00:00+00:00
[2024-04-30 02:58:12,908] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '3099', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpk0wy99m5', '--error-file', '/tmp/tmpc6ebhyys']
[2024-04-30 02:58:12,928] {standard_task_runner.py:77} INFO - Job 3099: Subtask download_dataset_task
[2024-04-30 02:58:12,889] {standard_task_runner.py:52} INFO - Started process 395 to run task
[2024-04-30 02:58:13,173] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 02:58:13,349] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:58:13,408] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-04-30 02:58:13,410] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 02:58:13,412] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-07.parquet']
[2024-04-30 02:58:13,477] {subprocess.py:85} INFO - Output:
[2024-04-30 02:58:17,226] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 02:58:17,400] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210702T060000, start_date=20240430T025812, end_date=20240430T025817
[2024-04-30 02:58:17,476] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 02:58:17,638] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:01:04,525] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:04,721] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:04,722] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:04,722] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:01:04,722] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:04,825] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-07-02 06:00:00+00:00
[2024-04-30 03:01:04,854] {standard_task_runner.py:52} INFO - Started process 657 to run task
[2024-04-30 03:01:04,893] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '3130', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpc5vpyu0m', '--error-file', '/tmp/tmpo_ds3xi5']
[2024-04-30 03:01:04,954] {standard_task_runner.py:77} INFO - Job 3130: Subtask download_dataset_task
[2024-04-30 03:01:05,287] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:01:05,560] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:01:05,622] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-04-30 03:01:05,630] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 03:01:05,633] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet > /opt/***/cleaned_data/yellowtaxi_tripdata_2021-07.parquet']
[2024-04-30 03:01:05,734] {subprocess.py:85} INFO - Output:
[2024-04-30 03:01:09,850] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 03:01:09,974] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210702T060000, start_date=20240430T030104, end_date=20240430T030109
[2024-04-30 03:01:10,067] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:01:10,151] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:30:00,579] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-04-30 04:30:00,618] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [queued]>
[2024-04-30 04:30:00,618] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:30:00,618] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:30:00,618] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:30:00,668] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-07-02 06:00:00+00:00
[2024-04-30 04:30:00,685] {standard_task_runner.py:52} INFO - Started process 5183 to run task
[2024-04-30 04:30:00,705] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-07-02T06:00:00+00:00', '--job-id', '3241', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp0u3hjulh', '--error-file', '/tmp/tmplhtqmy7_']
[2024-04-30 04:30:00,729] {standard_task_runner.py:77} INFO - Job 3241: Subtask download_dataset_task
[2024-04-30 04:30:00,920] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-07-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:30:01,066] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:30:01,246] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-07-02T06:00:00+00:00
[2024-04-30 04:30:01,248] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 04:30:01,259] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-07.parquet']
[2024-04-30 04:30:01,341] {subprocess.py:85} INFO - Output:
[2024-04-30 04:30:05,514] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 04:30:05,619] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210702T060000, start_date=20240430T043000, end_date=20240430T043005
[2024-04-30 04:30:05,867] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 04:30:05,961] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
