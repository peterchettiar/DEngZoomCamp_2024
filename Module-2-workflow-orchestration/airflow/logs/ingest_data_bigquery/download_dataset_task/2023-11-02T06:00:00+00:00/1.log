[2024-03-30 03:54:00,263] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-11-02T06:00:00+00:00 [queued]>
[2024-03-30 03:54:00,318] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-11-02T06:00:00+00:00 [queued]>
[2024-03-30 03:54:00,318] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:54:00,318] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:54:00,318] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:54:00,374] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-11-02 06:00:00+00:00
[2024-03-30 03:54:00,400] {standard_task_runner.py:52} INFO - Started process 2246 to run task
[2024-03-30 03:54:00,424] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-11-02T06:00:00+00:00', '--job-id', '2025', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpq23c2173', '--error-file', '/tmp/tmpg5dpu79q']
[2024-03-30 03:54:00,435] {standard_task_runner.py:77} INFO - Job 2025: Subtask download_dataset_task
[2024-03-30 03:54:00,584] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-11-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:54:00,726] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:54:00,838] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-11-02T06:00:00+00:00
[2024-03-30 03:54:00,842] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:54:00,844] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-11.parquet > /opt/***/yellowtaxi_tripdata_2023-11.parquet']
[2024-03-30 03:54:00,906] {subprocess.py:85} INFO - Output:
[2024-03-30 03:54:08,000] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:54:08,201] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20231102T060000, start_date=20240330T035400, end_date=20240330T035408
[2024-03-30 03:54:08,278] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:54:08,335] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:26:08,679] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-11-02T06:00:00+00:00 [queued]>
[2024-03-30 04:26:08,719] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-11-02T06:00:00+00:00 [queued]>
[2024-03-30 04:26:08,719] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:26:08,719] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:26:08,719] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:26:08,755] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-11-02 06:00:00+00:00
[2024-03-30 04:26:08,772] {standard_task_runner.py:52} INFO - Started process 4542 to run task
[2024-03-30 04:26:08,789] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-11-02T06:00:00+00:00', '--job-id', '2251', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpd_8pnfsu', '--error-file', '/tmp/tmpwikoveyc']
[2024-03-30 04:26:08,801] {standard_task_runner.py:77} INFO - Job 2251: Subtask download_dataset_task
[2024-03-30 04:26:08,904] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-11-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:26:08,993] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:26:09,047] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-11-02T06:00:00+00:00
[2024-03-30 04:26:09,049] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:26:09,050] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-11.parquet > /opt/***/yellowtaxi_tripdata_2023-11.parquet']
[2024-03-30 04:26:09,094] {subprocess.py:85} INFO - Output:
[2024-03-30 04:26:16,081] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:26:16,116] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20231102T060000, start_date=20240330T042608, end_date=20240330T042616
[2024-03-30 04:26:16,148] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:26:16,191] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:44:57,445] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-11-02T06:00:00+00:00 [queued]>
[2024-03-30 04:44:57,539] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-11-02T06:00:00+00:00 [queued]>
[2024-03-30 04:44:57,539] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:44:57,539] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:44:57,543] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:44:57,632] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-11-02 06:00:00+00:00
[2024-03-30 04:44:57,698] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-11-02T06:00:00+00:00', '--job-id', '2361', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp6u7pekly', '--error-file', '/tmp/tmp4hjk5k1i']
[2024-03-30 04:44:57,729] {standard_task_runner.py:77} INFO - Job 2361: Subtask download_dataset_task
[2024-03-30 04:44:57,671] {standard_task_runner.py:52} INFO - Started process 5796 to run task
[2024-03-30 04:44:57,884] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-11-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:44:58,023] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:44:58,092] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-11-02T06:00:00+00:00
[2024-03-30 04:44:58,099] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:44:58,101] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-11.parquet > /opt/***/yellowtaxi_tripdata_2023-11.parquet']
[2024-03-30 04:44:58,190] {subprocess.py:85} INFO - Output:
[2024-03-30 04:45:04,809] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:45:04,940] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20231102T060000, start_date=20240330T044457, end_date=20240330T044504
[2024-03-30 04:45:05,068] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:45:05,189] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 05:00:41,646] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-11-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:41,688] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-11-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:41,689] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:41,689] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 05:00:41,689] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:41,740] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-11-02 06:00:00+00:00
[2024-03-30 05:00:41,760] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-11-02T06:00:00+00:00', '--job-id', '2494', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp7p50pr4d', '--error-file', '/tmp/tmpyuyktsnk']
[2024-03-30 05:00:41,766] {standard_task_runner.py:77} INFO - Job 2494: Subtask download_dataset_task
[2024-03-30 05:00:41,753] {standard_task_runner.py:52} INFO - Started process 6971 to run task
[2024-03-30 05:00:41,872] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-11-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 05:00:41,929] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 05:00:41,969] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-11-02T06:00:00+00:00
[2024-03-30 05:00:41,971] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 05:00:41,972] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-11.parquet > /opt/***/yellowtaxi_tripdata_2023-11.parquet']
[2024-03-30 05:00:41,987] {subprocess.py:85} INFO - Output:
[2024-03-30 05:00:48,407] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 05:00:48,491] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20231102T060000, start_date=20240330T050041, end_date=20240330T050048
[2024-03-30 05:00:48,558] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 05:00:48,620] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:03:26,182] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-11-02T06:00:00+00:00 [queued]>
[2024-03-30 09:03:26,204] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-11-02T06:00:00+00:00 [queued]>
[2024-03-30 09:03:26,205] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:03:26,205] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:03:26,206] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:03:26,230] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-11-02 06:00:00+00:00
[2024-03-30 09:03:26,245] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-11-02T06:00:00+00:00', '--job-id', '2612', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpo1f4wrk0', '--error-file', '/tmp/tmpljgod5i1']
[2024-03-30 09:03:26,251] {standard_task_runner.py:77} INFO - Job 2612: Subtask download_dataset_task
[2024-03-30 09:03:26,239] {standard_task_runner.py:52} INFO - Started process 18524 to run task
[2024-03-30 09:03:26,319] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-11-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:03:26,371] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:03:26,401] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-11-02T06:00:00+00:00
[2024-03-30 09:03:26,403] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 09:03:26,404] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-11.parquet > /opt/***/yellowtaxi_tripdata_2023-11.parquet']
[2024-03-30 09:03:26,424] {subprocess.py:85} INFO - Output:
[2024-03-30 09:03:32,971] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 09:03:33,034] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20231102T060000, start_date=20240330T090326, end_date=20240330T090333
[2024-03-30 09:03:33,075] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:03:33,147] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 12:07:32,436] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-11-02T06:00:00+00:00 [queued]>
[2024-03-30 12:07:32,455] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-11-02T06:00:00+00:00 [queued]>
[2024-03-30 12:07:32,456] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 12:07:32,457] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 12:07:32,457] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 12:07:32,481] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-11-02 06:00:00+00:00
[2024-03-30 12:07:32,490] {standard_task_runner.py:52} INFO - Started process 29476 to run task
[2024-03-30 12:07:32,510] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-11-02T06:00:00+00:00', '--job-id', '2940', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpwpwybn41', '--error-file', '/tmp/tmpt30r5yyh']
[2024-03-30 12:07:32,515] {standard_task_runner.py:77} INFO - Job 2940: Subtask download_dataset_task
[2024-03-30 12:07:32,601] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-11-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 12:07:32,657] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 12:07:32,692] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-11-02T06:00:00+00:00
[2024-03-30 12:07:32,698] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 12:07:32,699] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-11.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2023-11.parquet']
[2024-03-30 12:07:32,717] {subprocess.py:85} INFO - Output:
[2024-03-30 12:07:39,342] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 12:07:39,384] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20231102T060000, start_date=20240330T120732, end_date=20240330T120739
[2024-03-30 12:07:39,423] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 12:07:39,467] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:02:28,393] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-11-02T06:00:00+00:00 [queued]>
[2024-04-30 03:02:28,433] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-11-02T06:00:00+00:00 [queued]>
[2024-04-30 03:02:28,434] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:02:28,434] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:02:28,435] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:02:28,453] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-11-02 06:00:00+00:00
[2024-04-30 03:02:28,472] {standard_task_runner.py:52} INFO - Started process 1038 to run task
[2024-04-30 03:02:28,488] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-11-02T06:00:00+00:00', '--job-id', '3220', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpe89os4fm', '--error-file', '/tmp/tmpqqu60bwr']
[2024-04-30 03:02:28,494] {standard_task_runner.py:77} INFO - Job 3220: Subtask download_dataset_task
[2024-04-30 03:02:28,665] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-11-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:02:28,741] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:02:28,783] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-11-02T06:00:00+00:00
[2024-04-30 03:02:28,785] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 03:02:28,787] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-11.parquet > /opt/***/cleaned_data/yellowtaxi_tripdata_2023-11.parquet']
[2024-04-30 03:02:28,810] {subprocess.py:85} INFO - Output:
[2024-04-30 03:02:33,818] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 03:02:34,072] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20231102T060000, start_date=20240430T030228, end_date=20240430T030234
[2024-04-30 03:02:34,138] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:02:34,235] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:35:34,528] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-11-02T06:00:00+00:00 [queued]>
[2024-04-30 04:35:34,552] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-11-02T06:00:00+00:00 [queued]>
[2024-04-30 04:35:34,552] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:35:34,553] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:35:34,553] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:35:34,574] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-11-02 06:00:00+00:00
[2024-04-30 04:35:34,591] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-11-02T06:00:00+00:00', '--job-id', '3323', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpqrsg0e8d', '--error-file', '/tmp/tmprim3m56a']
[2024-04-30 04:35:34,597] {standard_task_runner.py:77} INFO - Job 3323: Subtask download_dataset_task
[2024-04-30 04:35:34,585] {standard_task_runner.py:52} INFO - Started process 5901 to run task
[2024-04-30 04:35:34,711] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-11-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:35:34,787] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:35:34,826] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-11-02T06:00:00+00:00
[2024-04-30 04:35:34,827] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 04:35:34,828] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-11.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2023-11.parquet']
[2024-04-30 04:35:34,848] {subprocess.py:85} INFO - Output:
[2024-04-30 04:35:39,448] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 04:35:39,506] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20231102T060000, start_date=20240430T043534, end_date=20240430T043539
[2024-04-30 04:35:39,571] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 04:35:39,652] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
