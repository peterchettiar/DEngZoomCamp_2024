[2024-03-29 08:27:23,782] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [queued]>
[2024-03-29 08:27:23,891] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [queued]>
[2024-03-29 08:27:23,891] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:27:23,891] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:27:23,892] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:27:24,045] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-08-02 06:00:00+00:00
[2024-03-29 08:27:24,075] {standard_task_runner.py:52} INFO - Started process 1583 to run task
[2024-03-29 08:27:24,154] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-08-02T06:00:00+00:00', '--job-id', '1781', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpgxpduno3', '--error-file', '/tmp/tmp2pmlqh65']
[2024-03-29 08:27:24,162] {standard_task_runner.py:77} INFO - Job 1781: Subtask download_dataset_task
[2024-03-29 08:27:24,561] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:27:24,680] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:27:24,742] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-08-02T06:00:00+00:00
[2024-03-29 08:27:24,743] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:27:24,745] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-08.parquet > /opt/***/yellowtaxi_tripdata_2023-08.parquet']
[2024-03-29 08:27:24,810] {subprocess.py:85} INFO - Output:
[2024-03-29 08:27:31,152] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:27:31,371] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230802T060000, start_date=20240329T082723, end_date=20240329T082731
[2024-03-29 08:27:31,493] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:27:31,653] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:53:26,961] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [queued]>
[2024-03-30 03:53:27,041] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [queued]>
[2024-03-30 03:53:27,042] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:53:27,042] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:53:27,042] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:53:27,114] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-08-02 06:00:00+00:00
[2024-03-30 03:53:27,152] {standard_task_runner.py:52} INFO - Started process 2118 to run task
[2024-03-30 03:53:27,177] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-08-02T06:00:00+00:00', '--job-id', '1992', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpqg7t0n75', '--error-file', '/tmp/tmplxv0bd5g']
[2024-03-30 03:53:27,208] {standard_task_runner.py:77} INFO - Job 1992: Subtask download_dataset_task
[2024-03-30 03:53:27,607] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:53:27,814] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:53:27,896] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-08-02T06:00:00+00:00
[2024-03-30 03:53:27,898] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:53:27,900] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-08.parquet > /opt/***/yellowtaxi_tripdata_2023-08.parquet']
[2024-03-30 03:53:27,925] {subprocess.py:85} INFO - Output:
[2024-03-30 03:53:34,580] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:53:34,887] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230802T060000, start_date=20240330T035326, end_date=20240330T035334
[2024-03-30 03:53:34,956] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:53:35,107] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:19:03,747] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [queued]>
[2024-03-30 04:19:03,797] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [queued]>
[2024-03-30 04:19:03,797] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:19:03,798] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:19:03,799] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:19:04,042] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-08-02 06:00:00+00:00
[2024-03-30 04:19:04,108] {standard_task_runner.py:52} INFO - Started process 3793 to run task
[2024-03-30 04:19:04,138] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-08-02T06:00:00+00:00', '--job-id', '2137', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmphaskbitg', '--error-file', '/tmp/tmpz82voam8']
[2024-03-30 04:19:04,153] {standard_task_runner.py:77} INFO - Job 2137: Subtask download_dataset_task
[2024-03-30 04:19:04,879] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:19:05,602] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:19:05,656] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-08-02T06:00:00+00:00
[2024-03-30 04:19:05,662] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:19:05,665] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-08.parquet > /opt/***/yellowtaxi_tripdata_2023-08.parquet']
[2024-03-30 04:19:05,746] {subprocess.py:85} INFO - Output:
[2024-03-30 04:19:12,004] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:19:12,092] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230802T060000, start_date=20240330T041903, end_date=20240330T041912
[2024-03-30 04:19:12,240] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:19:12,336] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:25:34,470] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [queued]>
[2024-03-30 04:25:34,518] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [queued]>
[2024-03-30 04:25:34,522] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:25:34,522] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:25:34,524] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:25:34,584] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-08-02 06:00:00+00:00
[2024-03-30 04:25:34,656] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-08-02T06:00:00+00:00', '--job-id', '2216', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp_p74evqa', '--error-file', '/tmp/tmpvl5ufatv']
[2024-03-30 04:25:34,674] {standard_task_runner.py:77} INFO - Job 2216: Subtask download_dataset_task
[2024-03-30 04:25:34,626] {standard_task_runner.py:52} INFO - Started process 4400 to run task
[2024-03-30 04:25:34,880] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:25:35,038] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:25:35,101] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-08-02T06:00:00+00:00
[2024-03-30 04:25:35,110] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:25:35,112] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-08.parquet > /opt/***/yellowtaxi_tripdata_2023-08.parquet']
[2024-03-30 04:25:35,169] {subprocess.py:85} INFO - Output:
[2024-03-30 04:25:41,238] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:25:41,416] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230802T060000, start_date=20240330T042534, end_date=20240330T042541
[2024-03-30 04:25:41,654] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:25:41,971] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:44:52,679] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [queued]>
[2024-03-30 04:44:52,778] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [queued]>
[2024-03-30 04:44:52,779] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:44:52,779] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:44:52,779] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:44:53,223] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-08-02 06:00:00+00:00
[2024-03-30 04:44:53,942] {standard_task_runner.py:52} INFO - Started process 5778 to run task
[2024-03-30 04:44:54,507] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-08-02T06:00:00+00:00', '--job-id', '2359', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpxsrppnjy', '--error-file', '/tmp/tmp8aq82_pc']
[2024-03-30 04:44:55,175] {standard_task_runner.py:77} INFO - Job 2359: Subtask download_dataset_task
[2024-03-30 04:44:56,227] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:44:56,469] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:44:56,585] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-08-02T06:00:00+00:00
[2024-03-30 04:44:56,597] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:44:56,605] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-08.parquet > /opt/***/yellowtaxi_tripdata_2023-08.parquet']
[2024-03-30 04:44:56,694] {subprocess.py:85} INFO - Output:
[2024-03-30 04:45:02,819] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:45:02,934] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230802T060000, start_date=20240330T044452, end_date=20240330T044502
[2024-03-30 04:45:03,063] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:45:03,535] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 05:00:40,610] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:40,667] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:40,667] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:40,667] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 05:00:40,667] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:40,705] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-08-02 06:00:00+00:00
[2024-03-30 05:00:40,716] {standard_task_runner.py:52} INFO - Started process 6956 to run task
[2024-03-30 05:00:40,753] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-08-02T06:00:00+00:00', '--job-id', '2491', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpdcztflyg', '--error-file', '/tmp/tmp5k2asbtb']
[2024-03-30 05:00:40,769] {standard_task_runner.py:77} INFO - Job 2491: Subtask download_dataset_task
[2024-03-30 05:00:40,905] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 05:00:41,000] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 05:00:41,049] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-08-02T06:00:00+00:00
[2024-03-30 05:00:41,051] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 05:00:41,052] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-08.parquet > /opt/***/yellowtaxi_tripdata_2023-08.parquet']
[2024-03-30 05:00:41,102] {subprocess.py:85} INFO - Output:
[2024-03-30 05:00:47,037] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 05:00:47,090] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230802T060000, start_date=20240330T050040, end_date=20240330T050047
[2024-03-30 05:00:47,170] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 05:00:47,228] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:02:23,189] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [queued]>
[2024-03-30 09:02:23,238] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [queued]>
[2024-03-30 09:02:23,242] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:02:23,243] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:02:23,244] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:02:23,268] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-08-02 06:00:00+00:00
[2024-03-30 09:02:23,288] {standard_task_runner.py:52} INFO - Started process 18371 to run task
[2024-03-30 09:02:23,316] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-08-02T06:00:00+00:00', '--job-id', '2576', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpkspag3a_', '--error-file', '/tmp/tmpcz3ceoh9']
[2024-03-30 09:02:23,332] {standard_task_runner.py:77} INFO - Job 2576: Subtask download_dataset_task
[2024-03-30 09:02:23,656] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:02:23,925] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:02:24,052] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-08-02T06:00:00+00:00
[2024-03-30 09:02:24,060] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 09:02:24,065] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-08.parquet > /opt/***/yellowtaxi_tripdata_2023-08.parquet']
[2024-03-30 09:02:24,162] {subprocess.py:85} INFO - Output:
[2024-03-30 09:02:30,821] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 09:02:31,591] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230802T060000, start_date=20240330T090223, end_date=20240330T090231
[2024-03-30 09:02:32,415] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:02:33,295] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 12:07:01,104] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [queued]>
[2024-03-30 12:07:01,151] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [queued]>
[2024-03-30 12:07:01,151] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 12:07:01,152] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 12:07:01,152] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 12:07:01,184] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-08-02 06:00:00+00:00
[2024-03-30 12:07:01,193] {standard_task_runner.py:52} INFO - Started process 29351 to run task
[2024-03-30 12:07:01,205] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-08-02T06:00:00+00:00', '--job-id', '2931', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpqjbae0v3', '--error-file', '/tmp/tmpa_61zpm8']
[2024-03-30 12:07:01,227] {standard_task_runner.py:77} INFO - Job 2931: Subtask download_dataset_task
[2024-03-30 12:07:01,375] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 12:07:01,462] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 12:07:01,522] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-08-02T06:00:00+00:00
[2024-03-30 12:07:01,524] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 12:07:01,525] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-08.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2023-08.parquet']
[2024-03-30 12:07:01,557] {subprocess.py:85} INFO - Output:
[2024-03-30 12:07:07,529] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 12:07:07,569] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230802T060000, start_date=20240330T120701, end_date=20240330T120707
[2024-03-30 12:07:07,595] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 12:07:07,645] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:02:27,417] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [queued]>
[2024-04-30 03:02:27,466] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [queued]>
[2024-04-30 03:02:27,466] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:02:27,467] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:02:27,467] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:02:27,494] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-08-02 06:00:00+00:00
[2024-04-30 03:02:27,507] {standard_task_runner.py:52} INFO - Started process 1027 to run task
[2024-04-30 03:02:27,531] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-08-02T06:00:00+00:00', '--job-id', '3217', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpggm3a2la', '--error-file', '/tmp/tmpzfg1o9ut']
[2024-04-30 03:02:27,537] {standard_task_runner.py:77} INFO - Job 3217: Subtask download_dataset_task
[2024-04-30 03:02:27,679] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:02:27,773] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:02:27,830] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-08-02T06:00:00+00:00
[2024-04-30 03:02:27,832] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 03:02:27,833] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-08.parquet > /opt/***/cleaned_data/yellowtaxi_tripdata_2023-08.parquet']
[2024-04-30 03:02:27,895] {subprocess.py:85} INFO - Output:
[2024-04-30 03:02:32,479] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 03:02:32,524] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230802T060000, start_date=20240430T030227, end_date=20240430T030232
[2024-04-30 03:02:32,602] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:02:32,658] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:35:05,072] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [queued]>
[2024-04-30 04:35:05,086] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [queued]>
[2024-04-30 04:35:05,087] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:35:05,087] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:35:05,088] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:35:05,100] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-08-02 06:00:00+00:00
[2024-04-30 04:35:05,114] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-08-02T06:00:00+00:00', '--job-id', '3311', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpg4hfhfj0', '--error-file', '/tmp/tmp2mlj10_o']
[2024-04-30 04:35:05,108] {standard_task_runner.py:52} INFO - Started process 5798 to run task
[2024-04-30 04:35:05,121] {standard_task_runner.py:77} INFO - Job 3311: Subtask download_dataset_task
[2024-04-30 04:35:05,223] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-08-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:35:05,296] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:35:05,335] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-08-02T06:00:00+00:00
[2024-04-30 04:35:05,337] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 04:35:05,338] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-08.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2023-08.parquet']
[2024-04-30 04:35:05,360] {subprocess.py:85} INFO - Output:
[2024-04-30 04:35:10,136] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 04:35:10,445] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230802T060000, start_date=20240430T043505, end_date=20240430T043510
[2024-04-30 04:35:10,519] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 04:35:10,595] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
