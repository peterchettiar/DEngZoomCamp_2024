[2024-03-29 07:24:27,468] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:27,502] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:27,502] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:27,502] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:24:27,502] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:27,543] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-09-02 06:00:00+00:00
[2024-03-29 07:24:27,559] {standard_task_runner.py:52} INFO - Started process 493 to run task
[2024-03-29 07:24:27,582] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-09-02T06:00:00+00:00', '--job-id', '1444', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpkallqfrj', '--error-file', '/tmp/tmpc_2uirq0']
[2024-03-29 07:24:27,608] {standard_task_runner.py:77} INFO - Job 1444: Subtask download_dataset_task
[2024-03-29 07:24:27,813] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:24:27,959] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:24:28,113] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-09-02T06:00:00+00:00
[2024-03-29 07:24:28,115] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:24:28,116] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet > /opt/***/yellowtaxi_tripdata_2021-09.parquet']
[2024-03-29 07:24:28,195] {subprocess.py:85} INFO - Output:
[2024-03-29 07:24:34,102] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:24:34,245] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210902T060000, start_date=20240329T072427, end_date=20240329T072434
[2024-03-29 07:24:34,387] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:24:34,627] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:30:46,854] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-29 07:30:46,891] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-29 07:30:46,892] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:30:46,894] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:30:46,894] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:30:46,935] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-09-02 06:00:00+00:00
[2024-03-29 07:30:46,951] {standard_task_runner.py:52} INFO - Started process 1007 to run task
[2024-03-29 07:30:46,966] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-09-02T06:00:00+00:00', '--job-id', '1507', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpcbyvuynt', '--error-file', '/tmp/tmpgykf0lr_']
[2024-03-29 07:30:46,991] {standard_task_runner.py:77} INFO - Job 1507: Subtask download_dataset_task
[2024-03-29 07:30:47,151] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:30:47,237] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:30:47,289] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-09-02T06:00:00+00:00
[2024-03-29 07:30:47,294] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:30:47,295] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet > /opt/***/yellowtaxi_tripdata_2021-09.parquet']
[2024-03-29 07:30:47,367] {subprocess.py:85} INFO - Output:
[2024-03-29 07:30:53,554] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:30:54,288] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210902T060000, start_date=20240329T073046, end_date=20240329T073054
[2024-03-29 07:30:54,476] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:30:55,528] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:37:31,629] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:31,737] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:31,747] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:31,749] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:37:31,752] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:31,815] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-09-02 06:00:00+00:00
[2024-03-29 07:37:31,868] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-09-02T06:00:00+00:00', '--job-id', '1569', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp5b5gmsz8', '--error-file', '/tmp/tmp0ffxg795']
[2024-03-29 07:37:31,897] {standard_task_runner.py:77} INFO - Job 1569: Subtask download_dataset_task
[2024-03-29 07:37:31,850] {standard_task_runner.py:52} INFO - Started process 1543 to run task
[2024-03-29 07:37:32,338] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:37:32,445] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:37:32,504] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-09-02T06:00:00+00:00
[2024-03-29 07:37:32,507] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:37:32,508] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet > /opt/***/yellowtaxi_tripdata_2021-09.parquet']
[2024-03-29 07:37:32,563] {subprocess.py:85} INFO - Output:
[2024-03-29 07:37:38,594] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:37:39,135] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210902T060000, start_date=20240329T073731, end_date=20240329T073739
[2024-03-29 07:37:39,289] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:37:39,444] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:08:28,405] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:28,456] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:28,456] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:28,456] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:08:28,456] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:28,527] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-09-02 06:00:00+00:00
[2024-03-29 08:08:28,633] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-09-02T06:00:00+00:00', '--job-id', '1629', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpt5q4f9p9', '--error-file', '/tmp/tmpesi3wkjx']
[2024-03-29 08:08:28,546] {standard_task_runner.py:52} INFO - Started process 193 to run task
[2024-03-29 08:08:28,684] {standard_task_runner.py:77} INFO - Job 1629: Subtask download_dataset_task
[2024-03-29 08:08:29,150] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:08:29,453] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:08:29,583] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-09-02T06:00:00+00:00
[2024-03-29 08:08:29,585] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:08:29,586] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet > /opt/***/yellowtaxi_tripdata_2021-09.parquet']
[2024-03-29 08:08:29,677] {subprocess.py:85} INFO - Output:
[2024-03-29 08:08:35,436] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:08:35,551] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210902T060000, start_date=20240329T080828, end_date=20240329T080835
[2024-03-29 08:08:35,739] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:08:36,295] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:10:57,940] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-29 08:10:58,016] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-29 08:10:58,022] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:10:58,023] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:10:58,023] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:10:58,097] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-09-02 06:00:00+00:00
[2024-03-29 08:10:58,124] {standard_task_runner.py:52} INFO - Started process 503 to run task
[2024-03-29 08:10:58,157] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-09-02T06:00:00+00:00', '--job-id', '1677', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpzc_y69nx', '--error-file', '/tmp/tmp1n1svjx4']
[2024-03-29 08:10:58,182] {standard_task_runner.py:77} INFO - Job 1677: Subtask download_dataset_task
[2024-03-29 08:10:58,419] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:10:58,633] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:10:58,766] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-09-02T06:00:00+00:00
[2024-03-29 08:10:58,768] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:10:58,770] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet > /opt/***/yellowtaxi_tripdata_2021-09.parquet']
[2024-03-29 08:10:58,816] {subprocess.py:85} INFO - Output:
[2024-03-29 08:11:05,042] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:11:05,331] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210902T060000, start_date=20240329T081057, end_date=20240329T081105
[2024-03-29 08:11:05,528] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:11:06,394] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:30:05,306] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:05,459] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:05,459] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:05,459] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:30:05,459] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:05,571] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-09-02 06:00:00+00:00
[2024-03-30 03:30:05,621] {standard_task_runner.py:52} INFO - Started process 456 to run task
[2024-03-30 03:30:05,662] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-09-02T06:00:00+00:00', '--job-id', '1822', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpwntlg38j', '--error-file', '/tmp/tmpj4wccnwu']
[2024-03-30 03:30:05,685] {standard_task_runner.py:77} INFO - Job 1822: Subtask download_dataset_task
[2024-03-30 03:30:05,973] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:30:06,097] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:30:06,183] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-09-02T06:00:00+00:00
[2024-03-30 03:30:06,184] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:30:06,185] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet > /opt/***/yellowtaxi_tripdata_2021-09.parquet']
[2024-03-30 03:30:06,257] {subprocess.py:85} INFO - Output:
[2024-03-30 03:30:12,166] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:30:12,659] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210902T060000, start_date=20240330T033005, end_date=20240330T033012
[2024-03-30 03:30:12,867] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:30:13,046] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:41:57,896] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-30 03:41:57,961] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-30 03:41:57,962] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:41:57,962] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:41:57,962] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:41:58,020] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-09-02 06:00:00+00:00
[2024-03-30 03:41:58,075] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-09-02T06:00:00+00:00', '--job-id', '1901', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpq7msjmmu', '--error-file', '/tmp/tmp6blk07tw']
[2024-03-30 03:41:58,100] {standard_task_runner.py:77} INFO - Job 1901: Subtask download_dataset_task
[2024-03-30 03:41:58,061] {standard_task_runner.py:52} INFO - Started process 1282 to run task
[2024-03-30 03:41:58,266] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:41:58,364] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:41:58,445] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-09-02T06:00:00+00:00
[2024-03-30 03:41:58,447] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:41:58,447] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet > /opt/***/yellowtaxi_tripdata_2021-09.parquet']
[2024-03-30 03:41:58,571] {subprocess.py:85} INFO - Output:
[2024-03-30 03:42:04,497] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:42:04,985] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210902T060000, start_date=20240330T034157, end_date=20240330T034204
[2024-03-30 03:42:05,211] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:42:05,405] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:18:08,584] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:08,708] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:08,708] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:08,711] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:18:08,711] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:08,848] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-09-02 06:00:00+00:00
[2024-03-30 04:18:08,901] {standard_task_runner.py:52} INFO - Started process 3531 to run task
[2024-03-30 04:18:09,001] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-09-02T06:00:00+00:00', '--job-id', '2082', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpfeger1jb', '--error-file', '/tmp/tmpc0f3eobi']
[2024-03-30 04:18:09,058] {standard_task_runner.py:77} INFO - Job 2082: Subtask download_dataset_task
[2024-03-30 04:18:09,549] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:18:09,848] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:18:09,965] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-09-02T06:00:00+00:00
[2024-03-30 04:18:09,966] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:18:09,967] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet > /opt/***/yellowtaxi_tripdata_2021-09.parquet']
[2024-03-30 04:18:10,082] {subprocess.py:85} INFO - Output:
[2024-03-30 04:18:16,373] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:18:16,577] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210902T060000, start_date=20240330T041808, end_date=20240330T041816
[2024-03-30 04:18:16,877] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:18:17,129] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:24:44,727] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-30 04:24:44,813] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-30 04:24:44,813] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:24:44,819] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:24:44,820] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:24:44,908] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-09-02 06:00:00+00:00
[2024-03-30 04:24:44,940] {standard_task_runner.py:52} INFO - Started process 4154 to run task
[2024-03-30 04:24:44,956] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-09-02T06:00:00+00:00', '--job-id', '2162', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp6dn5jcux', '--error-file', '/tmp/tmps9o22zq8']
[2024-03-30 04:24:45,010] {standard_task_runner.py:77} INFO - Job 2162: Subtask download_dataset_task
[2024-03-30 04:24:45,230] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:24:45,314] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:24:45,413] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-09-02T06:00:00+00:00
[2024-03-30 04:24:45,415] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:24:45,415] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet > /opt/***/yellowtaxi_tripdata_2021-09.parquet']
[2024-03-30 04:24:45,444] {subprocess.py:85} INFO - Output:
[2024-03-30 04:24:51,462] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:24:51,586] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210902T060000, start_date=20240330T042444, end_date=20240330T042451
[2024-03-30 04:24:51,711] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:24:51,867] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:38:34,035] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-30 04:38:34,391] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-30 04:38:34,391] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:38:34,391] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:38:34,391] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:38:34,519] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-09-02 06:00:00+00:00
[2024-03-30 04:38:34,544] {standard_task_runner.py:52} INFO - Started process 5172 to run task
[2024-03-30 04:38:34,571] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-09-02T06:00:00+00:00', '--job-id', '2269', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpga0wcujv', '--error-file', '/tmp/tmpft74zfr3']
[2024-03-30 04:38:34,585] {standard_task_runner.py:77} INFO - Job 2269: Subtask download_dataset_task
[2024-03-30 04:38:34,734] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:38:34,818] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:38:34,871] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-09-02T06:00:00+00:00
[2024-03-30 04:38:34,875] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:38:34,876] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet > /opt/***/yellowtaxi_tripdata_2021-09.parquet']
[2024-03-30 04:38:34,924] {subprocess.py:85} INFO - Output:
[2024-03-30 04:38:41,382] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:38:41,477] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210902T060000, start_date=20240330T043834, end_date=20240330T043841
[2024-03-30 04:38:41,570] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:38:41,705] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:59:24,696] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:24,795] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:24,796] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:24,796] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:59:24,796] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:24,919] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-09-02 06:00:00+00:00
[2024-03-30 04:59:24,980] {standard_task_runner.py:52} INFO - Started process 6602 to run task
[2024-03-30 04:59:25,040] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-09-02T06:00:00+00:00', '--job-id', '2406', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpaulfiyif', '--error-file', '/tmp/tmp1_6nk75f']
[2024-03-30 04:59:25,088] {standard_task_runner.py:77} INFO - Job 2406: Subtask download_dataset_task
[2024-03-30 04:59:25,459] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:59:25,581] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:59:25,643] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-09-02T06:00:00+00:00
[2024-03-30 04:59:25,645] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:59:25,647] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet > /opt/***/yellowtaxi_tripdata_2021-09.parquet']
[2024-03-30 04:59:25,829] {subprocess.py:85} INFO - Output:
[2024-03-30 04:59:31,675] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:59:31,793] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210902T060000, start_date=20240330T045924, end_date=20240330T045931
[2024-03-30 04:59:31,881] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:59:32,024] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:01:31,288] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:31,441] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:31,450] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:31,455] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:01:31,455] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:31,597] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-09-02 06:00:00+00:00
[2024-03-30 09:01:31,637] {standard_task_runner.py:52} INFO - Started process 18128 to run task
[2024-03-30 09:01:31,724] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-09-02T06:00:00+00:00', '--job-id', '2523', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpx9d2w_vw', '--error-file', '/tmp/tmp09fum6k7']
[2024-03-30 09:01:31,812] {standard_task_runner.py:77} INFO - Job 2523: Subtask download_dataset_task
[2024-03-30 09:01:32,447] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:01:32,760] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:01:32,880] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-09-02T06:00:00+00:00
[2024-03-30 09:01:32,884] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 09:01:32,892] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet > /opt/***/yellowtaxi_tripdata_2021-09.parquet']
[2024-03-30 09:01:33,003] {subprocess.py:85} INFO - Output:
[2024-03-30 09:01:39,519] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 09:01:39,621] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210902T060000, start_date=20240330T090131, end_date=20240330T090139
[2024-03-30 09:01:39,712] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:01:40,223] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 10:50:04,106] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-30 10:50:04,175] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-30 10:50:04,176] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:50:04,177] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 10:50:04,178] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:50:04,240] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-09-02 06:00:00+00:00
[2024-03-30 10:50:04,275] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-09-02T06:00:00+00:00', '--job-id', '2636', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpo493qgk_', '--error-file', '/tmp/tmp7_9xdw62']
[2024-03-30 10:50:04,281] {standard_task_runner.py:77} INFO - Job 2636: Subtask download_dataset_task
[2024-03-30 10:50:04,249] {standard_task_runner.py:52} INFO - Started process 23497 to run task
[2024-03-30 10:50:04,524] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 10:50:04,619] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 10:50:04,693] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-09-02T06:00:00+00:00
[2024-03-30 10:50:04,695] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 10:50:04,696] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet > /opt/***raw_data/yellowtaxi_tripdata_2021-09.parquet']
[2024-03-30 10:50:04,733] {subprocess.py:85} INFO - Output:
[2024-03-30 10:50:04,758] {subprocess.py:89} INFO - bash: /opt/***raw_data/yellowtaxi_tripdata_2021-09.parquet: No such file or directory
[2024-03-30 10:50:04,765] {subprocess.py:93} INFO - Command exited with return code 1
[2024-03-30 10:50:04,830] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:50:04,856] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210902T060000, start_date=20240330T105004, end_date=20240330T105004
[2024-03-30 10:50:04,915] {standard_task_runner.py:92} ERROR - Failed to execute job 2636 for task download_dataset_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:50:04,963] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 10:50:05,113] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 10:54:53,516] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-30 10:54:53,565] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-30 10:54:53,565] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:54:53,566] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 10:54:53,566] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:54:53,610] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-09-02 06:00:00+00:00
[2024-03-30 10:54:53,641] {standard_task_runner.py:52} INFO - Started process 23780 to run task
[2024-03-30 10:54:53,682] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-09-02T06:00:00+00:00', '--job-id', '2649', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpwfoo_a6h', '--error-file', '/tmp/tmpp02hwa72']
[2024-03-30 10:54:53,715] {standard_task_runner.py:77} INFO - Job 2649: Subtask download_dataset_task
[2024-03-30 10:54:53,940] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 10:54:54,165] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 10:54:54,287] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-09-02T06:00:00+00:00
[2024-03-30 10:54:54,288] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 10:54:54,290] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet > /opt/***raw_data/yellowtaxi_tripdata_2021-09.parquet']
[2024-03-30 10:54:54,366] {subprocess.py:85} INFO - Output:
[2024-03-30 10:54:54,403] {subprocess.py:89} INFO - bash: /opt/***raw_data/yellowtaxi_tripdata_2021-09.parquet: No such file or directory
[2024-03-30 10:54:54,404] {subprocess.py:93} INFO - Command exited with return code 1
[2024-03-30 10:54:54,456] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:54:54,494] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210902T060000, start_date=20240330T105453, end_date=20240330T105454
[2024-03-30 10:54:54,559] {standard_task_runner.py:92} ERROR - Failed to execute job 2649 for task download_dataset_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:54:54,618] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 10:54:54,735] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:03:57,875] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-30 11:03:57,935] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-30 11:03:57,935] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:03:57,935] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:03:57,936] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:03:58,071] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-09-02 06:00:00+00:00
[2024-03-30 11:03:58,159] {standard_task_runner.py:52} INFO - Started process 24348 to run task
[2024-03-30 11:03:58,185] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-09-02T06:00:00+00:00', '--job-id', '2681', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp79k16ipi', '--error-file', '/tmp/tmpqb8zzteg']
[2024-03-30 11:03:58,260] {standard_task_runner.py:77} INFO - Job 2681: Subtask download_dataset_task
[2024-03-30 11:03:58,838] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:03:59,091] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:03:59,163] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-09-02T06:00:00+00:00
[2024-03-30 11:03:59,164] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:03:59,165] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-09.parquet']
[2024-03-30 11:03:59,236] {subprocess.py:85} INFO - Output:
[2024-03-30 11:04:05,148] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:04:05,537] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210902T060000, start_date=20240330T110357, end_date=20240330T110405
[2024-03-30 11:04:05,787] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:04:06,008] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:15:09,795] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-30 11:15:09,830] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-30 11:15:09,830] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:15:09,831] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:15:09,831] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:15:09,862] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-09-02 06:00:00+00:00
[2024-03-30 11:15:09,878] {standard_task_runner.py:52} INFO - Started process 25272 to run task
[2024-03-30 11:15:09,908] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-09-02T06:00:00+00:00', '--job-id', '2727', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp7tuc7sd8', '--error-file', '/tmp/tmptt5jgo4o']
[2024-03-30 11:15:09,930] {standard_task_runner.py:77} INFO - Job 2727: Subtask download_dataset_task
[2024-03-30 11:15:10,134] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:15:10,353] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:15:10,439] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-09-02T06:00:00+00:00
[2024-03-30 11:15:10,440] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:15:10,441] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-09.parquet']
[2024-03-30 11:15:10,524] {subprocess.py:85} INFO - Output:
[2024-03-30 11:15:16,427] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:15:16,902] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210902T060000, start_date=20240330T111509, end_date=20240330T111516
[2024-03-30 11:15:17,355] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:15:17,644] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:33:53,829] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-30 11:33:53,902] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-03-30 11:33:53,902] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:33:53,902] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:33:53,902] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:33:53,965] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-09-02 06:00:00+00:00
[2024-03-30 11:33:54,030] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-09-02T06:00:00+00:00', '--job-id', '2804', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpurp8zf_o', '--error-file', '/tmp/tmptbf16l38']
[2024-03-30 11:33:54,053] {standard_task_runner.py:77} INFO - Job 2804: Subtask download_dataset_task
[2024-03-30 11:33:53,999] {standard_task_runner.py:52} INFO - Started process 26850 to run task
[2024-03-30 11:33:54,336] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:33:54,501] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:33:54,610] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-09-02T06:00:00+00:00
[2024-03-30 11:33:54,613] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:33:54,618] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-09.parquet']
[2024-03-30 11:33:54,739] {subprocess.py:85} INFO - Output:
[2024-03-30 11:34:00,638] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:34:01,013] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210902T060000, start_date=20240330T113353, end_date=20240330T113401
[2024-03-30 11:34:01,216] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:34:01,459] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-28 09:15:30,888] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:31,047] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:31,048] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:31,048] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-28 09:15:31,048] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:31,154] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-09-02 06:00:00+00:00
[2024-04-28 09:15:31,237] {standard_task_runner.py:52} INFO - Started process 1399 to run task
[2024-04-28 09:15:31,289] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-09-02T06:00:00+00:00', '--job-id', '2998', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpp23xgy8n', '--error-file', '/tmp/tmponkqzmut']
[2024-04-28 09:15:31,329] {standard_task_runner.py:77} INFO - Job 2998: Subtask download_dataset_task
[2024-04-28 09:15:31,535] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [running]> on host 6c6a4ca9ff8e
[2024-04-28 09:15:31,724] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-28 09:15:31,789] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-09-02T06:00:00+00:00
[2024-04-28 09:15:31,791] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-28 09:15:31,802] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-09.parquet']
[2024-04-28 09:15:31,856] {subprocess.py:85} INFO - Output:
[2024-04-28 09:15:36,601] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-28 09:15:37,646] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210902T060000, start_date=20240428T091530, end_date=20240428T091537
[2024-04-28 09:15:38,330] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-28 09:15:38,803] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:13:46,761] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-04-30 02:13:46,825] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-04-30 02:13:46,836] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:13:46,836] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-30 02:13:46,837] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:13:46,896] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-09-02 06:00:00+00:00
[2024-04-30 02:13:46,928] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-09-02T06:00:00+00:00', '--job-id', '3028', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpg3fvsufi', '--error-file', '/tmp/tmppz1d2e_9']
[2024-04-30 02:13:46,952] {standard_task_runner.py:77} INFO - Job 3028: Subtask download_dataset_task
[2024-04-30 02:13:46,918] {standard_task_runner.py:52} INFO - Started process 308 to run task
[2024-04-30 02:13:47,203] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [running]> on host a1ae6a0259c5
[2024-04-30 02:13:47,427] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:13:47,541] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-09-02T06:00:00+00:00
[2024-04-30 02:13:47,547] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 02:13:47,548] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-09.parquet']
[2024-04-30 02:13:47,648] {subprocess.py:85} INFO - Output:
[2024-04-30 02:13:51,838] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 02:13:51,888] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210902T060000, start_date=20240430T021346, end_date=20240430T021351
[2024-04-30 02:13:51,962] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 02:13:52,027] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:58:12,690] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:12,753] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:12,754] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:12,758] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 02:58:12,758] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:12,810] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-09-02 06:00:00+00:00
[2024-04-30 02:58:12,838] {standard_task_runner.py:52} INFO - Started process 393 to run task
[2024-04-30 02:58:12,869] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-09-02T06:00:00+00:00', '--job-id', '3100', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp1vv6r4gx', '--error-file', '/tmp/tmpyzupbga1']
[2024-04-30 02:58:12,898] {standard_task_runner.py:77} INFO - Job 3100: Subtask download_dataset_task
[2024-04-30 02:58:13,147] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 02:58:13,243] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:58:13,314] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-09-02T06:00:00+00:00
[2024-04-30 02:58:13,320] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 02:58:13,321] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-09.parquet']
[2024-04-30 02:58:13,347] {subprocess.py:85} INFO - Output:
[2024-04-30 02:58:17,268] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 02:58:17,400] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210902T060000, start_date=20240430T025812, end_date=20240430T025817
[2024-04-30 02:58:17,594] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 02:58:18,295] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:01:06,275] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:06,351] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:06,352] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:06,352] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:01:06,353] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:06,454] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-09-02 06:00:00+00:00
[2024-04-30 03:01:06,483] {standard_task_runner.py:52} INFO - Started process 666 to run task
[2024-04-30 03:01:06,508] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-09-02T06:00:00+00:00', '--job-id', '3132', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpr7fhoncc', '--error-file', '/tmp/tmp2cjs4oce']
[2024-04-30 03:01:06,573] {standard_task_runner.py:77} INFO - Job 3132: Subtask download_dataset_task
[2024-04-30 03:01:06,815] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:01:07,009] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:01:07,128] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-09-02T06:00:00+00:00
[2024-04-30 03:01:07,133] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 03:01:07,138] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet > /opt/***/cleaned_data/yellowtaxi_tripdata_2021-09.parquet']
[2024-04-30 03:01:07,268] {subprocess.py:85} INFO - Output:
[2024-04-30 03:01:11,582] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 03:01:11,769] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210902T060000, start_date=20240430T030106, end_date=20240430T030111
[2024-04-30 03:01:11,940] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:01:12,145] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:30:01,201] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-04-30 04:30:01,326] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [queued]>
[2024-04-30 04:30:01,328] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:30:01,334] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:30:01,342] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:30:01,460] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-09-02 06:00:00+00:00
[2024-04-30 04:30:01,552] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-09-02T06:00:00+00:00', '--job-id', '3243', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp9wznsup7', '--error-file', '/tmp/tmpy0wdi9cw']
[2024-04-30 04:30:01,572] {standard_task_runner.py:77} INFO - Job 3243: Subtask download_dataset_task
[2024-04-30 04:30:01,535] {standard_task_runner.py:52} INFO - Started process 5189 to run task
[2024-04-30 04:30:01,976] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-09-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:30:02,208] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:30:02,303] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-09-02T06:00:00+00:00
[2024-04-30 04:30:02,315] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 04:30:02,316] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-09.parquet']
[2024-04-30 04:30:02,410] {subprocess.py:85} INFO - Output:
[2024-04-30 04:30:06,548] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 04:30:06,690] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210902T060000, start_date=20240430T043001, end_date=20240430T043006
[2024-04-30 04:30:06,742] {local_task_job.py:212} WARNING - State of this instance has been externally set to success. Terminating instance.
