[2024-03-30 03:54:00,529] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-12-02T06:00:00+00:00 [queued]>
[2024-03-30 03:54:00,604] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-12-02T06:00:00+00:00 [queued]>
[2024-03-30 03:54:00,604] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:54:00,604] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:54:00,614] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:54:00,701] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-12-02 06:00:00+00:00
[2024-03-30 03:54:00,822] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-12-02T06:00:00+00:00', '--job-id', '2026', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpzuztggm6', '--error-file', '/tmp/tmpapqrjipi']
[2024-03-30 03:54:00,849] {standard_task_runner.py:77} INFO - Job 2026: Subtask download_dataset_task
[2024-03-30 03:54:00,748] {standard_task_runner.py:52} INFO - Started process 2250 to run task
[2024-03-30 03:54:01,202] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-12-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:54:01,338] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:54:01,415] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-12-02T06:00:00+00:00
[2024-03-30 03:54:01,416] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:54:01,417] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-12.parquet > /opt/***/yellowtaxi_tripdata_2023-12.parquet']
[2024-03-30 03:54:01,466] {subprocess.py:85} INFO - Output:
[2024-03-30 03:54:08,087] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:54:08,202] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20231202T060000, start_date=20240330T035400, end_date=20240330T035408
[2024-03-30 03:54:08,273] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:54:08,340] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:26:08,686] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-12-02T06:00:00+00:00 [queued]>
[2024-03-30 04:26:08,717] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-12-02T06:00:00+00:00 [queued]>
[2024-03-30 04:26:08,718] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:26:08,718] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:26:08,718] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:26:08,751] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-12-02 06:00:00+00:00
[2024-03-30 04:26:08,764] {standard_task_runner.py:52} INFO - Started process 4541 to run task
[2024-03-30 04:26:08,777] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-12-02T06:00:00+00:00', '--job-id', '2252', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpa0_gw57n', '--error-file', '/tmp/tmpiaw5firg']
[2024-03-30 04:26:08,800] {standard_task_runner.py:77} INFO - Job 2252: Subtask download_dataset_task
[2024-03-30 04:26:08,942] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-12-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:26:09,021] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:26:09,057] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-12-02T06:00:00+00:00
[2024-03-30 04:26:09,058] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:26:09,059] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-12.parquet > /opt/***/yellowtaxi_tripdata_2023-12.parquet']
[2024-03-30 04:26:09,081] {subprocess.py:85} INFO - Output:
[2024-03-30 04:26:15,553] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:26:15,591] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20231202T060000, start_date=20240330T042608, end_date=20240330T042615
[2024-03-30 04:26:15,636] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:26:15,687] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:44:57,425] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-12-02T06:00:00+00:00 [queued]>
[2024-03-30 04:44:57,494] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-12-02T06:00:00+00:00 [queued]>
[2024-03-30 04:44:57,494] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:44:57,494] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:44:57,494] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:44:57,581] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-12-02 06:00:00+00:00
[2024-03-30 04:44:57,610] {standard_task_runner.py:52} INFO - Started process 5795 to run task
[2024-03-30 04:44:57,647] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-12-02T06:00:00+00:00', '--job-id', '2362', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp21yjn5au', '--error-file', '/tmp/tmp9jn45mkp']
[2024-03-30 04:44:57,666] {standard_task_runner.py:77} INFO - Job 2362: Subtask download_dataset_task
[2024-03-30 04:44:57,998] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-12-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:44:58,135] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:44:58,181] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-12-02T06:00:00+00:00
[2024-03-30 04:44:58,183] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:44:58,184] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-12.parquet > /opt/***/yellowtaxi_tripdata_2023-12.parquet']
[2024-03-30 04:44:58,207] {subprocess.py:85} INFO - Output:
[2024-03-30 04:45:04,816] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:45:04,916] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20231202T060000, start_date=20240330T044457, end_date=20240330T044504
[2024-03-30 04:45:05,069] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:45:05,251] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 05:00:41,902] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-12-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:41,924] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-12-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:41,924] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:41,924] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 05:00:41,924] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:41,941] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-12-02 06:00:00+00:00
[2024-03-30 05:00:41,950] {standard_task_runner.py:52} INFO - Started process 6975 to run task
[2024-03-30 05:00:41,956] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-12-02T06:00:00+00:00', '--job-id', '2495', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpsbhm0z7y', '--error-file', '/tmp/tmp0as8_jnj']
[2024-03-30 05:00:41,962] {standard_task_runner.py:77} INFO - Job 2495: Subtask download_dataset_task
[2024-03-30 05:00:42,040] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-12-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 05:00:42,082] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 05:00:42,105] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-12-02T06:00:00+00:00
[2024-03-30 05:00:42,106] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 05:00:42,107] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-12.parquet > /opt/***/yellowtaxi_tripdata_2023-12.parquet']
[2024-03-30 05:00:42,123] {subprocess.py:85} INFO - Output:
[2024-03-30 05:00:48,732] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 05:00:48,803] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20231202T060000, start_date=20240330T050041, end_date=20240330T050048
[2024-03-30 05:00:48,889] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 05:00:48,961] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:03:26,495] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-12-02T06:00:00+00:00 [queued]>
[2024-03-30 09:03:26,515] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-12-02T06:00:00+00:00 [queued]>
[2024-03-30 09:03:26,515] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:03:26,515] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:03:26,515] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:03:26,530] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-12-02 06:00:00+00:00
[2024-03-30 09:03:26,537] {standard_task_runner.py:52} INFO - Started process 18528 to run task
[2024-03-30 09:03:26,543] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-12-02T06:00:00+00:00', '--job-id', '2613', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp7r1ririp', '--error-file', '/tmp/tmp3o41f3wi']
[2024-03-30 09:03:26,549] {standard_task_runner.py:77} INFO - Job 2613: Subtask download_dataset_task
[2024-03-30 09:03:26,622] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-12-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:03:26,661] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:03:26,690] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-12-02T06:00:00+00:00
[2024-03-30 09:03:26,692] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 09:03:26,693] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-12.parquet > /opt/***/yellowtaxi_tripdata_2023-12.parquet']
[2024-03-30 09:03:26,713] {subprocess.py:85} INFO - Output:
[2024-03-30 09:03:33,210] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 09:03:33,259] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20231202T060000, start_date=20240330T090326, end_date=20240330T090333
[2024-03-30 09:03:33,323] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:03:33,379] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 12:07:33,145] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-12-02T06:00:00+00:00 [queued]>
[2024-03-30 12:07:33,172] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-12-02T06:00:00+00:00 [queued]>
[2024-03-30 12:07:33,173] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 12:07:33,173] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 12:07:33,174] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 12:07:33,194] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-12-02 06:00:00+00:00
[2024-03-30 12:07:33,203] {standard_task_runner.py:52} INFO - Started process 29488 to run task
[2024-03-30 12:07:33,227] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-12-02T06:00:00+00:00', '--job-id', '2942', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpdgl7pvjn', '--error-file', '/tmp/tmpv7ypafpf']
[2024-03-30 12:07:33,239] {standard_task_runner.py:77} INFO - Job 2942: Subtask download_dataset_task
[2024-03-30 12:07:33,394] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-12-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 12:07:33,505] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 12:07:33,560] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-12-02T06:00:00+00:00
[2024-03-30 12:07:33,562] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 12:07:33,563] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-12.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2023-12.parquet']
[2024-03-30 12:07:33,610] {subprocess.py:85} INFO - Output:
[2024-03-30 12:07:40,137] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 12:07:40,407] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20231202T060000, start_date=20240330T120733, end_date=20240330T120740
[2024-03-30 12:07:40,459] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 12:07:40,504] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:02:28,808] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-12-02T06:00:00+00:00 [queued]>
[2024-04-30 03:02:28,823] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-12-02T06:00:00+00:00 [queued]>
[2024-04-30 03:02:28,824] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:02:28,824] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:02:28,824] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:02:28,838] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-12-02 06:00:00+00:00
[2024-04-30 03:02:28,845] {standard_task_runner.py:52} INFO - Started process 1045 to run task
[2024-04-30 03:02:28,853] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-12-02T06:00:00+00:00', '--job-id', '3221', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpmvcqvlok', '--error-file', '/tmp/tmpk0nzsxg6']
[2024-04-30 03:02:28,859] {standard_task_runner.py:77} INFO - Job 3221: Subtask download_dataset_task
[2024-04-30 03:02:28,931] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-12-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:02:28,976] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:02:29,003] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-12-02T06:00:00+00:00
[2024-04-30 03:02:29,004] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 03:02:29,005] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-12.parquet > /opt/***/cleaned_data/yellowtaxi_tripdata_2023-12.parquet']
[2024-04-30 03:02:29,019] {subprocess.py:85} INFO - Output:
[2024-04-30 03:02:33,603] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 03:02:33,683] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20231202T060000, start_date=20240430T030228, end_date=20240430T030233
[2024-04-30 03:02:33,758] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:02:33,898] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:35:35,419] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-12-02T06:00:00+00:00 [queued]>
[2024-04-30 04:35:35,439] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-12-02T06:00:00+00:00 [queued]>
[2024-04-30 04:35:35,439] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:35:35,439] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:35:35,439] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:35:35,457] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-12-02 06:00:00+00:00
[2024-04-30 04:35:35,466] {standard_task_runner.py:52} INFO - Started process 5909 to run task
[2024-04-30 04:35:35,471] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-12-02T06:00:00+00:00', '--job-id', '3324', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp2npfz6ld', '--error-file', '/tmp/tmpsmpdwz6j']
[2024-04-30 04:35:35,483] {standard_task_runner.py:77} INFO - Job 3324: Subtask download_dataset_task
[2024-04-30 04:35:35,557] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-12-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:35:35,600] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:35:35,629] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-12-02T06:00:00+00:00
[2024-04-30 04:35:35,631] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 04:35:35,631] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-12.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2023-12.parquet']
[2024-04-30 04:35:35,645] {subprocess.py:85} INFO - Output:
[2024-04-30 04:35:40,033] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 04:35:40,087] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20231202T060000, start_date=20240430T043535, end_date=20240430T043540
[2024-04-30 04:35:40,136] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 04:35:40,210] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
