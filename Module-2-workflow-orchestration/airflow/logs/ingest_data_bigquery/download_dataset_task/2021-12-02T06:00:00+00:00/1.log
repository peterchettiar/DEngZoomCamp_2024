[2024-03-29 07:24:30,071] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:30,275] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:30,275] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:30,275] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:24:30,275] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:30,434] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-12-02 06:00:00+00:00
[2024-03-29 07:24:30,502] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-12-02T06:00:00+00:00', '--job-id', '1450', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpvys50lbi', '--error-file', '/tmp/tmp9oks10fu']
[2024-03-29 07:24:30,524] {standard_task_runner.py:77} INFO - Job 1450: Subtask download_dataset_task
[2024-03-29 07:24:30,487] {standard_task_runner.py:52} INFO - Started process 530 to run task
[2024-03-29 07:24:30,681] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:24:30,839] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:24:30,897] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-02T06:00:00+00:00
[2024-03-29 07:24:30,899] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:24:30,900] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet > /opt/***/yellowtaxi_tripdata_2021-12.parquet']
[2024-03-29 07:24:30,960] {subprocess.py:85} INFO - Output:
[2024-03-29 07:24:37,005] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:24:37,288] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20211202T060000, start_date=20240329T072430, end_date=20240329T072437
[2024-03-29 07:24:37,529] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:24:37,732] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:30:47,866] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-29 07:30:47,995] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-29 07:30:47,995] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:30:47,995] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:30:47,995] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:30:48,032] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-12-02 06:00:00+00:00
[2024-03-29 07:30:48,069] {standard_task_runner.py:52} INFO - Started process 1027 to run task
[2024-03-29 07:30:48,102] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-12-02T06:00:00+00:00', '--job-id', '1510', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpi44cooz4', '--error-file', '/tmp/tmp3i7f9mx4']
[2024-03-29 07:30:48,153] {standard_task_runner.py:77} INFO - Job 1510: Subtask download_dataset_task
[2024-03-29 07:30:48,454] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:30:48,614] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:30:48,687] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-02T06:00:00+00:00
[2024-03-29 07:30:48,691] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:30:48,694] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet > /opt/***/yellowtaxi_tripdata_2021-12.parquet']
[2024-03-29 07:30:48,824] {subprocess.py:85} INFO - Output:
[2024-03-29 07:30:55,037] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:30:55,247] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20211202T060000, start_date=20240329T073047, end_date=20240329T073055
[2024-03-29 07:30:55,586] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:30:55,810] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:37:33,773] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:33,870] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:33,871] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:33,871] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:37:33,871] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:34,018] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-12-02 06:00:00+00:00
[2024-03-29 07:37:34,084] {standard_task_runner.py:52} INFO - Started process 1561 to run task
[2024-03-29 07:37:34,113] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-12-02T06:00:00+00:00', '--job-id', '1572', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpkwx2guhm', '--error-file', '/tmp/tmpxunnrdzv']
[2024-03-29 07:37:34,142] {standard_task_runner.py:77} INFO - Job 1572: Subtask download_dataset_task
[2024-03-29 07:37:34,272] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:37:34,446] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:37:34,506] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-02T06:00:00+00:00
[2024-03-29 07:37:34,508] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:37:34,509] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet > /opt/***/yellowtaxi_tripdata_2021-12.parquet']
[2024-03-29 07:37:34,573] {subprocess.py:85} INFO - Output:
[2024-03-29 07:37:40,858] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:37:40,953] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20211202T060000, start_date=20240329T073733, end_date=20240329T073740
[2024-03-29 07:37:41,307] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:37:41,567] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:08:30,869] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:30,900] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:30,901] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:30,901] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:08:30,902] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:30,925] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-12-02 06:00:00+00:00
[2024-03-29 08:08:30,946] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-12-02T06:00:00+00:00', '--job-id', '1636', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpxpjzgj1p', '--error-file', '/tmp/tmpimpujryy']
[2024-03-29 08:08:30,936] {standard_task_runner.py:52} INFO - Started process 240 to run task
[2024-03-29 08:08:30,954] {standard_task_runner.py:77} INFO - Job 1636: Subtask download_dataset_task
[2024-03-29 08:08:31,063] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:08:31,124] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:08:31,159] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-02T06:00:00+00:00
[2024-03-29 08:08:31,161] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:08:31,163] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet > /opt/***/yellowtaxi_tripdata_2021-12.parquet']
[2024-03-29 08:08:31,183] {subprocess.py:85} INFO - Output:
[2024-03-29 08:08:37,247] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:08:37,346] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20211202T060000, start_date=20240329T080830, end_date=20240329T080837
[2024-03-29 08:08:37,495] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:08:37,806] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:10:58,951] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-29 08:10:59,009] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-29 08:10:59,009] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:10:59,009] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:10:59,009] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:10:59,086] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-12-02 06:00:00+00:00
[2024-03-29 08:10:59,125] {standard_task_runner.py:52} INFO - Started process 512 to run task
[2024-03-29 08:10:59,184] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-12-02T06:00:00+00:00', '--job-id', '1679', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpqjq5ur83', '--error-file', '/tmp/tmpqeb3eiij']
[2024-03-29 08:10:59,197] {standard_task_runner.py:77} INFO - Job 1679: Subtask download_dataset_task
[2024-03-29 08:10:59,427] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:10:59,595] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:10:59,670] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-02T06:00:00+00:00
[2024-03-29 08:10:59,673] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:10:59,675] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet > /opt/***/yellowtaxi_tripdata_2021-12.parquet']
[2024-03-29 08:10:59,739] {subprocess.py:85} INFO - Output:
[2024-03-29 08:11:06,341] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:11:07,250] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20211202T060000, start_date=20240329T081058, end_date=20240329T081107
[2024-03-29 08:11:07,569] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:11:08,010] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:30:06,643] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:06,669] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:06,670] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:06,670] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:30:06,671] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:06,690] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-12-02 06:00:00+00:00
[2024-03-30 03:30:06,699] {standard_task_runner.py:52} INFO - Started process 472 to run task
[2024-03-30 03:30:06,719] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-12-02T06:00:00+00:00', '--job-id', '1826', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmprfyrx1zw', '--error-file', '/tmp/tmpzj_rdz02']
[2024-03-30 03:30:06,741] {standard_task_runner.py:77} INFO - Job 1826: Subtask download_dataset_task
[2024-03-30 03:30:06,887] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:30:06,954] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:30:06,985] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-02T06:00:00+00:00
[2024-03-30 03:30:06,988] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:30:06,992] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet > /opt/***/yellowtaxi_tripdata_2021-12.parquet']
[2024-03-30 03:30:07,010] {subprocess.py:85} INFO - Output:
[2024-03-30 03:30:12,953] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:30:13,337] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20211202T060000, start_date=20240330T033006, end_date=20240330T033013
[2024-03-30 03:30:13,499] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:30:13,604] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:41:59,715] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-30 03:41:59,752] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-30 03:41:59,752] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:41:59,754] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:41:59,754] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:41:59,846] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-12-02 06:00:00+00:00
[2024-03-30 03:41:59,874] {standard_task_runner.py:52} INFO - Started process 1298 to run task
[2024-03-30 03:41:59,925] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-12-02T06:00:00+00:00', '--job-id', '1903', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp4rcprnbm', '--error-file', '/tmp/tmprwn2jmhw']
[2024-03-30 03:41:59,946] {standard_task_runner.py:77} INFO - Job 1903: Subtask download_dataset_task
[2024-03-30 03:42:00,110] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:42:00,411] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:42:00,472] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-02T06:00:00+00:00
[2024-03-30 03:42:00,476] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:42:00,479] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet > /opt/***/yellowtaxi_tripdata_2021-12.parquet']
[2024-03-30 03:42:00,645] {subprocess.py:85} INFO - Output:
[2024-03-30 03:42:06,680] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:42:06,830] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20211202T060000, start_date=20240330T034159, end_date=20240330T034206
[2024-03-30 03:42:06,900] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:42:07,032] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:18:08,560] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:08,701] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:08,702] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:08,704] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:18:08,704] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:08,836] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-12-02 06:00:00+00:00
[2024-03-30 04:18:08,884] {standard_task_runner.py:52} INFO - Started process 3529 to run task
[2024-03-30 04:18:08,982] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-12-02T06:00:00+00:00', '--job-id', '2081', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp1jkzgr1d', '--error-file', '/tmp/tmpkhj9ia_4']
[2024-03-30 04:18:09,049] {standard_task_runner.py:77} INFO - Job 2081: Subtask download_dataset_task
[2024-03-30 04:18:09,628] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:18:09,887] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:18:10,030] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-02T06:00:00+00:00
[2024-03-30 04:18:10,038] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:18:10,046] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet > /opt/***/yellowtaxi_tripdata_2021-12.parquet']
[2024-03-30 04:18:10,190] {subprocess.py:85} INFO - Output:
[2024-03-30 04:18:16,706] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:18:17,039] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20211202T060000, start_date=20240330T041808, end_date=20240330T041817
[2024-03-30 04:18:17,200] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:18:17,428] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:24:44,176] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-30 04:24:44,224] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-30 04:24:44,224] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:24:44,225] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:24:44,225] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:24:44,281] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-12-02 06:00:00+00:00
[2024-03-30 04:24:44,304] {standard_task_runner.py:52} INFO - Started process 4150 to run task
[2024-03-30 04:24:44,359] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-12-02T06:00:00+00:00', '--job-id', '2161', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpox467u0b', '--error-file', '/tmp/tmpqm_x7u5l']
[2024-03-30 04:24:44,407] {standard_task_runner.py:77} INFO - Job 2161: Subtask download_dataset_task
[2024-03-30 04:24:44,819] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:24:45,014] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:24:45,087] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-02T06:00:00+00:00
[2024-03-30 04:24:45,090] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:24:45,094] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet > /opt/***/yellowtaxi_tripdata_2021-12.parquet']
[2024-03-30 04:24:45,174] {subprocess.py:85} INFO - Output:
[2024-03-30 04:24:51,323] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:24:51,447] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20211202T060000, start_date=20240330T042444, end_date=20240330T042451
[2024-03-30 04:24:51,585] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:24:51,825] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:38:38,888] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-30 04:38:39,084] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-30 04:38:39,084] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:38:39,084] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:38:39,085] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:38:39,252] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-12-02 06:00:00+00:00
[2024-03-30 04:38:39,329] {standard_task_runner.py:52} INFO - Started process 5189 to run task
[2024-03-30 04:38:39,405] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-12-02T06:00:00+00:00', '--job-id', '2272', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp8sixqbn_', '--error-file', '/tmp/tmpejntkql3']
[2024-03-30 04:38:39,469] {standard_task_runner.py:77} INFO - Job 2272: Subtask download_dataset_task
[2024-03-30 04:38:39,960] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:38:40,861] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:38:40,991] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-02T06:00:00+00:00
[2024-03-30 04:38:40,994] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:38:40,995] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet > /opt/***/yellowtaxi_tripdata_2021-12.parquet']
[2024-03-30 04:38:41,082] {subprocess.py:85} INFO - Output:
[2024-03-30 04:38:47,682] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:38:47,809] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20211202T060000, start_date=20240330T043838, end_date=20240330T043847
[2024-03-30 04:38:47,998] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:38:48,104] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:59:25,501] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:25,587] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:25,587] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:25,587] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:59:25,587] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:25,686] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-12-02 06:00:00+00:00
[2024-03-30 04:59:25,793] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-12-02T06:00:00+00:00', '--job-id', '2409', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpjug4oeub', '--error-file', '/tmp/tmpwvmnjswe']
[2024-03-30 04:59:25,816] {standard_task_runner.py:77} INFO - Job 2409: Subtask download_dataset_task
[2024-03-30 04:59:25,727] {standard_task_runner.py:52} INFO - Started process 6605 to run task
[2024-03-30 04:59:26,120] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:59:26,481] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:59:26,662] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-02T06:00:00+00:00
[2024-03-30 04:59:26,675] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:59:26,681] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet > /opt/***/yellowtaxi_tripdata_2021-12.parquet']
[2024-03-30 04:59:26,852] {subprocess.py:85} INFO - Output:
[2024-03-30 04:59:33,084] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:59:33,175] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20211202T060000, start_date=20240330T045925, end_date=20240330T045933
[2024-03-30 04:59:33,363] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:59:33,476] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:01:32,745] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:32,900] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:32,900] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:32,900] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:01:32,905] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:32,980] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-12-02 06:00:00+00:00
[2024-03-30 09:01:33,096] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-12-02T06:00:00+00:00', '--job-id', '2527', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpcw584b5y', '--error-file', '/tmp/tmpg81oz1o5']
[2024-03-30 09:01:33,133] {standard_task_runner.py:77} INFO - Job 2527: Subtask download_dataset_task
[2024-03-30 09:01:33,029] {standard_task_runner.py:52} INFO - Started process 18144 to run task
[2024-03-30 09:01:33,413] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:01:33,703] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:01:33,842] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-02T06:00:00+00:00
[2024-03-30 09:01:33,844] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 09:01:33,845] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet > /opt/***/yellowtaxi_tripdata_2021-12.parquet']
[2024-03-30 09:01:33,974] {subprocess.py:85} INFO - Output:
[2024-03-30 09:01:41,012] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 09:01:41,200] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20211202T060000, start_date=20240330T090132, end_date=20240330T090141
[2024-03-30 09:01:41,413] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:01:41,967] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 10:50:04,736] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-30 10:50:04,766] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-30 10:50:04,767] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:50:04,770] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 10:50:04,771] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:50:04,815] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-12-02 06:00:00+00:00
[2024-03-30 10:50:04,847] {standard_task_runner.py:52} INFO - Started process 23502 to run task
[2024-03-30 10:50:04,875] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-12-02T06:00:00+00:00', '--job-id', '2639', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp44l6b8ne', '--error-file', '/tmp/tmpjia6vnwq']
[2024-03-30 10:50:04,904] {standard_task_runner.py:77} INFO - Job 2639: Subtask download_dataset_task
[2024-03-30 10:50:05,126] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 10:50:05,279] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 10:50:05,360] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-02T06:00:00+00:00
[2024-03-30 10:50:05,366] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 10:50:05,367] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet > /opt/***raw_data/yellowtaxi_tripdata_2021-12.parquet']
[2024-03-30 10:50:05,411] {subprocess.py:85} INFO - Output:
[2024-03-30 10:50:05,426] {subprocess.py:89} INFO - bash: /opt/***raw_data/yellowtaxi_tripdata_2021-12.parquet: No such file or directory
[2024-03-30 10:50:05,427] {subprocess.py:93} INFO - Command exited with return code 1
[2024-03-30 10:50:05,750] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:50:05,773] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20211202T060000, start_date=20240330T105004, end_date=20240330T105005
[2024-03-30 10:50:05,828] {standard_task_runner.py:92} ERROR - Failed to execute job 2639 for task download_dataset_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:50:05,897] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 10:50:06,009] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 10:54:55,921] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-30 10:54:55,953] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-30 10:54:55,953] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:54:55,954] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 10:54:55,955] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:54:56,001] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-12-02 06:00:00+00:00
[2024-03-30 10:54:56,031] {standard_task_runner.py:52} INFO - Started process 23800 to run task
[2024-03-30 10:54:56,061] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-12-02T06:00:00+00:00', '--job-id', '2653', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp0ut0e__u', '--error-file', '/tmp/tmpe3d9crpg']
[2024-03-30 10:54:56,092] {standard_task_runner.py:77} INFO - Job 2653: Subtask download_dataset_task
[2024-03-30 10:54:56,415] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 10:54:56,596] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 10:54:56,735] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-02T06:00:00+00:00
[2024-03-30 10:54:56,736] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 10:54:56,737] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet > /opt/***raw_data/yellowtaxi_tripdata_2021-12.parquet']
[2024-03-30 10:54:56,803] {subprocess.py:85} INFO - Output:
[2024-03-30 10:54:56,827] {subprocess.py:89} INFO - bash: /opt/***raw_data/yellowtaxi_tripdata_2021-12.parquet: No such file or directory
[2024-03-30 10:54:56,831] {subprocess.py:93} INFO - Command exited with return code 1
[2024-03-30 10:54:57,111] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:54:57,138] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20211202T060000, start_date=20240330T105455, end_date=20240330T105457
[2024-03-30 10:54:57,214] {standard_task_runner.py:92} ERROR - Failed to execute job 2653 for task download_dataset_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:54:57,252] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 10:54:57,344] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:04:02,728] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-30 11:04:02,860] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-30 11:04:02,861] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:04:02,861] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:04:02,861] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:04:02,967] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-12-02 06:00:00+00:00
[2024-03-30 11:04:03,021] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-12-02T06:00:00+00:00', '--job-id', '2684', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpvylhqfqb', '--error-file', '/tmp/tmp46yfiq4n']
[2024-03-30 11:04:03,069] {standard_task_runner.py:77} INFO - Job 2684: Subtask download_dataset_task
[2024-03-30 11:04:03,042] {standard_task_runner.py:52} INFO - Started process 24378 to run task
[2024-03-30 11:04:03,535] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:04:03,842] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:04:03,956] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-02T06:00:00+00:00
[2024-03-30 11:04:03,958] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:04:03,959] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-12.parquet']
[2024-03-30 11:04:04,041] {subprocess.py:85} INFO - Output:
[2024-03-30 11:04:10,059] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:04:10,233] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20211202T060000, start_date=20240330T110402, end_date=20240330T110410
[2024-03-30 11:04:10,448] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:04:10,784] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:15:12,274] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-30 11:15:12,356] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-30 11:15:12,357] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:15:12,357] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:15:12,357] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:15:12,436] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-12-02 06:00:00+00:00
[2024-03-30 11:15:12,469] {standard_task_runner.py:52} INFO - Started process 25294 to run task
[2024-03-30 11:15:12,508] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-12-02T06:00:00+00:00', '--job-id', '2731', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp0zzu_aip', '--error-file', '/tmp/tmpxym234sr']
[2024-03-30 11:15:12,531] {standard_task_runner.py:77} INFO - Job 2731: Subtask download_dataset_task
[2024-03-30 11:15:12,669] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:15:12,750] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:15:12,826] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-02T06:00:00+00:00
[2024-03-30 11:15:12,828] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:15:12,829] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-12.parquet']
[2024-03-30 11:15:12,851] {subprocess.py:85} INFO - Output:
[2024-03-30 11:15:18,873] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:15:19,478] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20211202T060000, start_date=20240330T111512, end_date=20240330T111519
[2024-03-30 11:15:19,727] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:15:19,964] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:33:53,895] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-30 11:33:53,971] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-03-30 11:33:53,975] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:33:53,975] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:33:53,975] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:33:54,003] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-12-02 06:00:00+00:00
[2024-03-30 11:33:54,024] {standard_task_runner.py:52} INFO - Started process 26851 to run task
[2024-03-30 11:33:54,058] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-12-02T06:00:00+00:00', '--job-id', '2806', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpx53wkrle', '--error-file', '/tmp/tmpobuajgya']
[2024-03-30 11:33:54,077] {standard_task_runner.py:77} INFO - Job 2806: Subtask download_dataset_task
[2024-03-30 11:33:54,288] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:33:54,389] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:33:54,443] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-02T06:00:00+00:00
[2024-03-30 11:33:54,451] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:33:54,453] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-12.parquet']
[2024-03-30 11:33:54,627] {subprocess.py:85} INFO - Output:
[2024-03-30 11:34:00,728] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:34:01,006] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20211202T060000, start_date=20240330T113353, end_date=20240330T113401
[2024-03-30 11:34:01,324] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:34:01,629] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-28 09:15:31,893] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:31,932] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:31,935] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:31,935] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-28 09:15:31,936] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:31,980] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-12-02 06:00:00+00:00
[2024-04-28 09:15:32,037] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-12-02T06:00:00+00:00', '--job-id', '3000', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpr_kvn_vv', '--error-file', '/tmp/tmpluzioi2k']
[2024-04-28 09:15:32,050] {standard_task_runner.py:77} INFO - Job 3000: Subtask download_dataset_task
[2024-04-28 09:15:32,011] {standard_task_runner.py:52} INFO - Started process 1428 to run task
[2024-04-28 09:15:32,202] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [running]> on host 6c6a4ca9ff8e
[2024-04-28 09:15:32,292] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-28 09:15:32,347] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-02T06:00:00+00:00
[2024-04-28 09:15:32,348] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-28 09:15:32,349] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-12.parquet']
[2024-04-28 09:15:32,413] {subprocess.py:85} INFO - Output:
[2024-04-28 09:15:37,429] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-28 09:15:37,714] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20211202T060000, start_date=20240428T091531, end_date=20240428T091537
[2024-04-28 09:15:38,362] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-28 09:15:38,809] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:13:46,736] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-04-30 02:13:46,869] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-04-30 02:13:46,869] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:13:46,869] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-30 02:13:46,869] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:13:46,997] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-12-02 06:00:00+00:00
[2024-04-30 02:13:47,019] {standard_task_runner.py:52} INFO - Started process 312 to run task
[2024-04-30 02:13:47,047] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-12-02T06:00:00+00:00', '--job-id', '3031', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp2vgp70or', '--error-file', '/tmp/tmp3y7j8zbj']
[2024-04-30 02:13:47,116] {standard_task_runner.py:77} INFO - Job 3031: Subtask download_dataset_task
[2024-04-30 02:13:47,511] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [running]> on host a1ae6a0259c5
[2024-04-30 02:13:47,785] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:13:47,961] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-02T06:00:00+00:00
[2024-04-30 02:13:47,962] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 02:13:47,963] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-12.parquet']
[2024-04-30 02:13:48,122] {subprocess.py:85} INFO - Output:
[2024-04-30 02:13:52,348] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 02:13:52,769] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20211202T060000, start_date=20240430T021346, end_date=20240430T021352
[2024-04-30 02:13:52,888] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 02:13:53,189] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:58:13,910] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:13,942] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:13,943] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:13,944] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 02:58:13,944] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:13,972] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-12-02 06:00:00+00:00
[2024-04-30 02:58:13,988] {standard_task_runner.py:52} INFO - Started process 415 to run task
[2024-04-30 02:58:14,014] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-12-02T06:00:00+00:00', '--job-id', '3104', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpzdhnn5b3', '--error-file', '/tmp/tmprtl2fx3e']
[2024-04-30 02:58:14,022] {standard_task_runner.py:77} INFO - Job 3104: Subtask download_dataset_task
[2024-04-30 02:58:14,151] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 02:58:14,249] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:58:14,304] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-02T06:00:00+00:00
[2024-04-30 02:58:14,308] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 02:58:14,310] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-12.parquet']
[2024-04-30 02:58:14,417] {subprocess.py:85} INFO - Output:
[2024-04-30 02:58:18,508] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 02:58:18,803] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20211202T060000, start_date=20240430T025813, end_date=20240430T025818
[2024-04-30 02:58:19,030] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 02:58:19,214] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:01:07,787] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:07,906] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:07,906] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:07,906] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:01:07,907] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:07,978] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-12-02 06:00:00+00:00
[2024-04-30 03:01:08,016] {standard_task_runner.py:52} INFO - Started process 677 to run task
[2024-04-30 03:01:08,079] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-12-02T06:00:00+00:00', '--job-id', '3134', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpwaju5sph', '--error-file', '/tmp/tmp54l82kbc']
[2024-04-30 03:01:08,096] {standard_task_runner.py:77} INFO - Job 3134: Subtask download_dataset_task
[2024-04-30 03:01:08,464] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:01:08,711] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:01:08,937] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-02T06:00:00+00:00
[2024-04-30 03:01:08,952] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 03:01:08,954] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet > /opt/***/cleaned_data/yellowtaxi_tripdata_2021-12.parquet']
[2024-04-30 03:01:09,042] {subprocess.py:85} INFO - Output:
[2024-04-30 03:01:13,315] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 03:01:13,562] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20211202T060000, start_date=20240430T030107, end_date=20240430T030113
[2024-04-30 03:01:13,784] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:01:14,066] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:30:02,710] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-04-30 04:30:02,794] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [queued]>
[2024-04-30 04:30:02,794] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:30:02,794] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:30:02,795] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:30:02,893] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-12-02 06:00:00+00:00
[2024-04-30 04:30:02,944] {standard_task_runner.py:52} INFO - Started process 5201 to run task
[2024-04-30 04:30:03,003] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-12-02T06:00:00+00:00', '--job-id', '3244', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpuk0s1kxl', '--error-file', '/tmp/tmpcnln9kmd']
[2024-04-30 04:30:03,015] {standard_task_runner.py:77} INFO - Job 3244: Subtask download_dataset_task
[2024-04-30 04:30:03,305] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-12-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:30:03,572] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:30:03,669] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-02T06:00:00+00:00
[2024-04-30 04:30:03,679] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 04:30:03,686] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-12.parquet']
[2024-04-30 04:30:03,827] {subprocess.py:85} INFO - Output:
[2024-04-30 04:30:08,280] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 04:30:08,480] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20211202T060000, start_date=20240430T043002, end_date=20240430T043008
[2024-04-30 04:30:08,899] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 04:30:09,190] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
