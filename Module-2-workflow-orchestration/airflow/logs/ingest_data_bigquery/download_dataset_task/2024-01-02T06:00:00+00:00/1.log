[2024-03-30 03:53:59,564] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2024-01-02T06:00:00+00:00 [queued]>
[2024-03-30 03:53:59,691] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2024-01-02T06:00:00+00:00 [queued]>
[2024-03-30 03:53:59,691] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:53:59,691] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:53:59,691] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:53:59,807] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2024-01-02 06:00:00+00:00
[2024-03-30 03:53:59,849] {standard_task_runner.py:52} INFO - Started process 2241 to run task
[2024-03-30 03:53:59,899] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2024-01-02T06:00:00+00:00', '--job-id', '2020', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpul4rt5zo', '--error-file', '/tmp/tmp4rqflg0g']
[2024-03-30 03:53:59,928] {standard_task_runner.py:77} INFO - Job 2020: Subtask download_dataset_task
[2024-03-30 03:54:00,227] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2024-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:54:00,395] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:54:00,452] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2024-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2024-01-02T06:00:00+00:00
[2024-03-30 03:54:00,454] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:54:00,455] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet > /opt/***/yellowtaxi_tripdata_2024-01.parquet']
[2024-03-30 03:54:00,541] {subprocess.py:85} INFO - Output:
[2024-03-30 03:54:07,312] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:54:07,345] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20240102T060000, start_date=20240330T035359, end_date=20240330T035407
[2024-03-30 03:54:07,393] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:54:07,703] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:26:09,276] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2024-01-02T06:00:00+00:00 [queued]>
[2024-03-30 04:26:09,287] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2024-01-02T06:00:00+00:00 [queued]>
[2024-03-30 04:26:09,287] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:26:09,287] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:26:09,288] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:26:09,298] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2024-01-02 06:00:00+00:00
[2024-03-30 04:26:09,305] {standard_task_runner.py:52} INFO - Started process 4549 to run task
[2024-03-30 04:26:09,311] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2024-01-02T06:00:00+00:00', '--job-id', '2253', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp3muzq6ev', '--error-file', '/tmp/tmp9hdz3ieu']
[2024-03-30 04:26:09,317] {standard_task_runner.py:77} INFO - Job 2253: Subtask download_dataset_task
[2024-03-30 04:26:09,388] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2024-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:26:09,441] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:26:09,475] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2024-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2024-01-02T06:00:00+00:00
[2024-03-30 04:26:09,477] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:26:09,478] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet > /opt/***/yellowtaxi_tripdata_2024-01.parquet']
[2024-03-30 04:26:09,496] {subprocess.py:85} INFO - Output:
[2024-03-30 04:26:15,514] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:26:15,548] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20240102T060000, start_date=20240330T042609, end_date=20240330T042615
[2024-03-30 04:26:15,606] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:26:15,651] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:45:00,152] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2024-01-02T06:00:00+00:00 [queued]>
[2024-03-30 04:45:00,239] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2024-01-02T06:00:00+00:00 [queued]>
[2024-03-30 04:45:00,247] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:45:00,247] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:45:00,248] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:45:00,316] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2024-01-02 06:00:00+00:00
[2024-03-30 04:45:00,373] {standard_task_runner.py:52} INFO - Started process 5817 to run task
[2024-03-30 04:45:00,411] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2024-01-02T06:00:00+00:00', '--job-id', '2364', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp50nxmfzt', '--error-file', '/tmp/tmpv3s2h_yr']
[2024-03-30 04:45:00,438] {standard_task_runner.py:77} INFO - Job 2364: Subtask download_dataset_task
[2024-03-30 04:45:00,634] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2024-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:45:00,992] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:45:01,127] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2024-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2024-01-02T06:00:00+00:00
[2024-03-30 04:45:01,136] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:45:01,142] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet > /opt/***/yellowtaxi_tripdata_2024-01.parquet']
[2024-03-30 04:45:01,292] {subprocess.py:85} INFO - Output:
[2024-03-30 04:45:07,551] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:45:07,703] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20240102T060000, start_date=20240330T044500, end_date=20240330T044507
[2024-03-30 04:45:08,150] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:45:08,421] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 05:00:42,029] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2024-01-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:42,041] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2024-01-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:42,041] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:42,041] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 05:00:42,041] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:42,053] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2024-01-02 06:00:00+00:00
[2024-03-30 05:00:42,059] {standard_task_runner.py:52} INFO - Started process 6979 to run task
[2024-03-30 05:00:42,065] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2024-01-02T06:00:00+00:00', '--job-id', '2496', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp8zpy4_zz', '--error-file', '/tmp/tmpkalisdts']
[2024-03-30 05:00:42,071] {standard_task_runner.py:77} INFO - Job 2496: Subtask download_dataset_task
[2024-03-30 05:00:42,139] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2024-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 05:00:42,180] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 05:00:42,204] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2024-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2024-01-02T06:00:00+00:00
[2024-03-30 05:00:42,206] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 05:00:42,207] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet > /opt/***/yellowtaxi_tripdata_2024-01.parquet']
[2024-03-30 05:00:42,220] {subprocess.py:85} INFO - Output:
[2024-03-30 05:00:48,164] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 05:00:48,236] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20240102T060000, start_date=20240330T050042, end_date=20240330T050048
[2024-03-30 05:00:48,311] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 05:00:48,382] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:03:26,667] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2024-01-02T06:00:00+00:00 [queued]>
[2024-03-30 09:03:26,683] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2024-01-02T06:00:00+00:00 [queued]>
[2024-03-30 09:03:26,684] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:03:26,684] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:03:26,684] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:03:26,696] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2024-01-02 06:00:00+00:00
[2024-03-30 09:03:26,703] {standard_task_runner.py:52} INFO - Started process 18529 to run task
[2024-03-30 09:03:26,709] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2024-01-02T06:00:00+00:00', '--job-id', '2614', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpkp0e3wqh', '--error-file', '/tmp/tmp8m4krhtq']
[2024-03-30 09:03:26,715] {standard_task_runner.py:77} INFO - Job 2614: Subtask download_dataset_task
[2024-03-30 09:03:26,796] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2024-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:03:26,844] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:03:26,868] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2024-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2024-01-02T06:00:00+00:00
[2024-03-30 09:03:26,869] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 09:03:26,870] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet > /opt/***/yellowtaxi_tripdata_2024-01.parquet']
[2024-03-30 09:03:26,882] {subprocess.py:85} INFO - Output:
[2024-03-30 09:03:32,949] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 09:03:33,010] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20240102T060000, start_date=20240330T090326, end_date=20240330T090333
[2024-03-30 09:03:33,090] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:03:33,152] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 12:08:35,419] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2024-01-02T06:00:00+00:00 [queued]>
[2024-03-30 12:08:35,430] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2024-01-02T06:00:00+00:00 [queued]>
[2024-03-30 12:08:35,430] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 12:08:35,431] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 12:08:35,431] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 12:08:35,443] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2024-01-02 06:00:00+00:00
[2024-03-30 12:08:35,449] {standard_task_runner.py:52} INFO - Started process 29673 to run task
[2024-03-30 12:08:35,455] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2024-01-02T06:00:00+00:00', '--job-id', '2954', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpbe96e6pj', '--error-file', '/tmp/tmpw_mzf82b']
[2024-03-30 12:08:35,460] {standard_task_runner.py:77} INFO - Job 2954: Subtask download_dataset_task
[2024-03-30 12:08:35,539] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2024-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 12:08:35,590] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 12:08:35,621] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2024-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2024-01-02T06:00:00+00:00
[2024-03-30 12:08:35,623] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 12:08:35,625] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2024-01.parquet']
[2024-03-30 12:08:35,641] {subprocess.py:85} INFO - Output:
[2024-03-30 12:08:41,796] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 12:08:41,997] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20240102T060000, start_date=20240330T120835, end_date=20240330T120841
[2024-03-30 12:08:42,026] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 12:08:42,065] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:02:28,999] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2024-01-02T06:00:00+00:00 [queued]>
[2024-04-30 03:02:29,015] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2024-01-02T06:00:00+00:00 [queued]>
[2024-04-30 03:02:29,016] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:02:29,016] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:02:29,016] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:02:29,030] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2024-01-02 06:00:00+00:00
[2024-04-30 03:02:29,036] {standard_task_runner.py:52} INFO - Started process 1048 to run task
[2024-04-30 03:02:29,043] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2024-01-02T06:00:00+00:00', '--job-id', '3222', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpbli8u8gz', '--error-file', '/tmp/tmptvbg_ped']
[2024-04-30 03:02:29,049] {standard_task_runner.py:77} INFO - Job 3222: Subtask download_dataset_task
[2024-04-30 03:02:29,124] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2024-01-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:02:29,171] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:02:29,199] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2024-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2024-01-02T06:00:00+00:00
[2024-04-30 03:02:29,201] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 03:02:29,202] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet > /opt/***/cleaned_data/yellowtaxi_tripdata_2024-01.parquet']
[2024-04-30 03:02:29,216] {subprocess.py:85} INFO - Output:
[2024-04-30 03:02:33,520] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 03:02:33,626] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20240102T060000, start_date=20240430T030229, end_date=20240430T030233
[2024-04-30 03:02:33,739] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:02:33,883] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 06:43:59,605] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2024-01-02T06:00:00+00:00 [queued]>
[2024-04-30 06:43:59,697] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2024-01-02T06:00:00+00:00 [queued]>
[2024-04-30 06:43:59,697] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 06:43:59,697] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 06:43:59,697] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 06:43:59,841] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2024-01-02 06:00:00+00:00
[2024-04-30 06:43:59,885] {standard_task_runner.py:52} INFO - Started process 96 to run task
[2024-04-30 06:43:59,977] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2024-01-02T06:00:00+00:00', '--job-id', '3646', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpoo0f76l3', '--error-file', '/tmp/tmph77l6vpp']
[2024-04-30 06:44:00,009] {standard_task_runner.py:77} INFO - Job 3646: Subtask download_dataset_task
[2024-04-30 06:44:00,438] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2024-01-02T06:00:00+00:00 [running]> on host 4d5ad4aa2a9b
[2024-04-30 06:44:00,720] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 06:44:00,842] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2024-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2024-01-02T06:00:00+00:00
[2024-04-30 06:44:00,845] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 06:44:00,845] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2024-01.parquet']
[2024-04-30 06:44:00,905] {subprocess.py:85} INFO - Output:
[2024-04-30 06:44:05,273] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 06:44:05,383] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20240102T060000, start_date=20240430T064359, end_date=20240430T064405
[2024-04-30 06:44:05,456] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 06:44:05,595] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
