[2024-03-29 08:27:20,660] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [queued]>
[2024-03-29 08:27:20,724] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [queued]>
[2024-03-29 08:27:20,739] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:27:20,746] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:27:20,746] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:27:20,807] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-05-02 06:00:00+00:00
[2024-03-29 08:27:20,890] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-05-02T06:00:00+00:00', '--job-id', '1777', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp_gtgxjx6', '--error-file', '/tmp/tmpmh8ew0d_']
[2024-03-29 08:27:20,909] {standard_task_runner.py:77} INFO - Job 1777: Subtask download_dataset_task
[2024-03-29 08:27:20,843] {standard_task_runner.py:52} INFO - Started process 1562 to run task
[2024-03-29 08:27:21,439] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:27:21,796] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:27:21,965] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-05-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-05-02T06:00:00+00:00
[2024-03-29 08:27:21,966] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:27:21,967] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-05.parquet > /opt/***/yellowtaxi_tripdata_2023-05.parquet']
[2024-03-29 08:27:22,087] {subprocess.py:85} INFO - Output:
[2024-03-29 08:27:28,882] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:27:28,989] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230502T060000, start_date=20240329T082720, end_date=20240329T082728
[2024-03-29 08:27:29,045] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:27:29,145] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:53:25,303] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [queued]>
[2024-03-30 03:53:25,428] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [queued]>
[2024-03-30 03:53:25,429] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:53:25,430] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:53:25,430] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:53:25,548] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-05-02 06:00:00+00:00
[2024-03-30 03:53:25,620] {standard_task_runner.py:52} INFO - Started process 2109 to run task
[2024-03-30 03:53:25,662] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-05-02T06:00:00+00:00', '--job-id', '1989', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp_3igb3kb', '--error-file', '/tmp/tmpgzgi7srm']
[2024-03-30 03:53:25,706] {standard_task_runner.py:77} INFO - Job 1989: Subtask download_dataset_task
[2024-03-30 03:53:26,168] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:53:26,512] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:53:26,631] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-05-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-05-02T06:00:00+00:00
[2024-03-30 03:53:26,632] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:53:26,633] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-05.parquet > /opt/***/yellowtaxi_tripdata_2023-05.parquet']
[2024-03-30 03:53:26,666] {subprocess.py:85} INFO - Output:
[2024-03-30 03:53:33,830] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:53:33,926] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230502T060000, start_date=20240330T035325, end_date=20240330T035333
[2024-03-30 03:53:34,049] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:53:34,194] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:19:01,424] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [queued]>
[2024-03-30 04:19:01,556] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [queued]>
[2024-03-30 04:19:01,557] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:19:01,557] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:19:01,557] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:19:01,718] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-05-02 06:00:00+00:00
[2024-03-30 04:19:01,840] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-05-02T06:00:00+00:00', '--job-id', '2135', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpqmwltito', '--error-file', '/tmp/tmpy41ely8f']
[2024-03-30 04:19:01,778] {standard_task_runner.py:52} INFO - Started process 3779 to run task
[2024-03-30 04:19:01,969] {standard_task_runner.py:77} INFO - Job 2135: Subtask download_dataset_task
[2024-03-30 04:19:02,693] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:19:03,061] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:19:03,164] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-05-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-05-02T06:00:00+00:00
[2024-03-30 04:19:03,166] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:19:03,167] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-05.parquet > /opt/***/yellowtaxi_tripdata_2023-05.parquet']
[2024-03-30 04:19:03,232] {subprocess.py:85} INFO - Output:
[2024-03-30 04:19:10,613] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:19:10,675] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230502T060000, start_date=20240330T041901, end_date=20240330T041910
[2024-03-30 04:19:10,763] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:19:10,919] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:25:33,072] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [queued]>
[2024-03-30 04:25:33,189] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [queued]>
[2024-03-30 04:25:33,189] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:25:33,189] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:25:33,189] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:25:33,296] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-05-02 06:00:00+00:00
[2024-03-30 04:25:33,354] {standard_task_runner.py:52} INFO - Started process 4393 to run task
[2024-03-30 04:25:33,409] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-05-02T06:00:00+00:00', '--job-id', '2213', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpoyxv_zto', '--error-file', '/tmp/tmpnc6d1rcb']
[2024-03-30 04:25:33,452] {standard_task_runner.py:77} INFO - Job 2213: Subtask download_dataset_task
[2024-03-30 04:25:33,675] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:25:33,805] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:25:33,856] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-05-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-05-02T06:00:00+00:00
[2024-03-30 04:25:33,858] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:25:33,859] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-05.parquet > /opt/***/yellowtaxi_tripdata_2023-05.parquet']
[2024-03-30 04:25:33,947] {subprocess.py:85} INFO - Output:
[2024-03-30 04:25:40,667] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:25:40,967] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230502T060000, start_date=20240330T042533, end_date=20240330T042540
[2024-03-30 04:25:41,135] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:25:41,418] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:44:50,192] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [queued]>
[2024-03-30 04:44:50,327] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [queued]>
[2024-03-30 04:44:50,327] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:44:50,327] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:44:50,327] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:44:50,447] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-05-02 06:00:00+00:00
[2024-03-30 04:44:50,491] {standard_task_runner.py:52} INFO - Started process 5767 to run task
[2024-03-30 04:44:50,538] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-05-02T06:00:00+00:00', '--job-id', '2356', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpnif5owlk', '--error-file', '/tmp/tmp6rfxwk0d']
[2024-03-30 04:44:50,618] {standard_task_runner.py:77} INFO - Job 2356: Subtask download_dataset_task
[2024-03-30 04:44:51,477] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:44:51,984] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:44:52,101] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-05-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-05-02T06:00:00+00:00
[2024-03-30 04:44:52,110] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:44:52,115] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-05.parquet > /opt/***/yellowtaxi_tripdata_2023-05.parquet']
[2024-03-30 04:44:52,234] {subprocess.py:85} INFO - Output:
[2024-03-30 04:45:00,282] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:45:00,841] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230502T060000, start_date=20240330T044450, end_date=20240330T044500
[2024-03-30 04:45:01,089] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:45:01,184] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 05:00:08,859] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:08,917] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:08,918] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:08,918] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 05:00:08,919] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:08,967] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-05-02 06:00:00+00:00
[2024-03-30 05:00:08,982] {standard_task_runner.py:52} INFO - Started process 6837 to run task
[2024-03-30 05:00:09,059] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-05-02T06:00:00+00:00', '--job-id', '2459', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpy2tr8nrc', '--error-file', '/tmp/tmp06y_s64h']
[2024-03-30 05:00:09,080] {standard_task_runner.py:77} INFO - Job 2459: Subtask download_dataset_task
[2024-03-30 05:00:09,462] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 05:00:09,653] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 05:00:09,701] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-05-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-05-02T06:00:00+00:00
[2024-03-30 05:00:09,703] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 05:00:09,704] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-05.parquet > /opt/***/yellowtaxi_tripdata_2023-05.parquet']
[2024-03-30 05:00:09,771] {subprocess.py:85} INFO - Output:
[2024-03-30 05:00:16,674] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 05:00:17,186] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230502T060000, start_date=20240330T050008, end_date=20240330T050017
[2024-03-30 05:00:17,296] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 05:00:17,480] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:02:21,950] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [queued]>
[2024-03-30 09:02:22,083] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [queued]>
[2024-03-30 09:02:22,083] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:02:22,083] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:02:22,086] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:02:22,168] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-05-02 06:00:00+00:00
[2024-03-30 09:02:22,214] {standard_task_runner.py:52} INFO - Started process 18361 to run task
[2024-03-30 09:02:22,267] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-05-02T06:00:00+00:00', '--job-id', '2575', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpmdf0vdnf', '--error-file', '/tmp/tmp7lpotkyc']
[2024-03-30 09:02:22,305] {standard_task_runner.py:77} INFO - Job 2575: Subtask download_dataset_task
[2024-03-30 09:02:23,009] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:02:23,174] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:02:23,217] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-05-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-05-02T06:00:00+00:00
[2024-03-30 09:02:23,221] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 09:02:23,222] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-05.parquet > /opt/***/yellowtaxi_tripdata_2023-05.parquet']
[2024-03-30 09:02:23,279] {subprocess.py:85} INFO - Output:
[2024-03-30 09:02:30,821] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 09:02:31,504] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230502T060000, start_date=20240330T090221, end_date=20240330T090231
[2024-03-30 09:02:32,291] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:02:33,096] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:57:19,635] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [queued]>
[2024-03-30 11:57:19,668] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [queued]>
[2024-03-30 11:57:19,669] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:57:19,669] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:57:19,670] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:57:19,704] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-05-02 06:00:00+00:00
[2024-03-30 11:57:19,727] {standard_task_runner.py:52} INFO - Started process 28548 to run task
[2024-03-30 11:57:19,751] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-05-02T06:00:00+00:00', '--job-id', '2899', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmphxgf8fbe', '--error-file', '/tmp/tmpnn4su_ho']
[2024-03-30 11:57:19,770] {standard_task_runner.py:77} INFO - Job 2899: Subtask download_dataset_task
[2024-03-30 11:57:19,994] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:57:20,187] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:57:20,254] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-05-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-05-02T06:00:00+00:00
[2024-03-30 11:57:20,256] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:57:20,257] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-05.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2023-05.parquet']
[2024-03-30 11:57:20,301] {subprocess.py:85} INFO - Output:
[2024-03-30 11:57:27,244] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:57:27,309] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230502T060000, start_date=20240330T115719, end_date=20240330T115727
[2024-03-30 11:57:27,357] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:57:27,495] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:01:51,196] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:51,298] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:51,299] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:51,299] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:01:51,303] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:51,366] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-05-02 06:00:00+00:00
[2024-04-30 03:01:51,414] {standard_task_runner.py:52} INFO - Started process 898 to run task
[2024-04-30 03:01:51,478] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-05-02T06:00:00+00:00', '--job-id', '3182', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpwqzj4hae', '--error-file', '/tmp/tmp0i8mmmei']
[2024-04-30 03:01:51,515] {standard_task_runner.py:77} INFO - Job 3182: Subtask download_dataset_task
[2024-04-30 03:01:51,919] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:01:52,190] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:01:52,342] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-05-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-05-02T06:00:00+00:00
[2024-04-30 03:01:52,355] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 03:01:52,356] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-05.parquet > /opt/***/cleaned_data/yellowtaxi_tripdata_2023-05.parquet']
[2024-04-30 03:01:52,474] {subprocess.py:85} INFO - Output:
[2024-04-30 03:01:57,793] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 03:01:57,976] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230502T060000, start_date=20240430T030151, end_date=20240430T030157
[2024-04-30 03:01:58,269] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:01:58,560] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:35:03,411] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [queued]>
[2024-04-30 04:35:03,439] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [queued]>
[2024-04-30 04:35:03,439] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:35:03,440] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:35:03,440] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:35:03,479] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-05-02 06:00:00+00:00
[2024-04-30 04:35:03,489] {standard_task_runner.py:52} INFO - Started process 5784 to run task
[2024-04-30 04:35:03,504] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-05-02T06:00:00+00:00', '--job-id', '3308', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmppl8e1p9t', '--error-file', '/tmp/tmpcmup5nxr']
[2024-04-30 04:35:03,521] {standard_task_runner.py:77} INFO - Job 3308: Subtask download_dataset_task
[2024-04-30 04:35:03,691] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-05-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:35:03,771] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:35:03,835] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-05-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-05-02T06:00:00+00:00
[2024-04-30 04:35:03,836] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 04:35:03,837] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-05.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2023-05.parquet']
[2024-04-30 04:35:03,891] {subprocess.py:85} INFO - Output:
[2024-04-30 04:35:08,553] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 04:35:08,599] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230502T060000, start_date=20240430T043503, end_date=20240430T043508
[2024-04-30 04:35:08,645] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 04:35:08,692] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
