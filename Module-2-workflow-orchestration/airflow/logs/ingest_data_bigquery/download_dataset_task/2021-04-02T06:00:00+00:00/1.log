[2024-03-29 07:24:26,154] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:26,226] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:26,227] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:26,227] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:24:26,228] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:26,309] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-04-02 06:00:00+00:00
[2024-03-29 07:24:26,360] {standard_task_runner.py:52} INFO - Started process 474 to run task
[2024-03-29 07:24:26,427] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '1440', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp4kqsyqmr', '--error-file', '/tmp/tmpyk5n7lhj']
[2024-03-29 07:24:26,464] {standard_task_runner.py:77} INFO - Job 1440: Subtask download_dataset_task
[2024-03-29 07:24:26,827] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:24:26,979] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:24:27,084] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-03-29 07:24:27,089] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:24:27,090] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet > /opt/***/yellowtaxi_tripdata_2021-04.parquet']
[2024-03-29 07:24:27,116] {subprocess.py:85} INFO - Output:
[2024-03-29 07:24:32,057] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:24:32,594] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210402T060000, start_date=20240329T072426, end_date=20240329T072432
[2024-03-29 07:24:32,780] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:24:33,850] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:30:43,886] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-29 07:30:43,935] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-29 07:30:43,935] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:30:43,936] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:30:43,936] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:30:44,011] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-04-02 06:00:00+00:00
[2024-03-29 07:30:44,047] {standard_task_runner.py:52} INFO - Started process 981 to run task
[2024-03-29 07:30:44,082] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '1502', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp502mcv4e', '--error-file', '/tmp/tmpsht32wx8']
[2024-03-29 07:30:44,141] {standard_task_runner.py:77} INFO - Job 1502: Subtask download_dataset_task
[2024-03-29 07:30:44,405] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:30:44,591] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:30:44,693] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-03-29 07:30:44,694] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:30:44,695] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet > /opt/***/yellowtaxi_tripdata_2021-04.parquet']
[2024-03-29 07:30:44,788] {subprocess.py:85} INFO - Output:
[2024-03-29 07:30:49,857] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:30:50,403] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210402T060000, start_date=20240329T073043, end_date=20240329T073050
[2024-03-29 07:30:50,485] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:30:50,557] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:37:24,689] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:24,764] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:24,765] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:24,766] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:37:24,766] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:24,823] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-04-02 06:00:00+00:00
[2024-03-29 07:37:24,845] {standard_task_runner.py:52} INFO - Started process 1491 to run task
[2024-03-29 07:37:24,898] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '1563', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpz_1p64f7', '--error-file', '/tmp/tmpagzfoq36']
[2024-03-29 07:37:24,936] {standard_task_runner.py:77} INFO - Job 1563: Subtask download_dataset_task
[2024-03-29 07:37:25,140] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:37:25,305] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:37:25,389] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-03-29 07:37:25,391] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:37:25,392] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet > /opt/***/yellowtaxi_tripdata_2021-04.parquet']
[2024-03-29 07:37:25,462] {subprocess.py:85} INFO - Output:
[2024-03-29 07:37:30,369] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:37:30,943] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210402T060000, start_date=20240329T073724, end_date=20240329T073730
[2024-03-29 07:37:31,099] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:37:31,712] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:08:27,126] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:27,254] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:27,254] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:27,254] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:08:27,254] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:27,411] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-04-02 06:00:00+00:00
[2024-03-29 08:08:27,420] {standard_task_runner.py:52} INFO - Started process 182 to run task
[2024-03-29 08:08:27,490] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '1623', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpts_xsjfm', '--error-file', '/tmp/tmpxqhiyzx5']
[2024-03-29 08:08:27,552] {standard_task_runner.py:77} INFO - Job 1623: Subtask download_dataset_task
[2024-03-29 08:08:27,671] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:08:27,792] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:08:27,881] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-03-29 08:08:27,882] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:08:27,884] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet > /opt/***/yellowtaxi_tripdata_2021-04.parquet']
[2024-03-29 08:08:27,958] {subprocess.py:85} INFO - Output:
[2024-03-29 08:08:33,024] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:08:33,224] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210402T060000, start_date=20240329T080827, end_date=20240329T080833
[2024-03-29 08:08:33,308] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:08:33,434] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:10:53,349] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-29 08:10:53,479] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-29 08:10:53,482] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:10:53,482] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:10:53,483] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:10:53,602] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-04-02 06:00:00+00:00
[2024-03-29 08:10:53,695] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '1671', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmphno1o7ue', '--error-file', '/tmp/tmp7p2qafl0']
[2024-03-29 08:10:53,739] {standard_task_runner.py:77} INFO - Job 1671: Subtask download_dataset_task
[2024-03-29 08:10:53,683] {standard_task_runner.py:52} INFO - Started process 467 to run task
[2024-03-29 08:10:54,215] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:10:54,378] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:10:54,523] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-03-29 08:10:54,535] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:10:54,542] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet > /opt/***/yellowtaxi_tripdata_2021-04.parquet']
[2024-03-29 08:10:54,697] {subprocess.py:85} INFO - Output:
[2024-03-29 08:10:59,818] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:11:00,013] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210402T060000, start_date=20240329T081053, end_date=20240329T081100
[2024-03-29 08:11:00,095] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:11:00,211] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:30:03,847] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:03,893] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:03,894] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:03,896] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:30:03,897] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:03,947] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-04-02 06:00:00+00:00
[2024-03-30 03:30:03,980] {standard_task_runner.py:52} INFO - Started process 427 to run task
[2024-03-30 03:30:04,025] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '1816', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp99pu1_6h', '--error-file', '/tmp/tmpk_8mmji9']
[2024-03-30 03:30:04,059] {standard_task_runner.py:77} INFO - Job 1816: Subtask download_dataset_task
[2024-03-30 03:30:04,384] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:30:04,680] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:30:04,784] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-03-30 03:30:04,785] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:30:04,795] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet > /opt/***/yellowtaxi_tripdata_2021-04.parquet']
[2024-03-30 03:30:04,958] {subprocess.py:85} INFO - Output:
[2024-03-30 03:30:10,417] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:30:10,490] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210402T060000, start_date=20240330T033003, end_date=20240330T033010
[2024-03-30 03:30:10,566] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:30:10,627] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:41:55,167] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-30 03:41:55,263] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-30 03:41:55,264] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:41:55,264] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:41:55,265] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:41:55,309] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-04-02 06:00:00+00:00
[2024-03-30 03:41:55,353] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '1896', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp2ksveb5z', '--error-file', '/tmp/tmpy740ldk3']
[2024-03-30 03:41:55,360] {standard_task_runner.py:77} INFO - Job 1896: Subtask download_dataset_task
[2024-03-30 03:41:55,330] {standard_task_runner.py:52} INFO - Started process 1255 to run task
[2024-03-30 03:41:55,617] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:41:55,798] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:41:55,862] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-03-30 03:41:55,864] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:41:55,865] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet > /opt/***/yellowtaxi_tripdata_2021-04.parquet']
[2024-03-30 03:41:55,952] {subprocess.py:85} INFO - Output:
[2024-03-30 03:42:00,907] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:42:01,257] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210402T060000, start_date=20240330T034155, end_date=20240330T034201
[2024-03-30 03:42:01,439] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:42:01,606] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:18:00,743] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:00,887] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:00,887] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:00,888] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:18:00,889] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:00,968] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-04-02 06:00:00+00:00
[2024-03-30 04:18:01,084] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '2075', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp4159rp7m', '--error-file', '/tmp/tmpni0ulcy2']
[2024-03-30 04:18:01,150] {standard_task_runner.py:77} INFO - Job 2075: Subtask download_dataset_task
[2024-03-30 04:18:01,024] {standard_task_runner.py:52} INFO - Started process 3492 to run task
[2024-03-30 04:18:01,761] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:18:02,118] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:18:02,299] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-03-30 04:18:02,301] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:18:02,302] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet > /opt/***/yellowtaxi_tripdata_2021-04.parquet']
[2024-03-30 04:18:02,503] {subprocess.py:85} INFO - Output:
[2024-03-30 04:18:07,563] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:18:07,868] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210402T060000, start_date=20240330T041800, end_date=20240330T041807
[2024-03-30 04:18:07,936] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:18:08,683] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:24:38,887] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-30 04:24:38,943] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-30 04:24:38,943] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:24:38,943] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:24:38,943] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:24:39,022] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-04-02 06:00:00+00:00
[2024-03-30 04:24:39,097] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '2155', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp7dw8fyir', '--error-file', '/tmp/tmpx0xntv8s']
[2024-03-30 04:24:39,189] {standard_task_runner.py:77} INFO - Job 2155: Subtask download_dataset_task
[2024-03-30 04:24:39,078] {standard_task_runner.py:52} INFO - Started process 4113 to run task
[2024-03-30 04:24:39,567] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:24:39,825] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:24:39,911] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-03-30 04:24:39,914] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:24:39,917] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet > /opt/***/yellowtaxi_tripdata_2021-04.parquet']
[2024-03-30 04:24:40,030] {subprocess.py:85} INFO - Output:
[2024-03-30 04:24:44,960] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:24:45,061] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210402T060000, start_date=20240330T042438, end_date=20240330T042445
[2024-03-30 04:24:45,150] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:24:45,315] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:38:36,084] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-30 04:38:36,105] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-30 04:38:36,106] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:38:36,106] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:38:36,106] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:38:36,150] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-04-02 06:00:00+00:00
[2024-03-30 04:38:36,229] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '2271', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpv4zdlina', '--error-file', '/tmp/tmp3ip_0y1c']
[2024-03-30 04:38:36,198] {standard_task_runner.py:52} INFO - Started process 5177 to run task
[2024-03-30 04:38:36,270] {standard_task_runner.py:77} INFO - Job 2271: Subtask download_dataset_task
[2024-03-30 04:38:36,571] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:38:37,057] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:38:37,341] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-03-30 04:38:37,342] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:38:37,343] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet > /opt/***/yellowtaxi_tripdata_2021-04.parquet']
[2024-03-30 04:38:37,753] {subprocess.py:85} INFO - Output:
[2024-03-30 04:38:43,191] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:38:43,498] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210402T060000, start_date=20240330T043836, end_date=20240330T043843
[2024-03-30 04:38:43,603] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:38:43,916] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:59:20,592] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:20,637] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:20,638] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:20,642] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:59:20,643] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:20,707] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-04-02 06:00:00+00:00
[2024-03-30 04:59:20,729] {standard_task_runner.py:52} INFO - Started process 6576 to run task
[2024-03-30 04:59:20,803] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '2402', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmplxc_1a_l', '--error-file', '/tmp/tmpsp8qd6xo']
[2024-03-30 04:59:20,848] {standard_task_runner.py:77} INFO - Job 2402: Subtask download_dataset_task
[2024-03-30 04:59:21,380] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:59:21,670] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:59:21,806] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-03-30 04:59:21,807] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:59:21,813] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet > /opt/***/yellowtaxi_tripdata_2021-04.parquet']
[2024-03-30 04:59:21,951] {subprocess.py:85} INFO - Output:
[2024-03-30 04:59:27,025] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:59:27,110] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210402T060000, start_date=20240330T045920, end_date=20240330T045927
[2024-03-30 04:59:27,231] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:59:27,338] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:01:25,222] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:25,287] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:25,288] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:25,289] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:01:25,289] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:25,329] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-04-02 06:00:00+00:00
[2024-03-30 09:01:25,419] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '2517', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpaslthadu', '--error-file', '/tmp/tmpk2wgjqra']
[2024-03-30 09:01:25,464] {standard_task_runner.py:77} INFO - Job 2517: Subtask download_dataset_task
[2024-03-30 09:01:25,349] {standard_task_runner.py:52} INFO - Started process 18090 to run task
[2024-03-30 09:01:25,747] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:01:25,840] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:01:25,994] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-03-30 09:01:25,997] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 09:01:25,999] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet > /opt/***/yellowtaxi_tripdata_2021-04.parquet']
[2024-03-30 09:01:26,107] {subprocess.py:85} INFO - Output:
[2024-03-30 09:01:31,038] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 09:01:31,191] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210402T060000, start_date=20240330T090125, end_date=20240330T090131
[2024-03-30 09:01:31,359] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:01:31,975] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 10:49:58,024] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-30 10:49:58,082] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-30 10:49:58,083] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:49:58,084] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 10:49:58,085] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:49:58,243] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-04-02 06:00:00+00:00
[2024-03-30 10:49:58,286] {standard_task_runner.py:52} INFO - Started process 23462 to run task
[2024-03-30 10:49:58,352] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '2628', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp94chqnor', '--error-file', '/tmp/tmpo8fjqtpz']
[2024-03-30 10:49:58,419] {standard_task_runner.py:77} INFO - Job 2628: Subtask download_dataset_task
[2024-03-30 10:49:58,883] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 10:49:59,060] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 10:49:59,166] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-03-30 10:49:59,168] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 10:49:59,169] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet > /opt/***raw_data/yellowtaxi_tripdata_2021-04.parquet']
[2024-03-30 10:49:59,218] {subprocess.py:85} INFO - Output:
[2024-03-30 10:49:59,247] {subprocess.py:89} INFO - bash: /opt/***raw_data/yellowtaxi_tripdata_2021-04.parquet: No such file or directory
[2024-03-30 10:49:59,248] {subprocess.py:93} INFO - Command exited with return code 1
[2024-03-30 10:49:59,315] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:49:59,356] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210402T060000, start_date=20240330T104958, end_date=20240330T104959
[2024-03-30 10:49:59,436] {standard_task_runner.py:92} ERROR - Failed to execute job 2628 for task download_dataset_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:49:59,502] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 10:49:59,651] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 10:54:50,687] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-30 10:54:50,771] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-30 10:54:50,771] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:54:50,772] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 10:54:50,773] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:54:50,827] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-04-02 06:00:00+00:00
[2024-03-30 10:54:50,869] {standard_task_runner.py:52} INFO - Started process 23753 to run task
[2024-03-30 10:54:50,889] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '2645', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp88z6nv6d', '--error-file', '/tmp/tmpxii_l1al']
[2024-03-30 10:54:50,917] {standard_task_runner.py:77} INFO - Job 2645: Subtask download_dataset_task
[2024-03-30 10:54:51,127] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 10:54:51,217] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 10:54:51,284] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-03-30 10:54:51,286] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 10:54:51,288] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet > /opt/***raw_data/yellowtaxi_tripdata_2021-04.parquet']
[2024-03-30 10:54:51,356] {subprocess.py:85} INFO - Output:
[2024-03-30 10:54:51,393] {subprocess.py:89} INFO - bash: /opt/***raw_data/yellowtaxi_tripdata_2021-04.parquet: No such file or directory
[2024-03-30 10:54:51,397] {subprocess.py:93} INFO - Command exited with return code 1
[2024-03-30 10:54:51,722] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:54:51,753] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210402T060000, start_date=20240330T105450, end_date=20240330T105451
[2024-03-30 10:54:51,876] {standard_task_runner.py:92} ERROR - Failed to execute job 2645 for task download_dataset_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:54:51,991] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 10:54:52,392] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:03:53,842] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-30 11:03:53,881] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-30 11:03:53,881] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:03:53,882] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:03:53,882] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:03:53,914] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-04-02 06:00:00+00:00
[2024-03-30 11:03:53,923] {standard_task_runner.py:52} INFO - Started process 24323 to run task
[2024-03-30 11:03:53,953] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '2676', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmprv231fh6', '--error-file', '/tmp/tmpgfpd3j7z']
[2024-03-30 11:03:53,995] {standard_task_runner.py:77} INFO - Job 2676: Subtask download_dataset_task
[2024-03-30 11:03:54,240] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:03:54,380] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:03:54,449] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-03-30 11:03:54,451] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:03:54,452] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-04.parquet']
[2024-03-30 11:03:54,511] {subprocess.py:85} INFO - Output:
[2024-03-30 11:03:59,483] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:04:00,053] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210402T060000, start_date=20240330T110353, end_date=20240330T110400
[2024-03-30 11:04:00,223] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:04:00,400] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:15:04,955] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-30 11:15:05,031] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-30 11:15:05,031] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:15:05,031] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:15:05,031] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:15:05,108] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-04-02 06:00:00+00:00
[2024-03-30 11:15:05,144] {standard_task_runner.py:52} INFO - Started process 25233 to run task
[2024-03-30 11:15:05,176] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '2722', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpw2r00hvs', '--error-file', '/tmp/tmpbgte9vk3']
[2024-03-30 11:15:05,210] {standard_task_runner.py:77} INFO - Job 2722: Subtask download_dataset_task
[2024-03-30 11:15:05,561] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:15:05,667] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:15:05,725] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-03-30 11:15:05,729] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:15:05,730] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-04.parquet']
[2024-03-30 11:15:05,763] {subprocess.py:85} INFO - Output:
[2024-03-30 11:15:10,682] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:15:11,089] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210402T060000, start_date=20240330T111504, end_date=20240330T111511
[2024-03-30 11:15:11,182] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:15:11,401] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:33:49,637] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-30 11:33:49,792] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-30 11:33:49,794] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:33:49,798] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:33:49,830] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:33:49,939] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-04-02 06:00:00+00:00
[2024-03-30 11:33:50,073] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '2799', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpyo5cb4pb', '--error-file', '/tmp/tmpfoennaua']
[2024-03-30 11:33:50,171] {standard_task_runner.py:77} INFO - Job 2799: Subtask download_dataset_task
[2024-03-30 11:33:50,025] {standard_task_runner.py:52} INFO - Started process 26820 to run task
[2024-03-30 11:33:50,617] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:33:50,908] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:33:51,075] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-03-30 11:33:51,084] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:33:51,085] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-04.parquet']
[2024-03-30 11:33:51,136] {subprocess.py:85} INFO - Output:
[2024-03-30 11:33:55,973] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:33:56,062] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210402T060000, start_date=20240330T113349, end_date=20240330T113356
[2024-03-30 11:33:56,190] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:33:56,291] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-28 09:15:29,741] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:29,900] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:29,911] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:29,911] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-28 09:15:29,912] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:30,105] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-04-02 06:00:00+00:00
[2024-04-28 09:15:30,335] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '2992', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpxngy08wm', '--error-file', '/tmp/tmpjjl91f9t']
[2024-04-28 09:15:30,391] {standard_task_runner.py:77} INFO - Job 2992: Subtask download_dataset_task
[2024-04-28 09:15:30,258] {standard_task_runner.py:52} INFO - Started process 1384 to run task
[2024-04-28 09:15:30,796] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host 6c6a4ca9ff8e
[2024-04-28 09:15:31,104] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-28 09:15:31,201] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-04-28 09:15:31,207] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-28 09:15:31,220] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-04.parquet']
[2024-04-28 09:15:31,402] {subprocess.py:85} INFO - Output:
[2024-04-28 09:15:35,384] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-28 09:15:35,882] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210402T060000, start_date=20240428T091529, end_date=20240428T091535
[2024-04-28 09:15:36,359] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-28 09:15:36,939] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:13:46,847] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-04-30 02:13:46,906] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-04-30 02:13:46,908] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:13:46,914] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-30 02:13:46,915] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:13:46,988] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-04-02 06:00:00+00:00
[2024-04-30 02:13:47,022] {standard_task_runner.py:52} INFO - Started process 311 to run task
[2024-04-30 02:13:47,051] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '3032', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmptyhl117p', '--error-file', '/tmp/tmpx9w3_wjs']
[2024-04-30 02:13:47,108] {standard_task_runner.py:77} INFO - Job 3032: Subtask download_dataset_task
[2024-04-30 02:13:47,429] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host a1ae6a0259c5
[2024-04-30 02:13:47,611] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:13:47,776] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-04-30 02:13:47,778] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 02:13:47,778] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-04.parquet']
[2024-04-30 02:13:47,993] {subprocess.py:85} INFO - Output:
[2024-04-30 02:13:51,779] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 02:13:51,821] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210402T060000, start_date=20240430T021346, end_date=20240430T021351
[2024-04-30 02:13:51,855] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 02:13:51,935] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:58:11,190] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:11,507] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:11,514] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:11,515] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 02:58:11,522] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:11,630] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-04-02 06:00:00+00:00
[2024-04-30 02:58:11,642] {standard_task_runner.py:52} INFO - Started process 367 to run task
[2024-04-30 02:58:11,719] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '3093', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpbvzx0v_d', '--error-file', '/tmp/tmpnxhikrug']
[2024-04-30 02:58:11,760] {standard_task_runner.py:77} INFO - Job 3093: Subtask download_dataset_task
[2024-04-30 02:58:12,105] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 02:58:12,284] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:58:12,373] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-04-30 02:58:12,375] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 02:58:12,376] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-04.parquet']
[2024-04-30 02:58:12,513] {subprocess.py:85} INFO - Output:
[2024-04-30 02:58:15,874] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 02:58:16,104] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210402T060000, start_date=20240430T025811, end_date=20240430T025816
[2024-04-30 02:58:16,309] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 02:58:16,519] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:01:03,030] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:03,126] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:03,132] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:03,141] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:01:03,150] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:03,298] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-04-02 06:00:00+00:00
[2024-04-30 03:01:03,400] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '3127', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpukvogkao', '--error-file', '/tmp/tmpyw_6ug_9']
[2024-04-30 03:01:03,429] {standard_task_runner.py:77} INFO - Job 3127: Subtask download_dataset_task
[2024-04-30 03:01:03,363] {standard_task_runner.py:52} INFO - Started process 645 to run task
[2024-04-30 03:01:03,657] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:01:03,847] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:01:03,941] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-04-30 03:01:03,943] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 03:01:03,944] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet > /opt/***/cleaned_data/yellowtaxi_tripdata_2021-04.parquet']
[2024-04-30 03:01:04,094] {subprocess.py:85} INFO - Output:
[2024-04-30 03:01:07,530] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 03:01:07,607] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210402T060000, start_date=20240430T030103, end_date=20240430T030107
[2024-04-30 03:01:07,696] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:01:08,645] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:29:57,913] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-04-30 04:29:58,015] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-04-30 04:29:58,018] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:29:58,020] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:29:58,022] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:29:58,123] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-04-02 06:00:00+00:00
[2024-04-30 04:29:58,187] {standard_task_runner.py:52} INFO - Started process 5169 to run task
[2024-04-30 04:29:58,268] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '3239', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpcp4bkhrg', '--error-file', '/tmp/tmpk4j1zrfs']
[2024-04-30 04:29:58,342] {standard_task_runner.py:77} INFO - Job 3239: Subtask download_dataset_task
[2024-04-30 04:29:58,591] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:29:58,660] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:29:58,778] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-04-30 04:29:58,780] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 04:29:58,781] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-04.parquet']
[2024-04-30 04:29:58,912] {subprocess.py:85} INFO - Output:
[2024-04-30 04:30:02,589] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 04:30:02,704] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210402T060000, start_date=20240430T042957, end_date=20240430T043002
[2024-04-30 04:30:02,811] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 04:30:02,952] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
