[2024-03-29 08:27:17,712] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [queued]>
[2024-03-29 08:27:17,739] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [queued]>
[2024-03-29 08:27:17,739] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:27:17,739] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:27:17,740] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:27:17,790] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-11-02 06:00:00+00:00
[2024-03-29 08:27:17,805] {standard_task_runner.py:52} INFO - Started process 1530 to run task
[2024-03-29 08:27:17,836] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-11-02T06:00:00+00:00', '--job-id', '1772', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmptulyv3p3', '--error-file', '/tmp/tmp8ala5vne']
[2024-03-29 08:27:17,842] {standard_task_runner.py:77} INFO - Job 1772: Subtask download_dataset_task
[2024-03-29 08:27:18,085] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:27:18,304] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:27:18,456] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-11-02T06:00:00+00:00
[2024-03-29 08:27:18,462] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:27:18,465] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-11.parquet > /opt/***/yellowtaxi_tripdata_2022-11.parquet']
[2024-03-29 08:27:18,567] {subprocess.py:85} INFO - Output:
[2024-03-29 08:27:24,712] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:27:24,900] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20221102T060000, start_date=20240329T082717, end_date=20240329T082724
[2024-03-29 08:27:25,030] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:27:25,177] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:53:20,761] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [queued]>
[2024-03-30 03:53:20,879] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [queued]>
[2024-03-30 03:53:20,880] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:53:20,882] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:53:20,883] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:53:20,942] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-11-02 06:00:00+00:00
[2024-03-30 03:53:20,965] {standard_task_runner.py:52} INFO - Started process 2072 to run task
[2024-03-30 03:53:20,996] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-11-02T06:00:00+00:00', '--job-id', '1983', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpb1r1lp8u', '--error-file', '/tmp/tmpk3ycpmae']
[2024-03-30 03:53:21,013] {standard_task_runner.py:77} INFO - Job 1983: Subtask download_dataset_task
[2024-03-30 03:53:21,363] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:53:21,634] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:53:21,727] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-11-02T06:00:00+00:00
[2024-03-30 03:53:21,729] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:53:21,731] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-11.parquet > /opt/***/yellowtaxi_tripdata_2022-11.parquet']
[2024-03-30 03:53:21,786] {subprocess.py:85} INFO - Output:
[2024-03-30 03:53:28,483] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:53:28,529] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20221102T060000, start_date=20240330T035320, end_date=20240330T035328
[2024-03-30 03:53:28,600] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:53:28,738] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:18:51,524] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:51,654] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:51,654] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:51,654] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:18:51,654] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:51,757] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-11-02 06:00:00+00:00
[2024-03-30 04:18:51,805] {standard_task_runner.py:52} INFO - Started process 3723 to run task
[2024-03-30 04:18:51,860] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-11-02T06:00:00+00:00', '--job-id', '2127', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpq6v4vg0g', '--error-file', '/tmp/tmpg6tx8nml']
[2024-03-30 04:18:51,906] {standard_task_runner.py:77} INFO - Job 2127: Subtask download_dataset_task
[2024-03-30 04:18:52,273] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:18:52,442] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:18:52,524] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-11-02T06:00:00+00:00
[2024-03-30 04:18:52,526] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:18:52,529] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-11.parquet > /opt/***/yellowtaxi_tripdata_2022-11.parquet']
[2024-03-30 04:18:52,615] {subprocess.py:85} INFO - Output:
[2024-03-30 04:18:58,816] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:18:59,772] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20221102T060000, start_date=20240330T041851, end_date=20240330T041859
[2024-03-30 04:18:59,980] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:19:00,132] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:25:28,792] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [queued]>
[2024-03-30 04:25:28,938] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [queued]>
[2024-03-30 04:25:28,938] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:25:28,943] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:25:28,943] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:25:29,087] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-11-02 06:00:00+00:00
[2024-03-30 04:25:29,201] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-11-02T06:00:00+00:00', '--job-id', '2207', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp32yy5t5j', '--error-file', '/tmp/tmpjnynm5oe']
[2024-03-30 04:25:29,260] {standard_task_runner.py:77} INFO - Job 2207: Subtask download_dataset_task
[2024-03-30 04:25:29,170] {standard_task_runner.py:52} INFO - Started process 4354 to run task
[2024-03-30 04:25:29,706] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:25:29,883] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:25:29,970] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-11-02T06:00:00+00:00
[2024-03-30 04:25:29,971] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:25:29,976] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-11.parquet > /opt/***/yellowtaxi_tripdata_2022-11.parquet']
[2024-03-30 04:25:30,050] {subprocess.py:85} INFO - Output:
[2024-03-30 04:25:36,163] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:25:36,248] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20221102T060000, start_date=20240330T042528, end_date=20240330T042536
[2024-03-30 04:25:36,351] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:25:36,500] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:44:44,903] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [queued]>
[2024-03-30 04:44:44,951] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [queued]>
[2024-03-30 04:44:44,951] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:44:44,952] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:44:44,952] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:44:44,978] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-11-02 06:00:00+00:00
[2024-03-30 04:44:44,995] {standard_task_runner.py:52} INFO - Started process 5720 to run task
[2024-03-30 04:44:45,008] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-11-02T06:00:00+00:00', '--job-id', '2350', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpzsgdb_8_', '--error-file', '/tmp/tmpvbyu1dk0']
[2024-03-30 04:44:45,035] {standard_task_runner.py:77} INFO - Job 2350: Subtask download_dataset_task
[2024-03-30 04:44:45,227] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:44:45,318] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:44:45,379] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-11-02T06:00:00+00:00
[2024-03-30 04:44:45,381] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:44:45,382] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-11.parquet > /opt/***/yellowtaxi_tripdata_2022-11.parquet']
[2024-03-30 04:44:45,475] {subprocess.py:85} INFO - Output:
[2024-03-30 04:44:51,535] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:44:51,639] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20221102T060000, start_date=20240330T044444, end_date=20240330T044451
[2024-03-30 04:44:51,824] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:44:52,124] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 05:00:05,219] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:05,295] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:05,295] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:05,298] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 05:00:05,298] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:05,369] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-11-02 06:00:00+00:00
[2024-03-30 05:00:05,403] {standard_task_runner.py:52} INFO - Started process 6801 to run task
[2024-03-30 05:00:05,476] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-11-02T06:00:00+00:00', '--job-id', '2452', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp5itpkrue', '--error-file', '/tmp/tmp0ulhdoc1']
[2024-03-30 05:00:05,518] {standard_task_runner.py:77} INFO - Job 2452: Subtask download_dataset_task
[2024-03-30 05:00:05,809] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 05:00:05,972] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 05:00:06,086] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-11-02T06:00:00+00:00
[2024-03-30 05:00:06,089] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 05:00:06,090] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-11.parquet > /opt/***/yellowtaxi_tripdata_2022-11.parquet']
[2024-03-30 05:00:06,171] {subprocess.py:85} INFO - Output:
[2024-03-30 05:00:12,357] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 05:00:12,818] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20221102T060000, start_date=20240330T050005, end_date=20240330T050012
[2024-03-30 05:00:12,966] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 05:00:13,400] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:02:19,082] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [queued]>
[2024-03-30 09:02:19,189] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [queued]>
[2024-03-30 09:02:19,189] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:02:19,190] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:02:19,190] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:02:19,542] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-11-02 06:00:00+00:00
[2024-03-30 09:02:19,658] {standard_task_runner.py:52} INFO - Started process 18338 to run task
[2024-03-30 09:02:19,677] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-11-02T06:00:00+00:00', '--job-id', '2570', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpkj5b18tg', '--error-file', '/tmp/tmpopi9o9us']
[2024-03-30 09:02:19,736] {standard_task_runner.py:77} INFO - Job 2570: Subtask download_dataset_task
[2024-03-30 09:02:20,216] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:02:20,625] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:02:20,782] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-11-02T06:00:00+00:00
[2024-03-30 09:02:20,788] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 09:02:20,789] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-11.parquet > /opt/***/yellowtaxi_tripdata_2022-11.parquet']
[2024-03-30 09:02:20,936] {subprocess.py:85} INFO - Output:
[2024-03-30 09:02:27,265] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 09:02:28,650] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20221102T060000, start_date=20240330T090219, end_date=20240330T090228
[2024-03-30 09:02:29,155] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:02:31,181] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:57:13,585] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [queued]>
[2024-03-30 11:57:13,617] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [queued]>
[2024-03-30 11:57:13,630] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:57:13,631] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:57:13,632] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:57:13,669] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-11-02 06:00:00+00:00
[2024-03-30 11:57:13,689] {standard_task_runner.py:52} INFO - Started process 28507 to run task
[2024-03-30 11:57:13,707] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-11-02T06:00:00+00:00', '--job-id', '2892', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpi8gdpxmh', '--error-file', '/tmp/tmpoxpya8pz']
[2024-03-30 11:57:13,737] {standard_task_runner.py:77} INFO - Job 2892: Subtask download_dataset_task
[2024-03-30 11:57:13,844] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:57:13,955] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:57:14,000] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-11-02T06:00:00+00:00
[2024-03-30 11:57:14,003] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:57:14,004] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-11.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-11.parquet']
[2024-03-30 11:57:14,070] {subprocess.py:85} INFO - Output:
[2024-03-30 11:57:20,262] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:57:20,338] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20221102T060000, start_date=20240330T115713, end_date=20240330T115720
[2024-03-30 11:57:20,387] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:57:20,463] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:01:46,093] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:46,203] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:46,207] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:46,207] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:01:46,207] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:46,377] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-11-02 06:00:00+00:00
[2024-04-30 03:01:46,441] {standard_task_runner.py:52} INFO - Started process 861 to run task
[2024-04-30 03:01:46,520] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-11-02T06:00:00+00:00', '--job-id', '3176', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmph0wnwc3o', '--error-file', '/tmp/tmpkk8we4lr']
[2024-04-30 03:01:46,583] {standard_task_runner.py:77} INFO - Job 3176: Subtask download_dataset_task
[2024-04-30 03:01:46,901] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:01:47,158] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:01:47,258] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-11-02T06:00:00+00:00
[2024-04-30 03:01:47,261] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 03:01:47,263] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-11.parquet > /opt/***/cleaned_data/yellowtaxi_tripdata_2022-11.parquet']
[2024-04-30 03:01:47,321] {subprocess.py:85} INFO - Output:
[2024-04-30 03:01:51,698] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 03:01:52,324] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20221102T060000, start_date=20240430T030146, end_date=20240430T030152
[2024-04-30 03:01:52,499] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:01:52,728] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:34:05,826] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [queued]>
[2024-04-30 04:34:05,845] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [queued]>
[2024-04-30 04:34:05,845] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:34:05,846] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:34:05,846] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:34:05,862] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-11-02 06:00:00+00:00
[2024-04-30 04:34:05,872] {standard_task_runner.py:52} INFO - Started process 5579 to run task
[2024-04-30 04:34:05,878] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-11-02T06:00:00+00:00', '--job-id', '3286', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpf4r5ce1t', '--error-file', '/tmp/tmp2jelef12']
[2024-04-30 04:34:05,883] {standard_task_runner.py:77} INFO - Job 3286: Subtask download_dataset_task
[2024-04-30 04:34:05,979] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-11-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:34:06,039] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:34:06,076] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-11-02T06:00:00+00:00
[2024-04-30 04:34:06,078] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 04:34:06,079] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-11.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-11.parquet']
[2024-04-30 04:34:06,104] {subprocess.py:85} INFO - Output:
[2024-04-30 04:34:10,139] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 04:34:10,611] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20221102T060000, start_date=20240430T043405, end_date=20240430T043410
[2024-04-30 04:34:10,741] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 04:34:10,835] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
