[2024-03-29 08:27:18,668] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [queued]>
[2024-03-29 08:27:18,755] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [queued]>
[2024-03-29 08:27:18,756] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:27:18,758] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:27:18,759] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:27:18,816] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-02-02 06:00:00+00:00
[2024-03-29 08:27:18,840] {standard_task_runner.py:52} INFO - Started process 1538 to run task
[2024-03-29 08:27:18,889] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-02-02T06:00:00+00:00', '--job-id', '1774', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpxwaxv71w', '--error-file', '/tmp/tmptipqwv9j']
[2024-03-29 08:27:18,911] {standard_task_runner.py:77} INFO - Job 1774: Subtask download_dataset_task
[2024-03-29 08:27:19,232] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:27:19,326] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:27:19,390] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-02-02T06:00:00+00:00
[2024-03-29 08:27:19,391] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:27:19,392] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet > /opt/***/yellowtaxi_tripdata_2023-02.parquet']
[2024-03-29 08:27:19,537] {subprocess.py:85} INFO - Output:
[2024-03-29 08:27:26,009] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:27:26,459] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230202T060000, start_date=20240329T082718, end_date=20240329T082726
[2024-03-29 08:27:26,575] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:27:27,437] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:53:22,311] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [queued]>
[2024-03-30 03:53:22,451] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [queued]>
[2024-03-30 03:53:22,451] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:53:22,452] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:53:22,452] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:53:22,526] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-02-02 06:00:00+00:00
[2024-03-30 03:53:22,557] {standard_task_runner.py:52} INFO - Started process 2087 to run task
[2024-03-30 03:53:22,640] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-02-02T06:00:00+00:00', '--job-id', '1986', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpcfwt811i', '--error-file', '/tmp/tmpq1jz8uip']
[2024-03-30 03:53:22,648] {standard_task_runner.py:77} INFO - Job 1986: Subtask download_dataset_task
[2024-03-30 03:53:23,044] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:53:23,349] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:53:23,447] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-02-02T06:00:00+00:00
[2024-03-30 03:53:23,448] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:53:23,449] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet > /opt/***/yellowtaxi_tripdata_2023-02.parquet']
[2024-03-30 03:53:23,516] {subprocess.py:85} INFO - Output:
[2024-03-30 03:53:30,139] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:53:30,558] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230202T060000, start_date=20240330T035322, end_date=20240330T035330
[2024-03-30 03:53:30,750] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:53:31,367] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:18:56,386] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:56,497] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:56,498] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:56,503] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:18:56,503] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:56,637] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-02-02 06:00:00+00:00
[2024-03-30 04:18:56,778] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-02-02T06:00:00+00:00', '--job-id', '2131', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp91rep2ot', '--error-file', '/tmp/tmpm860x1ia']
[2024-03-30 04:18:56,870] {standard_task_runner.py:77} INFO - Job 2131: Subtask download_dataset_task
[2024-03-30 04:18:56,701] {standard_task_runner.py:52} INFO - Started process 3750 to run task
[2024-03-30 04:18:57,427] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:18:57,818] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:18:57,968] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-02-02T06:00:00+00:00
[2024-03-30 04:18:57,980] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:18:57,987] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet > /opt/***/yellowtaxi_tripdata_2023-02.parquet']
[2024-03-30 04:18:58,226] {subprocess.py:85} INFO - Output:
[2024-03-30 04:19:04,680] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:19:05,590] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230202T060000, start_date=20240330T041856, end_date=20240330T041905
[2024-03-30 04:19:05,761] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:19:06,317] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:25:31,595] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [queued]>
[2024-03-30 04:25:31,686] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [queued]>
[2024-03-30 04:25:31,691] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:25:31,692] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:25:31,693] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:25:31,758] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-02-02 06:00:00+00:00
[2024-03-30 04:25:31,788] {standard_task_runner.py:52} INFO - Started process 4373 to run task
[2024-03-30 04:25:31,825] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-02-02T06:00:00+00:00', '--job-id', '2210', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmppq779mly', '--error-file', '/tmp/tmpuxk_azrs']
[2024-03-30 04:25:31,853] {standard_task_runner.py:77} INFO - Job 2210: Subtask download_dataset_task
[2024-03-30 04:25:32,122] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:25:32,301] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:25:32,379] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-02-02T06:00:00+00:00
[2024-03-30 04:25:32,383] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:25:32,384] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet > /opt/***/yellowtaxi_tripdata_2023-02.parquet']
[2024-03-30 04:25:32,470] {subprocess.py:85} INFO - Output:
[2024-03-30 04:25:38,483] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:25:38,969] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230202T060000, start_date=20240330T042531, end_date=20240330T042538
[2024-03-30 04:25:39,337] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:25:40,013] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:44:47,724] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [queued]>
[2024-03-30 04:44:47,855] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [queued]>
[2024-03-30 04:44:47,858] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:44:47,862] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:44:47,863] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:44:47,978] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-02-02 06:00:00+00:00
[2024-03-30 04:44:48,051] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-02-02T06:00:00+00:00', '--job-id', '2353', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpwv0n70mo', '--error-file', '/tmp/tmpm8mld43t']
[2024-03-30 04:44:48,091] {standard_task_runner.py:77} INFO - Job 2353: Subtask download_dataset_task
[2024-03-30 04:44:48,012] {standard_task_runner.py:52} INFO - Started process 5750 to run task
[2024-03-30 04:44:48,403] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:44:48,757] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:44:48,905] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-02-02T06:00:00+00:00
[2024-03-30 04:44:48,917] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:44:48,924] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet > /opt/***/yellowtaxi_tripdata_2023-02.parquet']
[2024-03-30 04:44:49,072] {subprocess.py:85} INFO - Output:
[2024-03-30 04:44:57,011] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:44:57,414] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230202T060000, start_date=20240330T044447, end_date=20240330T044457
[2024-03-30 04:44:57,554] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:44:57,731] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 05:00:07,503] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:07,571] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:07,575] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:07,576] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 05:00:07,576] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:07,676] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-02-02 06:00:00+00:00
[2024-03-30 05:00:07,737] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-02-02T06:00:00+00:00', '--job-id', '2455', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpg09galu8', '--error-file', '/tmp/tmphz59fg2s']
[2024-03-30 05:00:07,749] {standard_task_runner.py:77} INFO - Job 2455: Subtask download_dataset_task
[2024-03-30 05:00:07,715] {standard_task_runner.py:52} INFO - Started process 6820 to run task
[2024-03-30 05:00:07,956] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 05:00:08,075] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 05:00:08,149] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-02-02T06:00:00+00:00
[2024-03-30 05:00:08,151] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 05:00:08,159] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet > /opt/***/yellowtaxi_tripdata_2023-02.parquet']
[2024-03-30 05:00:08,230] {subprocess.py:85} INFO - Output:
[2024-03-30 05:00:14,215] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 05:00:14,797] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230202T060000, start_date=20240330T050007, end_date=20240330T050014
[2024-03-30 05:00:14,967] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 05:00:15,083] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:02:19,004] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [queued]>
[2024-03-30 09:02:19,108] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [queued]>
[2024-03-30 09:02:19,109] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:02:19,109] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:02:19,110] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:02:19,392] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-02-02 06:00:00+00:00
[2024-03-30 09:02:19,421] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-02-02T06:00:00+00:00', '--job-id', '2569', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpoadmc_wo', '--error-file', '/tmp/tmphkurh196']
[2024-03-30 09:02:19,469] {standard_task_runner.py:77} INFO - Job 2569: Subtask download_dataset_task
[2024-03-30 09:02:19,409] {standard_task_runner.py:52} INFO - Started process 18337 to run task
[2024-03-30 09:02:19,854] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:02:20,057] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:02:20,198] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-02-02T06:00:00+00:00
[2024-03-30 09:02:20,200] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 09:02:20,201] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet > /opt/***/yellowtaxi_tripdata_2023-02.parquet']
[2024-03-30 09:02:20,370] {subprocess.py:85} INFO - Output:
[2024-03-30 09:02:26,304] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 09:02:26,422] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230202T060000, start_date=20240330T090219, end_date=20240330T090226
[2024-03-30 09:02:26,557] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:02:27,411] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:57:16,821] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [queued]>
[2024-03-30 11:57:16,888] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [queued]>
[2024-03-30 11:57:16,889] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:57:16,889] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:57:16,890] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:57:16,928] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-02-02 06:00:00+00:00
[2024-03-30 11:57:16,946] {standard_task_runner.py:52} INFO - Started process 28534 to run task
[2024-03-30 11:57:16,982] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-02-02T06:00:00+00:00', '--job-id', '2896', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpdo8dnol9', '--error-file', '/tmp/tmpsxaf372p']
[2024-03-30 11:57:17,055] {standard_task_runner.py:77} INFO - Job 2896: Subtask download_dataset_task
[2024-03-30 11:57:17,238] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:57:17,386] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:57:17,490] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-02-02T06:00:00+00:00
[2024-03-30 11:57:17,496] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:57:17,500] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2023-02.parquet']
[2024-03-30 11:57:17,622] {subprocess.py:85} INFO - Output:
[2024-03-30 11:57:23,472] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:57:23,901] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230202T060000, start_date=20240330T115716, end_date=20240330T115723
[2024-03-30 11:57:24,004] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:57:24,105] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:01:48,462] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:48,547] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:48,548] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:48,548] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:01:48,548] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:48,591] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-02-02 06:00:00+00:00
[2024-04-30 03:01:48,641] {standard_task_runner.py:52} INFO - Started process 876 to run task
[2024-04-30 03:01:48,719] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-02-02T06:00:00+00:00', '--job-id', '3180', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmphb7nylec', '--error-file', '/tmp/tmprf45p9hy']
[2024-04-30 03:01:48,748] {standard_task_runner.py:77} INFO - Job 3180: Subtask download_dataset_task
[2024-04-30 03:01:49,182] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:01:49,638] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:01:49,848] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-02-02T06:00:00+00:00
[2024-04-30 03:01:49,850] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 03:01:49,851] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet > /opt/***/cleaned_data/yellowtaxi_tripdata_2023-02.parquet']
[2024-04-30 03:01:49,941] {subprocess.py:85} INFO - Output:
[2024-04-30 03:01:55,685] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 03:01:55,882] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230202T060000, start_date=20240430T030148, end_date=20240430T030155
[2024-04-30 03:01:56,073] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:01:56,721] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:34:35,613] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [queued]>
[2024-04-30 04:34:35,638] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [queued]>
[2024-04-30 04:34:35,638] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:34:35,639] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:34:35,640] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:34:35,662] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-02-02 06:00:00+00:00
[2024-04-30 04:34:35,677] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-02-02T06:00:00+00:00', '--job-id', '3297', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpmuowveqn', '--error-file', '/tmp/tmp14zlx764']
[2024-04-30 04:34:35,672] {standard_task_runner.py:52} INFO - Started process 5681 to run task
[2024-04-30 04:34:35,685] {standard_task_runner.py:77} INFO - Job 3297: Subtask download_dataset_task
[2024-04-30 04:34:35,778] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-02-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:34:35,825] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:34:35,858] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-02-02T06:00:00+00:00
[2024-04-30 04:34:35,859] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 04:34:35,860] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2023-02.parquet']
[2024-04-30 04:34:35,886] {subprocess.py:85} INFO - Output:
[2024-04-30 04:34:40,109] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 04:34:40,156] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230202T060000, start_date=20240430T043435, end_date=20240430T043440
[2024-04-30 04:34:40,197] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 04:34:40,258] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
