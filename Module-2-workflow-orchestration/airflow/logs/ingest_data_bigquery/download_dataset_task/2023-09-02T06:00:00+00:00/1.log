[2024-03-30 03:53:26,979] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [queued]>
[2024-03-30 03:53:27,108] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [queued]>
[2024-03-30 03:53:27,109] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:53:27,109] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:53:27,110] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:53:27,188] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-09-02 06:00:00+00:00
[2024-03-30 03:53:27,210] {standard_task_runner.py:52} INFO - Started process 2122 to run task
[2024-03-30 03:53:27,276] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-09-02T06:00:00+00:00', '--job-id', '1993', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpncb4apx0', '--error-file', '/tmp/tmpbv7pm56g']
[2024-03-30 03:53:27,285] {standard_task_runner.py:77} INFO - Job 1993: Subtask download_dataset_task
[2024-03-30 03:53:27,481] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:53:27,684] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:53:27,764] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-09-02T06:00:00+00:00
[2024-03-30 03:53:27,765] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:53:27,766] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-09.parquet > /opt/***/yellowtaxi_tripdata_2023-09.parquet']
[2024-03-30 03:53:27,827] {subprocess.py:85} INFO - Output:
[2024-03-30 03:53:34,087] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:53:34,222] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230902T060000, start_date=20240330T035326, end_date=20240330T035334
[2024-03-30 03:53:34,415] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:53:34,563] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:19:03,734] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [queued]>
[2024-03-30 04:19:03,783] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [queued]>
[2024-03-30 04:19:03,789] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:19:03,789] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:19:03,789] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:19:04,040] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-09-02 06:00:00+00:00
[2024-03-30 04:19:04,105] {standard_task_runner.py:52} INFO - Started process 3792 to run task
[2024-03-30 04:19:04,152] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-09-02T06:00:00+00:00', '--job-id', '2138', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpogityjao', '--error-file', '/tmp/tmp5oioprtw']
[2024-03-30 04:19:04,181] {standard_task_runner.py:77} INFO - Job 2138: Subtask download_dataset_task
[2024-03-30 04:19:04,982] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:19:05,664] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:19:05,787] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-09-02T06:00:00+00:00
[2024-03-30 04:19:05,788] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:19:05,789] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-09.parquet > /opt/***/yellowtaxi_tripdata_2023-09.parquet']
[2024-03-30 04:19:05,926] {subprocess.py:85} INFO - Output:
[2024-03-30 04:19:12,007] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:19:12,087] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230902T060000, start_date=20240330T041903, end_date=20240330T041912
[2024-03-30 04:19:12,222] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:19:12,327] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:26:07,536] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [queued]>
[2024-03-30 04:26:07,574] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [queued]>
[2024-03-30 04:26:07,574] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:26:07,575] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:26:07,575] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:26:07,601] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-09-02 06:00:00+00:00
[2024-03-30 04:26:07,610] {standard_task_runner.py:52} INFO - Started process 4528 to run task
[2024-03-30 04:26:07,648] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-09-02T06:00:00+00:00', '--job-id', '2249', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmppwwew9qj', '--error-file', '/tmp/tmpt2_3joth']
[2024-03-30 04:26:07,671] {standard_task_runner.py:77} INFO - Job 2249: Subtask download_dataset_task
[2024-03-30 04:26:07,793] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:26:07,925] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:26:07,990] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-09-02T06:00:00+00:00
[2024-03-30 04:26:07,992] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:26:07,994] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-09.parquet > /opt/***/yellowtaxi_tripdata_2023-09.parquet']
[2024-03-30 04:26:08,059] {subprocess.py:85} INFO - Output:
[2024-03-30 04:26:14,147] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:26:14,185] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230902T060000, start_date=20240330T042607, end_date=20240330T042614
[2024-03-30 04:26:14,222] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:26:14,263] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:44:57,940] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [queued]>
[2024-03-30 04:44:58,007] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [queued]>
[2024-03-30 04:44:58,007] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:44:58,008] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:44:58,008] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:44:58,057] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-09-02 06:00:00+00:00
[2024-03-30 04:44:58,085] {standard_task_runner.py:52} INFO - Started process 5800 to run task
[2024-03-30 04:44:58,143] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-09-02T06:00:00+00:00', '--job-id', '2363', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmple976fow', '--error-file', '/tmp/tmp4oijyntq']
[2024-03-30 04:44:58,173] {standard_task_runner.py:77} INFO - Job 2363: Subtask download_dataset_task
[2024-03-30 04:44:58,395] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:44:58,683] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:44:58,754] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-09-02T06:00:00+00:00
[2024-03-30 04:44:58,764] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:44:58,768] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-09.parquet > /opt/***/yellowtaxi_tripdata_2023-09.parquet']
[2024-03-30 04:44:58,843] {subprocess.py:85} INFO - Output:
[2024-03-30 04:45:04,921] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:45:05,002] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230902T060000, start_date=20240330T044457, end_date=20240330T044505
[2024-03-30 04:45:05,152] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:45:05,319] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 05:00:40,825] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:40,866] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:40,866] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:40,866] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 05:00:40,867] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:40,899] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-09-02 06:00:00+00:00
[2024-03-30 05:00:40,908] {standard_task_runner.py:52} INFO - Started process 6961 to run task
[2024-03-30 05:00:40,927] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-09-02T06:00:00+00:00', '--job-id', '2492', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpfda82njs', '--error-file', '/tmp/tmpznpf_6co']
[2024-03-30 05:00:40,932] {standard_task_runner.py:77} INFO - Job 2492: Subtask download_dataset_task
[2024-03-30 05:00:41,085] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 05:00:41,171] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 05:00:41,220] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-09-02T06:00:00+00:00
[2024-03-30 05:00:41,222] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 05:00:41,223] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-09.parquet > /opt/***/yellowtaxi_tripdata_2023-09.parquet']
[2024-03-30 05:00:41,269] {subprocess.py:85} INFO - Output:
[2024-03-30 05:00:47,178] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 05:00:47,225] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230902T060000, start_date=20240330T050040, end_date=20240330T050047
[2024-03-30 05:00:47,258] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 05:00:47,315] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:03:25,619] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [queued]>
[2024-03-30 09:03:25,661] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [queued]>
[2024-03-30 09:03:25,662] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:03:25,662] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:03:25,663] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:03:25,703] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-09-02 06:00:00+00:00
[2024-03-30 09:03:25,725] {standard_task_runner.py:52} INFO - Started process 18515 to run task
[2024-03-30 09:03:25,748] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-09-02T06:00:00+00:00', '--job-id', '2610', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpsrbgbxtz', '--error-file', '/tmp/tmp01blrcfe']
[2024-03-30 09:03:25,762] {standard_task_runner.py:77} INFO - Job 2610: Subtask download_dataset_task
[2024-03-30 09:03:25,917] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:03:25,998] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:03:26,034] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-09-02T06:00:00+00:00
[2024-03-30 09:03:26,037] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 09:03:26,038] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-09.parquet > /opt/***/yellowtaxi_tripdata_2023-09.parquet']
[2024-03-30 09:03:26,073] {subprocess.py:85} INFO - Output:
[2024-03-30 09:03:31,935] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 09:03:31,972] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230902T060000, start_date=20240330T090325, end_date=20240330T090331
[2024-03-30 09:03:32,018] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:03:32,063] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 12:07:02,690] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [queued]>
[2024-03-30 12:07:02,766] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [queued]>
[2024-03-30 12:07:02,767] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 12:07:02,767] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 12:07:02,768] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 12:07:02,809] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-09-02 06:00:00+00:00
[2024-03-30 12:07:02,830] {standard_task_runner.py:52} INFO - Started process 29362 to run task
[2024-03-30 12:07:02,851] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-09-02T06:00:00+00:00', '--job-id', '2932', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpwfu9u885', '--error-file', '/tmp/tmpigiutit2']
[2024-03-30 12:07:02,856] {standard_task_runner.py:77} INFO - Job 2932: Subtask download_dataset_task
[2024-03-30 12:07:02,994] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 12:07:03,078] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 12:07:03,133] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-09-02T06:00:00+00:00
[2024-03-30 12:07:03,135] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 12:07:03,136] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-09.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2023-09.parquet']
[2024-03-30 12:07:03,175] {subprocess.py:85} INFO - Output:
[2024-03-30 12:07:09,158] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 12:07:09,193] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230902T060000, start_date=20240330T120702, end_date=20240330T120709
[2024-03-30 12:07:09,233] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 12:07:09,278] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:02:27,897] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [queued]>
[2024-04-30 03:02:27,952] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [queued]>
[2024-04-30 03:02:27,953] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:02:27,954] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:02:27,955] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:02:28,004] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-09-02 06:00:00+00:00
[2024-04-30 03:02:28,043] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-09-02T06:00:00+00:00', '--job-id', '3218', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpr8pem_a_', '--error-file', '/tmp/tmp99hrl6j9']
[2024-04-30 03:02:28,056] {standard_task_runner.py:77} INFO - Job 3218: Subtask download_dataset_task
[2024-04-30 03:02:28,024] {standard_task_runner.py:52} INFO - Started process 1031 to run task
[2024-04-30 03:02:28,241] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:02:28,329] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:02:28,377] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-09-02T06:00:00+00:00
[2024-04-30 03:02:28,378] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 03:02:28,379] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-09.parquet > /opt/***/cleaned_data/yellowtaxi_tripdata_2023-09.parquet']
[2024-04-30 03:02:28,408] {subprocess.py:85} INFO - Output:
[2024-04-30 03:02:33,104] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 03:02:33,195] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230902T060000, start_date=20240430T030227, end_date=20240430T030233
[2024-04-30 03:02:33,263] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:02:33,353] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:35:32,769] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [queued]>
[2024-04-30 04:35:32,793] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [queued]>
[2024-04-30 04:35:32,794] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:35:32,795] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:35:32,798] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:35:32,827] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-09-02 06:00:00+00:00
[2024-04-30 04:35:32,845] {standard_task_runner.py:52} INFO - Started process 5884 to run task
[2024-04-30 04:35:32,865] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-09-02T06:00:00+00:00', '--job-id', '3321', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp32wktkom', '--error-file', '/tmp/tmp7rjdnfbi']
[2024-04-30 04:35:32,871] {standard_task_runner.py:77} INFO - Job 3321: Subtask download_dataset_task
[2024-04-30 04:35:32,996] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-09-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:35:33,067] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:35:33,120] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-09-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-09-02T06:00:00+00:00
[2024-04-30 04:35:33,121] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 04:35:33,123] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-09.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2023-09.parquet']
[2024-04-30 04:35:33,171] {subprocess.py:85} INFO - Output:
[2024-04-30 04:35:37,282] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 04:35:37,329] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230902T060000, start_date=20240430T043532, end_date=20240430T043537
[2024-04-30 04:35:37,385] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 04:35:37,456] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
