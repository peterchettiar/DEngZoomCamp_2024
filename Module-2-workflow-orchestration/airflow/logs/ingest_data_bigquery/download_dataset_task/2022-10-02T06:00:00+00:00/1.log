[2024-03-29 08:27:15,547] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [queued]>
[2024-03-29 08:27:15,634] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [queued]>
[2024-03-29 08:27:15,634] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:27:15,635] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:27:15,635] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:27:15,697] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-10-02 06:00:00+00:00
[2024-03-29 08:27:15,735] {standard_task_runner.py:52} INFO - Started process 1511 to run task
[2024-03-29 08:27:15,763] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-10-02T06:00:00+00:00', '--job-id', '1769', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp_625xzjn', '--error-file', '/tmp/tmpye_aq5j0']
[2024-03-29 08:27:15,781] {standard_task_runner.py:77} INFO - Job 1769: Subtask download_dataset_task
[2024-03-29 08:27:15,989] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:27:16,147] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:27:16,285] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-10-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-10-02T06:00:00+00:00
[2024-03-29 08:27:16,287] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:27:16,296] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-10.parquet > /opt/***/yellowtaxi_tripdata_2022-10.parquet']
[2024-03-29 08:27:16,375] {subprocess.py:85} INFO - Output:
[2024-03-29 08:27:23,104] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:27:23,769] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20221002T060000, start_date=20240329T082715, end_date=20240329T082723
[2024-03-29 08:27:23,961] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:27:24,145] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:53:18,960] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [queued]>
[2024-03-30 03:53:19,079] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [queued]>
[2024-03-30 03:53:19,087] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:53:19,088] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:53:19,089] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:53:19,174] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-10-02 06:00:00+00:00
[2024-03-30 03:53:19,252] {standard_task_runner.py:52} INFO - Started process 2061 to run task
[2024-03-30 03:53:19,327] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-10-02T06:00:00+00:00', '--job-id', '1981', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpvyjuqk9d', '--error-file', '/tmp/tmpxh1i0z10']
[2024-03-30 03:53:19,435] {standard_task_runner.py:77} INFO - Job 1981: Subtask download_dataset_task
[2024-03-30 03:53:19,935] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:53:20,394] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:53:20,451] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-10-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-10-02T06:00:00+00:00
[2024-03-30 03:53:20,455] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:53:20,460] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-10.parquet > /opt/***/yellowtaxi_tripdata_2022-10.parquet']
[2024-03-30 03:53:20,509] {subprocess.py:85} INFO - Output:
[2024-03-30 03:53:27,703] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:53:27,808] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20221002T060000, start_date=20240330T035319, end_date=20240330T035327
[2024-03-30 03:53:27,899] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:53:28,004] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:18:52,112] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:52,257] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:52,258] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:52,258] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:18:52,258] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:52,366] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-10-02 06:00:00+00:00
[2024-03-30 04:18:52,427] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-10-02T06:00:00+00:00', '--job-id', '2128', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpbzk1qklz', '--error-file', '/tmp/tmpbg4jh4qn']
[2024-03-30 04:18:52,468] {standard_task_runner.py:77} INFO - Job 2128: Subtask download_dataset_task
[2024-03-30 04:18:52,410] {standard_task_runner.py:52} INFO - Started process 3726 to run task
[2024-03-30 04:18:52,734] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:18:53,030] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:18:53,150] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-10-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-10-02T06:00:00+00:00
[2024-03-30 04:18:53,151] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:18:53,152] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-10.parquet > /opt/***/yellowtaxi_tripdata_2022-10.parquet']
[2024-03-30 04:18:53,178] {subprocess.py:85} INFO - Output:
[2024-03-30 04:18:59,867] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:18:59,989] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20221002T060000, start_date=20240330T041852, end_date=20240330T041859
[2024-03-30 04:19:00,063] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:19:00,178] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:25:28,225] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [queued]>
[2024-03-30 04:25:28,312] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [queued]>
[2024-03-30 04:25:28,312] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:25:28,312] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:25:28,313] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:25:28,421] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-10-02 06:00:00+00:00
[2024-03-30 04:25:28,494] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-10-02T06:00:00+00:00', '--job-id', '2206', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpd4oqi83e', '--error-file', '/tmp/tmpkmsiorg2']
[2024-03-30 04:25:28,534] {standard_task_runner.py:77} INFO - Job 2206: Subtask download_dataset_task
[2024-03-30 04:25:28,470] {standard_task_runner.py:52} INFO - Started process 4344 to run task
[2024-03-30 04:25:29,081] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:25:29,232] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:25:29,367] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-10-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-10-02T06:00:00+00:00
[2024-03-30 04:25:29,377] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:25:29,382] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-10.parquet > /opt/***/yellowtaxi_tripdata_2022-10.parquet']
[2024-03-30 04:25:29,471] {subprocess.py:85} INFO - Output:
[2024-03-30 04:25:36,277] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:25:36,702] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20221002T060000, start_date=20240330T042528, end_date=20240330T042536
[2024-03-30 04:25:36,787] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:25:36,966] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:44:22,543] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [queued]>
[2024-03-30 04:44:22,557] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [queued]>
[2024-03-30 04:44:22,557] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:44:22,558] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:44:22,558] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:44:22,568] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-10-02 06:00:00+00:00
[2024-03-30 04:44:22,574] {standard_task_runner.py:52} INFO - Started process 5645 to run task
[2024-03-30 04:44:22,579] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-10-02T06:00:00+00:00', '--job-id', '2332', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmprob1vk9r', '--error-file', '/tmp/tmpfe33fgoa']
[2024-03-30 04:44:22,584] {standard_task_runner.py:77} INFO - Job 2332: Subtask download_dataset_task
[2024-03-30 04:44:22,664] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:44:22,702] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:44:22,722] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-10-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-10-02T06:00:00+00:00
[2024-03-30 04:44:22,724] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:44:22,724] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-10.parquet > /opt/***/yellowtaxi_tripdata_2022-10.parquet']
[2024-03-30 04:44:22,736] {subprocess.py:85} INFO - Output:
[2024-03-30 04:44:29,350] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:44:29,443] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20221002T060000, start_date=20240330T044422, end_date=20240330T044429
[2024-03-30 04:44:29,576] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:44:29,715] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 05:00:05,215] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:05,305] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:05,305] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:05,305] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 05:00:05,305] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:05,357] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-10-02 06:00:00+00:00
[2024-03-30 05:00:05,380] {standard_task_runner.py:52} INFO - Started process 6798 to run task
[2024-03-30 05:00:05,428] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-10-02T06:00:00+00:00', '--job-id', '2451', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmprsmg74ql', '--error-file', '/tmp/tmp106hfzu5']
[2024-03-30 05:00:05,478] {standard_task_runner.py:77} INFO - Job 2451: Subtask download_dataset_task
[2024-03-30 05:00:05,677] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 05:00:05,835] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 05:00:05,965] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-10-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-10-02T06:00:00+00:00
[2024-03-30 05:00:05,976] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 05:00:05,989] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-10.parquet > /opt/***/yellowtaxi_tripdata_2022-10.parquet']
[2024-03-30 05:00:06,100] {subprocess.py:85} INFO - Output:
[2024-03-30 05:00:12,849] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 05:00:12,967] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20221002T060000, start_date=20240330T050005, end_date=20240330T050012
[2024-03-30 05:00:13,087] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 05:00:13,300] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:02:15,846] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [queued]>
[2024-03-30 09:02:16,083] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [queued]>
[2024-03-30 09:02:16,084] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:02:16,084] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:02:16,084] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:02:16,278] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-10-02 06:00:00+00:00
[2024-03-30 09:02:16,397] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-10-02T06:00:00+00:00', '--job-id', '2566', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpm2z0jimi', '--error-file', '/tmp/tmpz7pbzy70']
[2024-03-30 09:02:16,437] {standard_task_runner.py:77} INFO - Job 2566: Subtask download_dataset_task
[2024-03-30 09:02:16,383] {standard_task_runner.py:52} INFO - Started process 18314 to run task
[2024-03-30 09:02:17,146] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:02:17,648] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:02:17,891] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-10-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-10-02T06:00:00+00:00
[2024-03-30 09:02:17,894] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 09:02:17,896] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-10.parquet > /opt/***/yellowtaxi_tripdata_2022-10.parquet']
[2024-03-30 09:02:18,079] {subprocess.py:85} INFO - Output:
[2024-03-30 09:02:25,161] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 09:02:25,501] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20221002T060000, start_date=20240330T090215, end_date=20240330T090225
[2024-03-30 09:02:25,631] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:02:26,273] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:57:04,971] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [queued]>
[2024-03-30 11:57:04,984] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [queued]>
[2024-03-30 11:57:04,984] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:57:04,984] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:57:04,984] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:57:04,995] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-10-02 06:00:00+00:00
[2024-03-30 11:57:05,002] {standard_task_runner.py:52} INFO - Started process 28459 to run task
[2024-03-30 11:57:05,009] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-10-02T06:00:00+00:00', '--job-id', '2889', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmppsb7zw3y', '--error-file', '/tmp/tmpunbcd2hs']
[2024-03-30 11:57:05,014] {standard_task_runner.py:77} INFO - Job 2889: Subtask download_dataset_task
[2024-03-30 11:57:05,077] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:57:05,120] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:57:05,144] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-10-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-10-02T06:00:00+00:00
[2024-03-30 11:57:05,145] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:57:05,146] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-10.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-10.parquet']
[2024-03-30 11:57:05,160] {subprocess.py:85} INFO - Output:
[2024-03-30 11:57:11,734] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:57:11,949] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20221002T060000, start_date=20240330T115704, end_date=20240330T115711
[2024-03-30 11:57:12,007] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:57:12,065] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:01:45,440] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:45,532] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:45,532] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:45,532] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:01:45,533] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:45,598] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-10-02 06:00:00+00:00
[2024-04-30 03:01:45,623] {standard_task_runner.py:52} INFO - Started process 853 to run task
[2024-04-30 03:01:45,676] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-10-02T06:00:00+00:00', '--job-id', '3175', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpel15x7ac', '--error-file', '/tmp/tmpy2r41dfz']
[2024-04-30 03:01:45,706] {standard_task_runner.py:77} INFO - Job 3175: Subtask download_dataset_task
[2024-04-30 03:01:45,965] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:01:46,123] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:01:46,329] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-10-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-10-02T06:00:00+00:00
[2024-04-30 03:01:46,339] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 03:01:46,354] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-10.parquet > /opt/***/cleaned_data/yellowtaxi_tripdata_2022-10.parquet']
[2024-04-30 03:01:46,448] {subprocess.py:85} INFO - Output:
[2024-04-30 03:01:51,409] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 03:01:51,670] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20221002T060000, start_date=20240430T030145, end_date=20240430T030151
[2024-04-30 03:01:51,855] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:01:52,051] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:34:05,495] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [queued]>
[2024-04-30 04:34:05,522] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [queued]>
[2024-04-30 04:34:05,523] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:34:05,523] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:34:05,523] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:34:05,550] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-10-02 06:00:00+00:00
[2024-04-30 04:34:05,560] {standard_task_runner.py:52} INFO - Started process 5574 to run task
[2024-04-30 04:34:05,576] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-10-02T06:00:00+00:00', '--job-id', '3285', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpphn8fkmi', '--error-file', '/tmp/tmp75yg_341']
[2024-04-30 04:34:05,586] {standard_task_runner.py:77} INFO - Job 3285: Subtask download_dataset_task
[2024-04-30 04:34:05,687] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-10-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:34:05,756] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:34:05,792] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-10-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-10-02T06:00:00+00:00
[2024-04-30 04:34:05,798] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 04:34:05,799] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-10.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-10.parquet']
[2024-04-30 04:34:05,821] {subprocess.py:85} INFO - Output:
[2024-04-30 04:34:10,194] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 04:34:10,617] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20221002T060000, start_date=20240430T043405, end_date=20240430T043410
[2024-04-30 04:34:10,717] {local_task_job.py:212} WARNING - State of this instance has been externally set to success. Terminating instance.
[2024-04-30 04:34:10,732] {process_utils.py:124} INFO - Sending Signals.SIGTERM to group 5574. PIDs of all processes in the group: [5574]
[2024-04-30 04:34:10,732] {process_utils.py:75} INFO - Sending the signal Signals.SIGTERM to group 5574
[2024-04-30 04:34:10,735] {process_utils.py:70} INFO - Process psutil.Process(pid=5574, status='terminated', exitcode=0, started='04:34:05') (5574) terminated with exit code 0
