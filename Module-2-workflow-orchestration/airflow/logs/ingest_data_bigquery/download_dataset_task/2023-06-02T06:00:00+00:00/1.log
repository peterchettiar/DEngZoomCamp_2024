[2024-03-29 08:27:22,688] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [queued]>
[2024-03-29 08:27:22,710] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [queued]>
[2024-03-29 08:27:22,710] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:27:22,710] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:27:22,711] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:27:22,737] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-06-02 06:00:00+00:00
[2024-03-29 08:27:22,755] {standard_task_runner.py:52} INFO - Started process 1571 to run task
[2024-03-29 08:27:22,787] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-06-02T06:00:00+00:00', '--job-id', '1780', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp73ku5qu6', '--error-file', '/tmp/tmpn104u_4w']
[2024-03-29 08:27:22,813] {standard_task_runner.py:77} INFO - Job 1780: Subtask download_dataset_task
[2024-03-29 08:27:23,034] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:27:23,138] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:27:23,270] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-06-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-06-02T06:00:00+00:00
[2024-03-29 08:27:23,277] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:27:23,278] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-06.parquet > /opt/***/yellowtaxi_tripdata_2023-06.parquet']
[2024-03-29 08:27:23,366] {subprocess.py:85} INFO - Output:
[2024-03-29 08:27:30,064] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:27:30,274] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230602T060000, start_date=20240329T082722, end_date=20240329T082730
[2024-03-29 08:27:30,436] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:27:30,616] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:53:25,508] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [queued]>
[2024-03-30 03:53:25,541] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [queued]>
[2024-03-30 03:53:25,542] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:53:25,542] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:53:25,544] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:53:25,575] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-06-02 06:00:00+00:00
[2024-03-30 03:53:25,590] {standard_task_runner.py:52} INFO - Started process 2108 to run task
[2024-03-30 03:53:25,633] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-06-02T06:00:00+00:00', '--job-id', '1990', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmphogzdhrw', '--error-file', '/tmp/tmpphqmfnnb']
[2024-03-30 03:53:25,660] {standard_task_runner.py:77} INFO - Job 1990: Subtask download_dataset_task
[2024-03-30 03:53:26,099] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:53:26,437] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:53:26,548] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-06-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-06-02T06:00:00+00:00
[2024-03-30 03:53:26,560] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:53:26,567] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-06.parquet > /opt/***/yellowtaxi_tripdata_2023-06.parquet']
[2024-03-30 03:53:26,722] {subprocess.py:85} INFO - Output:
[2024-03-30 03:53:33,731] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:53:33,817] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230602T060000, start_date=20240330T035325, end_date=20240330T035333
[2024-03-30 03:53:33,936] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:53:34,151] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:19:00,558] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [queued]>
[2024-03-30 04:19:00,616] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [queued]>
[2024-03-30 04:19:00,617] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:19:00,617] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:19:00,617] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:19:00,661] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-06-02 06:00:00+00:00
[2024-03-30 04:19:00,703] {standard_task_runner.py:52} INFO - Started process 3769 to run task
[2024-03-30 04:19:00,742] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-06-02T06:00:00+00:00', '--job-id', '2134', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpmj5mmmko', '--error-file', '/tmp/tmpydokbldg']
[2024-03-30 04:19:00,786] {standard_task_runner.py:77} INFO - Job 2134: Subtask download_dataset_task
[2024-03-30 04:19:01,410] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:19:01,775] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:19:01,997] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-06-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-06-02T06:00:00+00:00
[2024-03-30 04:19:01,999] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:19:02,007] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-06.parquet > /opt/***/yellowtaxi_tripdata_2023-06.parquet']
[2024-03-30 04:19:02,349] {subprocess.py:85} INFO - Output:
[2024-03-30 04:19:09,151] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:19:09,408] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230602T060000, start_date=20240330T041900, end_date=20240330T041909
[2024-03-30 04:19:09,570] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:19:09,922] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:25:33,884] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [queued]>
[2024-03-30 04:25:33,935] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [queued]>
[2024-03-30 04:25:33,935] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:25:33,935] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:25:33,936] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:25:33,983] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-06-02 06:00:00+00:00
[2024-03-30 04:25:34,016] {standard_task_runner.py:52} INFO - Started process 4397 to run task
[2024-03-30 04:25:34,070] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-06-02T06:00:00+00:00', '--job-id', '2214', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp633ep9t1', '--error-file', '/tmp/tmpigrq1zdz']
[2024-03-30 04:25:34,102] {standard_task_runner.py:77} INFO - Job 2214: Subtask download_dataset_task
[2024-03-30 04:25:34,481] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:25:34,665] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:25:34,706] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-06-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-06-02T06:00:00+00:00
[2024-03-30 04:25:34,708] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:25:34,709] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-06.parquet > /opt/***/yellowtaxi_tripdata_2023-06.parquet']
[2024-03-30 04:25:34,756] {subprocess.py:85} INFO - Output:
[2024-03-30 04:25:41,431] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:25:41,864] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230602T060000, start_date=20240330T042533, end_date=20240330T042541
[2024-03-30 04:25:41,939] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:25:42,072] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:44:52,720] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [queued]>
[2024-03-30 04:44:53,269] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [queued]>
[2024-03-30 04:44:53,337] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:44:53,362] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:44:53,365] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:44:55,327] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-06-02 06:00:00+00:00
[2024-03-30 04:44:55,503] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-06-02T06:00:00+00:00', '--job-id', '2357', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp8vsd_b6n', '--error-file', '/tmp/tmpgvznnef1']
[2024-03-30 04:44:55,497] {standard_task_runner.py:52} INFO - Started process 5780 to run task
[2024-03-30 04:44:55,559] {standard_task_runner.py:77} INFO - Job 2357: Subtask download_dataset_task
[2024-03-30 04:44:56,135] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:44:56,400] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:44:56,496] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-06-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-06-02T06:00:00+00:00
[2024-03-30 04:44:56,502] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:44:56,504] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-06.parquet > /opt/***/yellowtaxi_tripdata_2023-06.parquet']
[2024-03-30 04:44:56,630] {subprocess.py:85} INFO - Output:
[2024-03-30 04:45:03,287] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:45:03,460] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230602T060000, start_date=20240330T044452, end_date=20240330T044503
[2024-03-30 04:45:03,738] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:45:03,984] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 05:00:09,708] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:09,746] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:09,747] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:09,748] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 05:00:09,748] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:09,807] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-06-02 06:00:00+00:00
[2024-03-30 05:00:09,829] {standard_task_runner.py:52} INFO - Started process 6845 to run task
[2024-03-30 05:00:09,852] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-06-02T06:00:00+00:00', '--job-id', '2460', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpl2y3qp3a', '--error-file', '/tmp/tmprbcya6fq']
[2024-03-30 05:00:09,868] {standard_task_runner.py:77} INFO - Job 2460: Subtask download_dataset_task
[2024-03-30 05:00:10,072] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 05:00:10,225] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 05:00:10,286] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-06-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-06-02T06:00:00+00:00
[2024-03-30 05:00:10,289] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 05:00:10,290] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-06.parquet > /opt/***/yellowtaxi_tripdata_2023-06.parquet']
[2024-03-30 05:00:10,354] {subprocess.py:85} INFO - Output:
[2024-03-30 05:00:17,008] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 05:00:17,182] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230602T060000, start_date=20240330T050009, end_date=20240330T050017
[2024-03-30 05:00:17,284] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 05:00:17,479] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:02:21,492] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [queued]>
[2024-03-30 09:02:21,545] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [queued]>
[2024-03-30 09:02:21,545] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:02:21,549] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:02:21,549] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:02:21,648] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-06-02 06:00:00+00:00
[2024-03-30 09:02:21,729] {standard_task_runner.py:52} INFO - Started process 18360 to run task
[2024-03-30 09:02:21,811] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-06-02T06:00:00+00:00', '--job-id', '2573', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp052ue0ck', '--error-file', '/tmp/tmppvf294fm']
[2024-03-30 09:02:21,839] {standard_task_runner.py:77} INFO - Job 2573: Subtask download_dataset_task
[2024-03-30 09:02:22,358] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:02:22,829] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:02:22,905] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-06-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-06-02T06:00:00+00:00
[2024-03-30 09:02:22,907] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 09:02:22,908] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-06.parquet > /opt/***/yellowtaxi_tripdata_2023-06.parquet']
[2024-03-30 09:02:22,965] {subprocess.py:85} INFO - Output:
[2024-03-30 09:02:29,674] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 09:02:30,581] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230602T060000, start_date=20240330T090221, end_date=20240330T090230
[2024-03-30 09:02:31,231] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:02:32,251] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:57:20,971] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [queued]>
[2024-03-30 11:57:21,030] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [queued]>
[2024-03-30 11:57:21,032] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:57:21,032] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:57:21,033] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:57:21,083] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-06-02 06:00:00+00:00
[2024-03-30 11:57:21,102] {standard_task_runner.py:52} INFO - Started process 28557 to run task
[2024-03-30 11:57:21,130] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-06-02T06:00:00+00:00', '--job-id', '2900', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp3toarw3x', '--error-file', '/tmp/tmp1zgkag9t']
[2024-03-30 11:57:21,151] {standard_task_runner.py:77} INFO - Job 2900: Subtask download_dataset_task
[2024-03-30 11:57:21,351] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:57:21,443] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:57:21,530] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-06-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-06-02T06:00:00+00:00
[2024-03-30 11:57:21,533] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:57:21,534] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-06.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2023-06.parquet']
[2024-03-30 11:57:21,562] {subprocess.py:85} INFO - Output:
[2024-03-30 11:57:28,075] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:57:28,599] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230602T060000, start_date=20240330T115720, end_date=20240330T115728
[2024-03-30 11:57:28,791] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:57:29,015] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:01:52,501] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:52,646] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:52,646] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:52,647] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:01:52,647] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:52,771] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-06-02 06:00:00+00:00
[2024-04-30 03:01:52,808] {standard_task_runner.py:52} INFO - Started process 909 to run task
[2024-04-30 03:01:52,868] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-06-02T06:00:00+00:00', '--job-id', '3184', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpa_jj9zow', '--error-file', '/tmp/tmpq9y1p7kh']
[2024-04-30 03:01:52,915] {standard_task_runner.py:77} INFO - Job 3184: Subtask download_dataset_task
[2024-04-30 03:01:53,334] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:01:53,515] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:01:53,667] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-06-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-06-02T06:00:00+00:00
[2024-04-30 03:01:53,683] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 03:01:53,684] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-06.parquet > /opt/***/cleaned_data/yellowtaxi_tripdata_2023-06.parquet']
[2024-04-30 03:01:53,742] {subprocess.py:85} INFO - Output:
[2024-04-30 03:01:58,873] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 03:01:59,046] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230602T060000, start_date=20240430T030152, end_date=20240430T030159
[2024-04-30 03:01:59,152] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:01:59,269] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:35:04,108] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [queued]>
[2024-04-30 04:35:04,138] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [queued]>
[2024-04-30 04:35:04,139] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:35:04,139] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:35:04,140] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:35:04,163] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-06-02 06:00:00+00:00
[2024-04-30 04:35:04,172] {standard_task_runner.py:52} INFO - Started process 5789 to run task
[2024-04-30 04:35:04,191] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-06-02T06:00:00+00:00', '--job-id', '3309', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpgze2l7q7', '--error-file', '/tmp/tmp3rwtzdpt']
[2024-04-30 04:35:04,197] {standard_task_runner.py:77} INFO - Job 3309: Subtask download_dataset_task
[2024-04-30 04:35:04,299] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-06-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:35:04,367] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:35:04,414] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-06-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-06-02T06:00:00+00:00
[2024-04-30 04:35:04,420] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 04:35:04,421] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-06.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2023-06.parquet']
[2024-04-30 04:35:04,442] {subprocess.py:85} INFO - Output:
[2024-04-30 04:35:08,912] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 04:35:08,951] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230602T060000, start_date=20240430T043504, end_date=20240430T043508
[2024-04-30 04:35:08,987] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 04:35:09,038] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
