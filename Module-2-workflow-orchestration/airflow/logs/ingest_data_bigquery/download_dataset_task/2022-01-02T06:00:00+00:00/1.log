[2024-03-29 07:24:28,319] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:28,405] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:28,406] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:28,406] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:24:28,406] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:28,495] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-01-02 06:00:00+00:00
[2024-03-29 07:24:28,512] {standard_task_runner.py:52} INFO - Started process 512 to run task
[2024-03-29 07:24:28,593] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-01-02T06:00:00+00:00', '--job-id', '1445', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpp5gg9rz9', '--error-file', '/tmp/tmp3p_u0ljn']
[2024-03-29 07:24:28,636] {standard_task_runner.py:77} INFO - Job 1445: Subtask download_dataset_task
[2024-03-29 07:24:29,175] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:24:29,336] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:24:29,452] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-02T06:00:00+00:00
[2024-03-29 07:24:29,453] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:24:29,454] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet > /opt/***/yellowtaxi_tripdata_2022-01.parquet']
[2024-03-29 07:24:29,630] {subprocess.py:85} INFO - Output:
[2024-03-29 07:24:34,985] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:24:35,571] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220102T060000, start_date=20240329T072428, end_date=20240329T072435
[2024-03-29 07:24:35,817] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:24:36,078] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:30:47,781] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-29 07:30:47,871] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-29 07:30:47,873] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:30:47,873] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:30:47,873] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:30:47,997] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-01-02 06:00:00+00:00
[2024-03-29 07:30:48,101] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-01-02T06:00:00+00:00', '--job-id', '1509', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpn7oomedf', '--error-file', '/tmp/tmpf9xjl9xh']
[2024-03-29 07:30:48,059] {standard_task_runner.py:52} INFO - Started process 1028 to run task
[2024-03-29 07:30:48,151] {standard_task_runner.py:77} INFO - Job 1509: Subtask download_dataset_task
[2024-03-29 07:30:48,472] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:30:48,636] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:30:48,717] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-02T06:00:00+00:00
[2024-03-29 07:30:48,718] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:30:48,719] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet > /opt/***/yellowtaxi_tripdata_2022-01.parquet']
[2024-03-29 07:30:48,834] {subprocess.py:85} INFO - Output:
[2024-03-29 07:30:54,061] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:30:54,287] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220102T060000, start_date=20240329T073047, end_date=20240329T073054
[2024-03-29 07:30:54,512] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:30:55,550] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:37:33,976] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:34,001] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:34,006] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:34,007] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:37:34,008] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:34,056] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-01-02 06:00:00+00:00
[2024-03-29 07:37:34,064] {standard_task_runner.py:52} INFO - Started process 1560 to run task
[2024-03-29 07:37:34,087] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-01-02T06:00:00+00:00', '--job-id', '1573', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp5xt8jwj5', '--error-file', '/tmp/tmpqv4uhl6_']
[2024-03-29 07:37:34,114] {standard_task_runner.py:77} INFO - Job 1573: Subtask download_dataset_task
[2024-03-29 07:37:34,319] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:37:34,402] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:37:34,472] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-02T06:00:00+00:00
[2024-03-29 07:37:34,474] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:37:34,475] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet > /opt/***/yellowtaxi_tripdata_2022-01.parquet']
[2024-03-29 07:37:34,528] {subprocess.py:85} INFO - Output:
[2024-03-29 07:37:39,832] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:37:40,007] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220102T060000, start_date=20240329T073733, end_date=20240329T073740
[2024-03-29 07:37:40,280] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:37:41,053] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:08:30,310] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:30,367] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:30,367] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:30,368] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:08:30,369] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:30,454] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-01-02 06:00:00+00:00
[2024-03-29 08:08:30,485] {standard_task_runner.py:52} INFO - Started process 228 to run task
[2024-03-29 08:08:30,524] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-01-02T06:00:00+00:00', '--job-id', '1635', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp3t1i_7gb', '--error-file', '/tmp/tmpaphrqn6l']
[2024-03-29 08:08:30,551] {standard_task_runner.py:77} INFO - Job 1635: Subtask download_dataset_task
[2024-03-29 08:08:30,704] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:08:30,772] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:08:30,811] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-02T06:00:00+00:00
[2024-03-29 08:08:30,813] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:08:30,819] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet > /opt/***/yellowtaxi_tripdata_2022-01.parquet']
[2024-03-29 08:08:30,846] {subprocess.py:85} INFO - Output:
[2024-03-29 08:08:36,077] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:08:36,195] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220102T060000, start_date=20240329T080830, end_date=20240329T080836
[2024-03-29 08:08:36,344] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:08:36,646] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:10:59,456] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-29 08:10:59,524] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-29 08:10:59,525] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:10:59,526] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:10:59,527] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:10:59,585] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-01-02 06:00:00+00:00
[2024-03-29 08:10:59,615] {standard_task_runner.py:52} INFO - Started process 516 to run task
[2024-03-29 08:10:59,659] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-01-02T06:00:00+00:00', '--job-id', '1680', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp65z18ehm', '--error-file', '/tmp/tmp0pwc4i8_']
[2024-03-29 08:10:59,690] {standard_task_runner.py:77} INFO - Job 1680: Subtask download_dataset_task
[2024-03-29 08:10:59,992] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:11:00,180] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:11:00,236] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-02T06:00:00+00:00
[2024-03-29 08:11:00,239] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:11:00,240] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet > /opt/***/yellowtaxi_tripdata_2022-01.parquet']
[2024-03-29 08:11:00,277] {subprocess.py:85} INFO - Output:
[2024-03-29 08:11:05,723] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:11:06,303] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220102T060000, start_date=20240329T081059, end_date=20240329T081106
[2024-03-29 08:11:06,708] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:11:07,508] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:30:04,726] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:04,875] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:04,876] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:04,876] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:30:04,876] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:04,983] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-01-02 06:00:00+00:00
[2024-03-30 03:30:05,014] {standard_task_runner.py:52} INFO - Started process 437 to run task
[2024-03-30 03:30:05,074] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-01-02T06:00:00+00:00', '--job-id', '1820', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmprb_rdu0h', '--error-file', '/tmp/tmpe7qw5fjg']
[2024-03-30 03:30:05,160] {standard_task_runner.py:77} INFO - Job 1820: Subtask download_dataset_task
[2024-03-30 03:30:05,471] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:30:05,667] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:30:05,783] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-02T06:00:00+00:00
[2024-03-30 03:30:05,785] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:30:05,786] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet > /opt/***/yellowtaxi_tripdata_2022-01.parquet']
[2024-03-30 03:30:05,902] {subprocess.py:85} INFO - Output:
[2024-03-30 03:30:11,192] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:30:11,254] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220102T060000, start_date=20240330T033004, end_date=20240330T033011
[2024-03-30 03:30:11,339] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:30:11,719] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:42:00,500] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-30 03:42:00,646] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-30 03:42:00,650] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:42:00,650] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:42:00,663] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:42:00,781] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-01-02 06:00:00+00:00
[2024-03-30 03:42:00,827] {standard_task_runner.py:52} INFO - Started process 1306 to run task
[2024-03-30 03:42:00,902] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-01-02T06:00:00+00:00', '--job-id', '1904', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp47ls4za2', '--error-file', '/tmp/tmpzswgs05k']
[2024-03-30 03:42:00,965] {standard_task_runner.py:77} INFO - Job 1904: Subtask download_dataset_task
[2024-03-30 03:42:01,431] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:42:01,522] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:42:01,589] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-02T06:00:00+00:00
[2024-03-30 03:42:01,590] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:42:01,592] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet > /opt/***/yellowtaxi_tripdata_2022-01.parquet']
[2024-03-30 03:42:01,721] {subprocess.py:85} INFO - Output:
[2024-03-30 03:42:06,897] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:42:07,036] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220102T060000, start_date=20240330T034200, end_date=20240330T034207
[2024-03-30 03:42:07,225] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:42:07,356] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:18:10,062] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:10,241] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:10,245] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:10,245] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:18:10,245] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:10,307] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-01-02 06:00:00+00:00
[2024-03-30 04:18:10,384] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-01-02T06:00:00+00:00', '--job-id', '2084', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpa1yihv7u', '--error-file', '/tmp/tmpgwhfwz_h']
[2024-03-30 04:18:10,405] {standard_task_runner.py:77} INFO - Job 2084: Subtask download_dataset_task
[2024-03-30 04:18:10,342] {standard_task_runner.py:52} INFO - Started process 3545 to run task
[2024-03-30 04:18:10,803] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:18:11,015] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:18:11,127] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-02T06:00:00+00:00
[2024-03-30 04:18:11,128] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:18:11,130] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet > /opt/***/yellowtaxi_tripdata_2022-01.parquet']
[2024-03-30 04:18:11,226] {subprocess.py:85} INFO - Output:
[2024-03-30 04:18:16,461] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:18:16,587] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220102T060000, start_date=20240330T041810, end_date=20240330T041816
[2024-03-30 04:18:16,676] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:18:17,075] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:24:45,587] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-30 04:24:45,627] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-30 04:24:45,627] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:24:45,627] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:24:45,627] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:24:45,669] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-01-02 06:00:00+00:00
[2024-03-30 04:24:45,692] {standard_task_runner.py:52} INFO - Started process 4166 to run task
[2024-03-30 04:24:45,730] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-01-02T06:00:00+00:00', '--job-id', '2165', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp3y36qgiv', '--error-file', '/tmp/tmpem2o45lv']
[2024-03-30 04:24:45,752] {standard_task_runner.py:77} INFO - Job 2165: Subtask download_dataset_task
[2024-03-30 04:24:46,073] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:24:46,226] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:24:46,332] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-02T06:00:00+00:00
[2024-03-30 04:24:46,340] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:24:46,341] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet > /opt/***/yellowtaxi_tripdata_2022-01.parquet']
[2024-03-30 04:24:46,454] {subprocess.py:85} INFO - Output:
[2024-03-30 04:24:51,766] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:24:51,906] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220102T060000, start_date=20240330T042445, end_date=20240330T042451
[2024-03-30 04:24:52,103] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:24:52,235] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:38:43,682] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-30 04:38:43,905] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-30 04:38:43,906] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:38:43,906] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:38:43,906] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:38:44,088] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-01-02 06:00:00+00:00
[2024-03-30 04:38:44,193] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-01-02T06:00:00+00:00', '--job-id', '2279', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpxqdrhqka', '--error-file', '/tmp/tmpwzkgx90e']
[2024-03-30 04:38:44,205] {standard_task_runner.py:77} INFO - Job 2279: Subtask download_dataset_task
[2024-03-30 04:38:44,211] {standard_task_runner.py:52} INFO - Started process 5211 to run task
[2024-03-30 04:38:44,413] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:38:44,553] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:38:44,630] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-02T06:00:00+00:00
[2024-03-30 04:38:44,635] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:38:44,636] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet > /opt/***/yellowtaxi_tripdata_2022-01.parquet']
[2024-03-30 04:38:44,655] {subprocess.py:85} INFO - Output:
[2024-03-30 04:38:50,040] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:38:50,551] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220102T060000, start_date=20240330T043843, end_date=20240330T043850
[2024-03-30 04:38:50,673] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:38:51,627] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:59:26,899] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:26,984] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:26,984] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:26,984] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:59:26,984] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:27,079] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-01-02 06:00:00+00:00
[2024-03-30 04:59:27,143] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-01-02T06:00:00+00:00', '--job-id', '2411', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpwb3wocew', '--error-file', '/tmp/tmp_8k8et_k']
[2024-03-30 04:59:27,167] {standard_task_runner.py:77} INFO - Job 2411: Subtask download_dataset_task
[2024-03-30 04:59:27,122] {standard_task_runner.py:52} INFO - Started process 6627 to run task
[2024-03-30 04:59:27,431] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:59:27,534] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:59:27,596] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-02T06:00:00+00:00
[2024-03-30 04:59:27,598] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:59:27,599] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet > /opt/***/yellowtaxi_tripdata_2022-01.parquet']
[2024-03-30 04:59:27,697] {subprocess.py:85} INFO - Output:
[2024-03-30 04:59:33,021] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:59:33,181] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220102T060000, start_date=20240330T045926, end_date=20240330T045933
[2024-03-30 04:59:33,345] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:59:33,614] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:01:30,985] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:31,113] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:31,113] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:31,113] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:01:31,113] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:31,296] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-01-02 06:00:00+00:00
[2024-03-30 09:01:31,398] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-01-02T06:00:00+00:00', '--job-id', '2522', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp5d1soxyu', '--error-file', '/tmp/tmpz1595p15']
[2024-03-30 09:01:31,453] {standard_task_runner.py:77} INFO - Job 2522: Subtask download_dataset_task
[2024-03-30 09:01:31,364] {standard_task_runner.py:52} INFO - Started process 18127 to run task
[2024-03-30 09:01:31,916] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:01:32,074] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:01:32,301] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-02T06:00:00+00:00
[2024-03-30 09:01:32,314] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 09:01:32,324] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet > /opt/***/yellowtaxi_tripdata_2022-01.parquet']
[2024-03-30 09:01:32,453] {subprocess.py:85} INFO - Output:
[2024-03-30 09:01:38,121] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 09:01:39,241] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220102T060000, start_date=20240330T090131, end_date=20240330T090139
[2024-03-30 09:01:39,391] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:01:39,528] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 10:50:04,718] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-30 10:50:04,775] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-30 10:50:04,775] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:50:04,775] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 10:50:04,775] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:50:04,796] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-01-02 06:00:00+00:00
[2024-03-30 10:50:04,823] {standard_task_runner.py:52} INFO - Started process 23501 to run task
[2024-03-30 10:50:04,831] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-01-02T06:00:00+00:00', '--job-id', '2638', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp8q39hsaa', '--error-file', '/tmp/tmp4y9pd_8r']
[2024-03-30 10:50:04,850] {standard_task_runner.py:77} INFO - Job 2638: Subtask download_dataset_task
[2024-03-30 10:50:05,083] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 10:50:05,200] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 10:50:05,264] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-02T06:00:00+00:00
[2024-03-30 10:50:05,266] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 10:50:05,267] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet > /opt/***raw_data/yellowtaxi_tripdata_2022-01.parquet']
[2024-03-30 10:50:05,298] {subprocess.py:85} INFO - Output:
[2024-03-30 10:50:05,318] {subprocess.py:89} INFO - bash: /opt/***raw_data/yellowtaxi_tripdata_2022-01.parquet: No such file or directory
[2024-03-30 10:50:05,340] {subprocess.py:93} INFO - Command exited with return code 1
[2024-03-30 10:50:05,744] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:50:05,781] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220102T060000, start_date=20240330T105004, end_date=20240330T105005
[2024-03-30 10:50:05,839] {standard_task_runner.py:92} ERROR - Failed to execute job 2638 for task download_dataset_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:50:05,869] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 10:50:05,959] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 10:54:55,881] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-30 10:54:55,928] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-30 10:54:55,928] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:54:55,928] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 10:54:55,928] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:54:55,978] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-01-02 06:00:00+00:00
[2024-03-30 10:54:56,000] {standard_task_runner.py:52} INFO - Started process 23799 to run task
[2024-03-30 10:54:56,019] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-01-02T06:00:00+00:00', '--job-id', '2652', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpdua_j6bg', '--error-file', '/tmp/tmp60kii9e7']
[2024-03-30 10:54:56,063] {standard_task_runner.py:77} INFO - Job 2652: Subtask download_dataset_task
[2024-03-30 10:54:56,363] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 10:54:56,480] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 10:54:56,553] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-02T06:00:00+00:00
[2024-03-30 10:54:56,556] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 10:54:56,558] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet > /opt/***raw_data/yellowtaxi_tripdata_2022-01.parquet']
[2024-03-30 10:54:56,591] {subprocess.py:85} INFO - Output:
[2024-03-30 10:54:56,603] {subprocess.py:89} INFO - bash: /opt/***raw_data/yellowtaxi_tripdata_2022-01.parquet: No such file or directory
[2024-03-30 10:54:56,617] {subprocess.py:93} INFO - Command exited with return code 1
[2024-03-30 10:54:56,645] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:54:56,655] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220102T060000, start_date=20240330T105455, end_date=20240330T105456
[2024-03-30 10:54:56,691] {standard_task_runner.py:92} ERROR - Failed to execute job 2652 for task download_dataset_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:54:56,778] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 10:54:56,854] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:04:03,363] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-30 11:04:03,463] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-30 11:04:03,463] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:04:03,466] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:04:03,467] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:04:03,595] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-01-02 06:00:00+00:00
[2024-03-30 11:04:03,689] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-01-02T06:00:00+00:00', '--job-id', '2685', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp_ux48lpk', '--error-file', '/tmp/tmp5yvpiiax']
[2024-03-30 11:04:03,742] {standard_task_runner.py:77} INFO - Job 2685: Subtask download_dataset_task
[2024-03-30 11:04:03,641] {standard_task_runner.py:52} INFO - Started process 24384 to run task
[2024-03-30 11:04:04,094] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:04:04,271] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:04:04,547] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-02T06:00:00+00:00
[2024-03-30 11:04:04,550] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:04:04,552] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-01.parquet']
[2024-03-30 11:04:04,638] {subprocess.py:85} INFO - Output:
[2024-03-30 11:04:09,795] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:04:10,237] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220102T060000, start_date=20240330T110403, end_date=20240330T110410
[2024-03-30 11:04:10,484] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:04:10,799] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:15:11,691] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-30 11:15:11,747] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-30 11:15:11,747] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:15:11,747] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:15:11,747] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:15:11,802] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-01-02 06:00:00+00:00
[2024-03-30 11:15:11,824] {standard_task_runner.py:52} INFO - Started process 25293 to run task
[2024-03-30 11:15:11,866] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-01-02T06:00:00+00:00', '--job-id', '2730', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpvp4cz14b', '--error-file', '/tmp/tmpb7wdh_l7']
[2024-03-30 11:15:11,891] {standard_task_runner.py:77} INFO - Job 2730: Subtask download_dataset_task
[2024-03-30 11:15:12,170] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:15:12,343] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:15:12,427] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-02T06:00:00+00:00
[2024-03-30 11:15:12,431] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:15:12,441] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-01.parquet']
[2024-03-30 11:15:12,485] {subprocess.py:85} INFO - Output:
[2024-03-30 11:15:17,650] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:15:18,001] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220102T060000, start_date=20240330T111511, end_date=20240330T111518
[2024-03-30 11:15:18,245] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:15:18,774] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:33:53,884] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-30 11:33:53,942] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-03-30 11:33:53,942] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:33:53,943] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:33:53,943] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:33:54,007] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-01-02 06:00:00+00:00
[2024-03-30 11:33:54,040] {standard_task_runner.py:52} INFO - Started process 26854 to run task
[2024-03-30 11:33:54,075] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-01-02T06:00:00+00:00', '--job-id', '2807', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpnernux_w', '--error-file', '/tmp/tmpoqfcdije']
[2024-03-30 11:33:54,100] {standard_task_runner.py:77} INFO - Job 2807: Subtask download_dataset_task
[2024-03-30 11:33:54,287] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:33:54,481] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:33:54,577] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-02T06:00:00+00:00
[2024-03-30 11:33:54,579] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:33:54,580] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-01.parquet']
[2024-03-30 11:33:54,682] {subprocess.py:85} INFO - Output:
[2024-03-30 11:34:00,338] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:34:00,636] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220102T060000, start_date=20240330T113353, end_date=20240330T113400
[2024-03-30 11:34:01,014] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:34:01,621] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-28 09:15:32,543] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:32,611] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:32,612] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:32,612] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-28 09:15:32,613] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:32,658] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-01-02 06:00:00+00:00
[2024-04-28 09:15:32,685] {standard_task_runner.py:52} INFO - Started process 1434 to run task
[2024-04-28 09:15:32,705] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-01-02T06:00:00+00:00', '--job-id', '3001', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpd6uq4sma', '--error-file', '/tmp/tmp09r4688j']
[2024-04-28 09:15:32,714] {standard_task_runner.py:77} INFO - Job 3001: Subtask download_dataset_task
[2024-04-28 09:15:32,888] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [running]> on host 6c6a4ca9ff8e
[2024-04-28 09:15:33,020] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-28 09:15:33,102] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-02T06:00:00+00:00
[2024-04-28 09:15:33,104] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-28 09:15:33,105] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-01.parquet']
[2024-04-28 09:15:33,167] {subprocess.py:85} INFO - Output:
[2024-04-28 09:15:37,030] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-28 09:15:37,651] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220102T060000, start_date=20240428T091532, end_date=20240428T091537
[2024-04-28 09:15:38,280] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-28 09:15:38,810] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:13:48,348] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-04-30 02:13:48,377] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-04-30 02:13:48,377] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:13:48,378] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-30 02:13:48,378] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:13:48,409] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-01-02 06:00:00+00:00
[2024-04-30 02:13:48,433] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-01-02T06:00:00+00:00', '--job-id', '3036', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpfph6q6x4', '--error-file', '/tmp/tmpaynk3zwq']
[2024-04-30 02:13:48,417] {standard_task_runner.py:52} INFO - Started process 356 to run task
[2024-04-30 02:13:48,452] {standard_task_runner.py:77} INFO - Job 3036: Subtask download_dataset_task
[2024-04-30 02:13:48,659] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [running]> on host a1ae6a0259c5
[2024-04-30 02:13:48,712] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:13:48,753] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-02T06:00:00+00:00
[2024-04-30 02:13:48,754] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 02:13:48,755] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-01.parquet']
[2024-04-30 02:13:48,773] {subprocess.py:85} INFO - Output:
[2024-04-30 02:13:52,376] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 02:13:52,761] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220102T060000, start_date=20240430T021348, end_date=20240430T021352
[2024-04-30 02:13:52,900] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 02:13:53,111] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:58:13,202] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:13,294] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:13,294] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:13,294] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 02:58:13,294] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:13,370] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-01-02 06:00:00+00:00
[2024-04-30 02:58:13,387] {standard_task_runner.py:52} INFO - Started process 403 to run task
[2024-04-30 02:58:13,410] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-01-02T06:00:00+00:00', '--job-id', '3102', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpymshyjll', '--error-file', '/tmp/tmpbj371_dj']
[2024-04-30 02:58:13,435] {standard_task_runner.py:77} INFO - Job 3102: Subtask download_dataset_task
[2024-04-30 02:58:13,603] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 02:58:13,690] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:58:13,748] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-02T06:00:00+00:00
[2024-04-30 02:58:13,750] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 02:58:13,751] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-01.parquet']
[2024-04-30 02:58:13,774] {subprocess.py:85} INFO - Output:
[2024-04-30 02:58:17,235] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 02:58:17,428] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220102T060000, start_date=20240430T025813, end_date=20240430T025817
[2024-04-30 02:58:17,520] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 02:58:17,700] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:01:09,421] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:09,548] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:09,548] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:09,548] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:01:09,550] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:09,601] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-01-02 06:00:00+00:00
[2024-04-30 03:01:09,613] {standard_task_runner.py:52} INFO - Started process 688 to run task
[2024-04-30 03:01:09,656] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-01-02T06:00:00+00:00', '--job-id', '3138', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpzbrlr2f0', '--error-file', '/tmp/tmp41aefrdt']
[2024-04-30 03:01:09,671] {standard_task_runner.py:77} INFO - Job 3138: Subtask download_dataset_task
[2024-04-30 03:01:09,866] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:01:09,972] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:01:10,038] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-02T06:00:00+00:00
[2024-04-30 03:01:10,039] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 03:01:10,041] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet > /opt/***/cleaned_data/yellowtaxi_tripdata_2022-01.parquet']
[2024-04-30 03:01:10,122] {subprocess.py:85} INFO - Output:
[2024-04-30 03:01:13,817] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 03:01:13,982] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220102T060000, start_date=20240430T030109, end_date=20240430T030113
[2024-04-30 03:01:14,126] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:01:14,381] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:30:03,615] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-04-30 04:30:03,726] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [queued]>
[2024-04-30 04:30:03,726] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:30:03,726] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:30:03,727] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:30:03,820] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-01-02 06:00:00+00:00
[2024-04-30 04:30:03,928] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-01-02T06:00:00+00:00', '--job-id', '3247', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpyqwco3hu', '--error-file', '/tmp/tmp_jffnx4b']
[2024-04-30 04:30:03,978] {standard_task_runner.py:77} INFO - Job 3247: Subtask download_dataset_task
[2024-04-30 04:30:03,895] {standard_task_runner.py:52} INFO - Started process 5211 to run task
[2024-04-30 04:30:04,254] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-01-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:30:04,532] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:30:04,695] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-02T06:00:00+00:00
[2024-04-30 04:30:04,703] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 04:30:04,711] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-01.parquet']
[2024-04-30 04:30:04,806] {subprocess.py:85} INFO - Output:
[2024-04-30 04:30:08,609] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 04:30:09,319] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220102T060000, start_date=20240430T043003, end_date=20240430T043009
[2024-04-30 04:30:09,477] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 04:30:09,865] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
