[2024-03-29 08:27:13,377] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [queued]>
[2024-03-29 08:27:13,460] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [queued]>
[2024-03-29 08:27:13,465] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:27:13,466] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:27:13,466] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:27:13,541] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-06-02 06:00:00+00:00
[2024-03-29 08:27:13,574] {standard_task_runner.py:52} INFO - Started process 1494 to run task
[2024-03-29 08:27:13,594] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-06-02T06:00:00+00:00', '--job-id', '1766', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpi69opgjk', '--error-file', '/tmp/tmpaci3jigi']
[2024-03-29 08:27:13,624] {standard_task_runner.py:77} INFO - Job 1766: Subtask download_dataset_task
[2024-03-29 08:27:13,842] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:27:14,010] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:27:14,139] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-06-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-02T06:00:00+00:00
[2024-03-29 08:27:14,140] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:27:14,141] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet > /opt/***/yellowtaxi_tripdata_2022-06.parquet']
[2024-03-29 08:27:14,180] {subprocess.py:85} INFO - Output:
[2024-03-29 08:27:21,266] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:27:22,005] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220602T060000, start_date=20240329T082713, end_date=20240329T082722
[2024-03-29 08:27:22,109] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:27:22,254] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:52:47,229] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [queued]>
[2024-03-30 03:52:47,367] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [queued]>
[2024-03-30 03:52:47,367] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:52:47,367] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:52:47,368] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:52:47,553] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-06-02 06:00:00+00:00
[2024-03-30 03:52:47,778] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-06-02T06:00:00+00:00', '--job-id', '1962', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpijz3re8g', '--error-file', '/tmp/tmpy39bzucz']
[2024-03-30 03:52:47,868] {standard_task_runner.py:77} INFO - Job 1962: Subtask download_dataset_task
[2024-03-30 03:52:47,673] {standard_task_runner.py:52} INFO - Started process 1981 to run task
[2024-03-30 03:52:48,581] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:52:49,066] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:52:49,419] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-06-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-02T06:00:00+00:00
[2024-03-30 03:52:49,432] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:52:49,439] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet > /opt/***/yellowtaxi_tripdata_2022-06.parquet']
[2024-03-30 03:52:49,591] {subprocess.py:85} INFO - Output:
[2024-03-30 03:52:57,914] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:52:59,162] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220602T060000, start_date=20240330T035247, end_date=20240330T035259
[2024-03-30 03:52:59,569] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:52:59,872] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:18:48,527] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:48,566] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:48,567] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:48,567] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:18:48,568] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:48,607] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-06-02 06:00:00+00:00
[2024-03-30 04:18:48,617] {standard_task_runner.py:52} INFO - Started process 3696 to run task
[2024-03-30 04:18:48,641] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-06-02T06:00:00+00:00', '--job-id', '2123', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpyo95c2r7', '--error-file', '/tmp/tmph4md692k']
[2024-03-30 04:18:48,662] {standard_task_runner.py:77} INFO - Job 2123: Subtask download_dataset_task
[2024-03-30 04:18:48,870] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:18:48,965] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:18:49,015] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-06-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-02T06:00:00+00:00
[2024-03-30 04:18:49,017] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:18:49,018] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet > /opt/***/yellowtaxi_tripdata_2022-06.parquet']
[2024-03-30 04:18:49,081] {subprocess.py:85} INFO - Output:
[2024-03-30 04:18:56,223] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:18:56,395] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220602T060000, start_date=20240330T041848, end_date=20240330T041856
[2024-03-30 04:18:56,484] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:18:56,904] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:25:24,057] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [queued]>
[2024-03-30 04:25:24,104] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [queued]>
[2024-03-30 04:25:24,104] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:25:24,104] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:25:24,104] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:25:24,139] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-06-02 06:00:00+00:00
[2024-03-30 04:25:24,149] {standard_task_runner.py:52} INFO - Started process 4313 to run task
[2024-03-30 04:25:24,183] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-06-02T06:00:00+00:00', '--job-id', '2202', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpbhfce014', '--error-file', '/tmp/tmps6ldbh0_']
[2024-03-30 04:25:24,194] {standard_task_runner.py:77} INFO - Job 2202: Subtask download_dataset_task
[2024-03-30 04:25:24,327] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:25:24,500] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:25:24,573] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-06-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-02T06:00:00+00:00
[2024-03-30 04:25:24,575] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:25:24,576] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet > /opt/***/yellowtaxi_tripdata_2022-06.parquet']
[2024-03-30 04:25:24,609] {subprocess.py:85} INFO - Output:
[2024-03-30 04:25:31,079] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:25:31,553] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220602T060000, start_date=20240330T042524, end_date=20240330T042531
[2024-03-30 04:25:31,705] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:25:31,806] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:42:48,543] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [queued]>
[2024-03-30 04:42:48,555] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [queued]>
[2024-03-30 04:42:48,555] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:42:48,555] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:42:48,555] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:42:48,568] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-06-02 06:00:00+00:00
[2024-03-30 04:42:48,574] {standard_task_runner.py:52} INFO - Started process 5526 to run task
[2024-03-30 04:42:48,579] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-06-02T06:00:00+00:00', '--job-id', '2320', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp82gcdl1v', '--error-file', '/tmp/tmps8qsvivg']
[2024-03-30 04:42:48,583] {standard_task_runner.py:77} INFO - Job 2320: Subtask download_dataset_task
[2024-03-30 04:42:48,650] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:42:48,689] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:42:48,711] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-06-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-02T06:00:00+00:00
[2024-03-30 04:42:48,712] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:42:48,713] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet > /opt/***/yellowtaxi_tripdata_2022-06.parquet']
[2024-03-30 04:42:48,726] {subprocess.py:85} INFO - Output:
[2024-03-30 04:42:55,299] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:42:55,331] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220602T060000, start_date=20240330T044248, end_date=20240330T044255
[2024-03-30 04:42:55,389] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:42:55,429] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 05:00:01,184] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:01,220] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:01,221] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:01,221] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 05:00:01,222] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:01,275] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-06-02 06:00:00+00:00
[2024-03-30 05:00:01,286] {standard_task_runner.py:52} INFO - Started process 6766 to run task
[2024-03-30 05:00:01,306] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-06-02T06:00:00+00:00', '--job-id', '2447', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpa1ca9_4e', '--error-file', '/tmp/tmpemgb4dcg']
[2024-03-30 05:00:01,337] {standard_task_runner.py:77} INFO - Job 2447: Subtask download_dataset_task
[2024-03-30 05:00:01,599] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 05:00:01,721] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 05:00:01,801] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-06-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-02T06:00:00+00:00
[2024-03-30 05:00:01,803] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 05:00:01,804] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet > /opt/***/yellowtaxi_tripdata_2022-06.parquet']
[2024-03-30 05:00:01,838] {subprocess.py:85} INFO - Output:
[2024-03-30 05:00:08,334] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 05:00:08,838] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220602T060000, start_date=20240330T050001, end_date=20240330T050008
[2024-03-30 05:00:08,944] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 05:00:09,156] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:02:10,385] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [queued]>
[2024-03-30 09:02:10,483] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [queued]>
[2024-03-30 09:02:10,484] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:02:10,485] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:02:10,489] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:02:10,555] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-06-02 06:00:00+00:00
[2024-03-30 09:02:10,576] {standard_task_runner.py:52} INFO - Started process 18289 to run task
[2024-03-30 09:02:10,594] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-06-02T06:00:00+00:00', '--job-id', '2563', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp69dcn1i_', '--error-file', '/tmp/tmpalukf9dt']
[2024-03-30 09:02:10,613] {standard_task_runner.py:77} INFO - Job 2563: Subtask download_dataset_task
[2024-03-30 09:02:10,817] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:02:10,974] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:02:11,115] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-06-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-02T06:00:00+00:00
[2024-03-30 09:02:11,121] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 09:02:11,122] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet > /opt/***/yellowtaxi_tripdata_2022-06.parquet']
[2024-03-30 09:02:11,204] {subprocess.py:85} INFO - Output:
[2024-03-30 09:02:17,892] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 09:02:18,257] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220602T060000, start_date=20240330T090210, end_date=20240330T090218
[2024-03-30 09:02:18,434] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:02:18,753] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:31:08,603] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [queued]>
[2024-03-30 11:31:08,616] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [queued]>
[2024-03-30 11:31:08,616] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:31:08,617] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:31:08,617] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:31:08,628] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-06-02 06:00:00+00:00
[2024-03-30 11:31:08,635] {standard_task_runner.py:52} INFO - Started process 26649 to run task
[2024-03-30 11:31:08,641] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-06-02T06:00:00+00:00', '--job-id', '2792', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpzbs5y_5y', '--error-file', '/tmp/tmpxs5tbgit']
[2024-03-30 11:31:08,647] {standard_task_runner.py:77} INFO - Job 2792: Subtask download_dataset_task
[2024-03-30 11:31:08,711] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:31:08,755] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:31:08,784] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-06-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-02T06:00:00+00:00
[2024-03-30 11:31:08,785] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:31:08,786] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-06.parquet']
[2024-03-30 11:31:08,800] {subprocess.py:85} INFO - Output:
[2024-03-30 11:31:15,438] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:31:15,485] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220602T060000, start_date=20240330T113108, end_date=20240330T113115
[2024-03-30 11:31:15,548] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:31:15,607] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:51:15,188] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [queued]>
[2024-03-30 11:51:15,202] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [queued]>
[2024-03-30 11:51:15,202] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:51:15,203] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:51:15,203] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:51:15,214] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-06-02 06:00:00+00:00
[2024-03-30 11:51:15,222] {standard_task_runner.py:52} INFO - Started process 27766 to run task
[2024-03-30 11:51:15,228] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-06-02T06:00:00+00:00', '--job-id', '2853', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpv7p4u1qa', '--error-file', '/tmp/tmp8m87xfgv']
[2024-03-30 11:51:15,234] {standard_task_runner.py:77} INFO - Job 2853: Subtask download_dataset_task
[2024-03-30 11:51:15,298] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:51:15,339] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:51:15,364] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-06-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-02T06:00:00+00:00
[2024-03-30 11:51:15,366] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:51:15,366] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-06.parquet']
[2024-03-30 11:51:15,380] {subprocess.py:85} INFO - Output:
[2024-03-30 11:51:22,960] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:51:23,079] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220602T060000, start_date=20240330T115115, end_date=20240330T115123
[2024-03-30 11:51:23,133] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:51:23,201] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:01:41,312] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:41,376] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:41,379] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:41,382] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:01:41,384] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:41,429] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-06-02 06:00:00+00:00
[2024-04-30 03:01:41,455] {standard_task_runner.py:52} INFO - Started process 823 to run task
[2024-04-30 03:01:41,474] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-06-02T06:00:00+00:00', '--job-id', '3170', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp1n5v3lnn', '--error-file', '/tmp/tmprpcbzwbq']
[2024-04-30 03:01:41,493] {standard_task_runner.py:77} INFO - Job 3170: Subtask download_dataset_task
[2024-04-30 03:01:41,792] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:01:42,007] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:01:42,085] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-06-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-02T06:00:00+00:00
[2024-04-30 03:01:42,086] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 03:01:42,087] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet > /opt/***/cleaned_data/yellowtaxi_tripdata_2022-06.parquet']
[2024-04-30 03:01:42,157] {subprocess.py:85} INFO - Output:
[2024-04-30 03:01:46,757] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 03:01:46,877] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220602T060000, start_date=20240430T030141, end_date=20240430T030146
[2024-04-30 03:01:46,971] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:01:47,064] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:33:31,671] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [queued]>
[2024-04-30 04:33:31,716] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [queued]>
[2024-04-30 04:33:31,717] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:33:31,718] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:33:31,718] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:33:31,743] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-06-02 06:00:00+00:00
[2024-04-30 04:33:31,753] {standard_task_runner.py:52} INFO - Started process 5473 to run task
[2024-04-30 04:33:31,790] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-06-02T06:00:00+00:00', '--job-id', '3273', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpkqa7tjl1', '--error-file', '/tmp/tmpca_umqes']
[2024-04-30 04:33:31,808] {standard_task_runner.py:77} INFO - Job 3273: Subtask download_dataset_task
[2024-04-30 04:33:31,962] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-06-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:33:32,070] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:33:32,147] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-06-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-02T06:00:00+00:00
[2024-04-30 04:33:32,158] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 04:33:32,161] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-06.parquet']
[2024-04-30 04:33:32,228] {subprocess.py:85} INFO - Output:
[2024-04-30 04:33:36,690] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 04:33:36,744] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220602T060000, start_date=20240430T043331, end_date=20240430T043336
[2024-04-30 04:33:36,813] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 04:33:36,883] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
