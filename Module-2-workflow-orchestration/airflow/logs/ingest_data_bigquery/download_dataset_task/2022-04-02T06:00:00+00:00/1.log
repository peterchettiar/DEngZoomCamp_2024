[2024-03-29 07:24:30,392] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:30,450] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:30,451] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:30,452] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:24:30,452] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:30,473] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-04-02 06:00:00+00:00
[2024-03-29 07:24:30,492] {standard_task_runner.py:52} INFO - Started process 531 to run task
[2024-03-29 07:24:30,533] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-04-02T06:00:00+00:00', '--job-id', '1451', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpw3e1zbw3', '--error-file', '/tmp/tmp7ya4a0_6']
[2024-03-29 07:24:30,548] {standard_task_runner.py:77} INFO - Job 1451: Subtask download_dataset_task
[2024-03-29 07:24:30,753] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:24:30,889] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:24:30,959] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-04-02T06:00:00+00:00
[2024-03-29 07:24:30,962] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:24:30,964] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-04.parquet > /opt/***/yellowtaxi_tripdata_2022-04.parquet']
[2024-03-29 07:24:31,004] {subprocess.py:85} INFO - Output:
[2024-03-29 07:24:37,687] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:24:38,143] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220402T060000, start_date=20240329T072430, end_date=20240329T072438
[2024-03-29 07:24:38,255] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:24:38,413] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:08:30,280] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:30,339] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:30,340] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:30,340] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:08:30,345] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:30,464] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-04-02 06:00:00+00:00
[2024-03-29 08:08:30,486] {standard_task_runner.py:52} INFO - Started process 229 to run task
[2024-03-29 08:08:30,535] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-04-02T06:00:00+00:00', '--job-id', '1634', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpqdev7s0e', '--error-file', '/tmp/tmprgxe6kzg']
[2024-03-29 08:08:30,541] {standard_task_runner.py:77} INFO - Job 1634: Subtask download_dataset_task
[2024-03-29 08:08:30,722] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:08:30,798] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:08:30,837] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-04-02T06:00:00+00:00
[2024-03-29 08:08:30,839] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:08:30,839] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-04.parquet > /opt/***/yellowtaxi_tripdata_2022-04.parquet']
[2024-03-29 08:08:30,859] {subprocess.py:85} INFO - Output:
[2024-03-29 08:08:37,268] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:08:37,488] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220402T060000, start_date=20240329T080830, end_date=20240329T080837
[2024-03-29 08:08:37,717] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:08:38,567] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:11:01,057] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-03-29 08:11:01,108] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-03-29 08:11:01,109] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:11:01,109] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:11:01,109] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:11:01,139] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-04-02 06:00:00+00:00
[2024-03-29 08:11:01,208] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-04-02T06:00:00+00:00', '--job-id', '1683', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpjvxtks64', '--error-file', '/tmp/tmpuq2s6j9g']
[2024-03-29 08:11:01,224] {standard_task_runner.py:77} INFO - Job 1683: Subtask download_dataset_task
[2024-03-29 08:11:01,178] {standard_task_runner.py:52} INFO - Started process 533 to run task
[2024-03-29 08:11:01,377] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:11:01,527] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:11:01,601] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-04-02T06:00:00+00:00
[2024-03-29 08:11:01,603] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:11:01,604] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-04.parquet > /opt/***/yellowtaxi_tripdata_2022-04.parquet']
[2024-03-29 08:11:01,694] {subprocess.py:85} INFO - Output:
[2024-03-29 08:11:08,640] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:11:08,846] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220402T060000, start_date=20240329T081101, end_date=20240329T081108
[2024-03-29 08:11:09,126] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:11:09,800] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:52:38,099] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-03-30 03:52:38,479] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-03-30 03:52:38,479] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:52:38,479] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:52:38,479] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:52:38,919] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-04-02 06:00:00+00:00
[2024-03-30 03:52:39,209] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-04-02T06:00:00+00:00', '--job-id', '1959', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpvmeg26a5', '--error-file', '/tmp/tmp0leujbg5']
[2024-03-30 03:52:39,277] {standard_task_runner.py:77} INFO - Job 1959: Subtask download_dataset_task
[2024-03-30 03:52:39,033] {standard_task_runner.py:52} INFO - Started process 1960 to run task
[2024-03-30 03:52:40,293] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:52:41,331] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:52:41,763] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-04-02T06:00:00+00:00
[2024-03-30 03:52:41,766] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:52:41,788] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-04.parquet > /opt/***/yellowtaxi_tripdata_2022-04.parquet']
[2024-03-30 03:52:41,999] {subprocess.py:85} INFO - Output:
[2024-03-30 03:52:48,855] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:52:49,044] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220402T060000, start_date=20240330T035238, end_date=20240330T035249
[2024-03-30 03:52:49,321] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:52:50,610] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:18:11,487] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:11,563] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:11,563] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:11,563] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:18:11,563] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:11,616] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-04-02 06:00:00+00:00
[2024-03-30 04:18:11,680] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-04-02T06:00:00+00:00', '--job-id', '2087', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpjkkij7jx', '--error-file', '/tmp/tmpye_liohc']
[2024-03-30 04:18:11,708] {standard_task_runner.py:77} INFO - Job 2087: Subtask download_dataset_task
[2024-03-30 04:18:11,647] {standard_task_runner.py:52} INFO - Started process 3559 to run task
[2024-03-30 04:18:11,980] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:18:12,176] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:18:12,257] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-04-02T06:00:00+00:00
[2024-03-30 04:18:12,259] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:18:12,260] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-04.parquet > /opt/***/yellowtaxi_tripdata_2022-04.parquet']
[2024-03-30 04:18:12,328] {subprocess.py:85} INFO - Output:
[2024-03-30 04:18:18,847] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:18:19,355] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220402T060000, start_date=20240330T041811, end_date=20240330T041819
[2024-03-30 04:18:19,587] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:18:19,780] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:24:46,538] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-03-30 04:24:46,594] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-03-30 04:24:46,596] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:24:46,600] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:24:46,601] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:24:46,687] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-04-02 06:00:00+00:00
[2024-03-30 04:24:46,726] {standard_task_runner.py:52} INFO - Started process 4178 to run task
[2024-03-30 04:24:46,771] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-04-02T06:00:00+00:00', '--job-id', '2166', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmprfl1ol0c', '--error-file', '/tmp/tmpa2em7fa6']
[2024-03-30 04:24:46,820] {standard_task_runner.py:77} INFO - Job 2166: Subtask download_dataset_task
[2024-03-30 04:24:47,066] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:24:47,194] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:24:47,267] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-04-02T06:00:00+00:00
[2024-03-30 04:24:47,268] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:24:47,269] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-04.parquet > /opt/***/yellowtaxi_tripdata_2022-04.parquet']
[2024-03-30 04:24:47,331] {subprocess.py:85} INFO - Output:
[2024-03-30 04:24:53,806] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:24:54,294] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220402T060000, start_date=20240330T042446, end_date=20240330T042454
[2024-03-30 04:24:54,488] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:24:55,074] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:38:50,392] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-03-30 04:38:50,483] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-03-30 04:38:50,483] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:38:50,483] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:38:50,483] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:38:50,996] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-04-02 06:00:00+00:00
[2024-03-30 04:38:51,061] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-04-02T06:00:00+00:00', '--job-id', '2283', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpki_asfyn', '--error-file', '/tmp/tmpxlo4s0g6']
[2024-03-30 04:38:51,117] {standard_task_runner.py:77} INFO - Job 2283: Subtask download_dataset_task
[2024-03-30 04:38:51,079] {standard_task_runner.py:52} INFO - Started process 5242 to run task
[2024-03-30 04:38:52,250] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:38:52,580] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:38:52,804] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-04-02T06:00:00+00:00
[2024-03-30 04:38:52,815] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:38:52,816] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-04.parquet > /opt/***/yellowtaxi_tripdata_2022-04.parquet']
[2024-03-30 04:38:53,114] {subprocess.py:85} INFO - Output:
[2024-03-30 04:39:00,523] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:39:00,605] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220402T060000, start_date=20240330T043850, end_date=20240330T043900
[2024-03-30 04:39:00,698] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:39:01,230] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:59:53,319] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:53,436] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:53,437] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:53,439] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:59:53,439] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:53,501] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-04-02 06:00:00+00:00
[2024-03-30 04:59:53,581] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-04-02T06:00:00+00:00', '--job-id', '2439', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpm9de35gx', '--error-file', '/tmp/tmpo8919n9i']
[2024-03-30 04:59:53,610] {standard_task_runner.py:77} INFO - Job 2439: Subtask download_dataset_task
[2024-03-30 04:59:53,549] {standard_task_runner.py:52} INFO - Started process 6740 to run task
[2024-03-30 04:59:53,936] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:59:54,085] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:59:54,159] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-04-02T06:00:00+00:00
[2024-03-30 04:59:54,160] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:59:54,161] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-04.parquet > /opt/***/yellowtaxi_tripdata_2022-04.parquet']
[2024-03-30 04:59:54,238] {subprocess.py:85} INFO - Output:
[2024-03-30 05:00:00,770] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 05:00:00,843] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220402T060000, start_date=20240330T045953, end_date=20240330T050000
[2024-03-30 05:00:00,912] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 05:00:01,196] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:01:34,505] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:34,586] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:34,586] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:34,586] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:01:34,586] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:34,701] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-04-02 06:00:00+00:00
[2024-03-30 09:01:34,809] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-04-02T06:00:00+00:00', '--job-id', '2529', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpihryd1_w', '--error-file', '/tmp/tmp06sv5qau']
[2024-03-30 09:01:34,856] {standard_task_runner.py:77} INFO - Job 2529: Subtask download_dataset_task
[2024-03-30 09:01:34,769] {standard_task_runner.py:52} INFO - Started process 18159 to run task
[2024-03-30 09:01:35,157] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:01:35,305] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:01:35,374] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-04-02T06:00:00+00:00
[2024-03-30 09:01:35,378] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 09:01:35,381] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-04.parquet > /opt/***/yellowtaxi_tripdata_2022-04.parquet']
[2024-03-30 09:01:35,470] {subprocess.py:85} INFO - Output:
[2024-03-30 09:01:42,613] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 09:01:42,745] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220402T060000, start_date=20240330T090134, end_date=20240330T090142
[2024-03-30 09:01:42,818] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:01:42,984] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:04:07,264] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-03-30 11:04:07,313] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-03-30 11:04:07,313] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:04:07,313] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:04:07,315] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:04:07,379] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-04-02 06:00:00+00:00
[2024-03-30 11:04:07,439] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-04-02T06:00:00+00:00', '--job-id', '2689', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp67r7x6mw', '--error-file', '/tmp/tmpxj3p2nc4']
[2024-03-30 11:04:07,404] {standard_task_runner.py:52} INFO - Started process 24408 to run task
[2024-03-30 11:04:07,470] {standard_task_runner.py:77} INFO - Job 2689: Subtask download_dataset_task
[2024-03-30 11:04:07,903] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:04:08,216] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:04:08,322] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-04-02T06:00:00+00:00
[2024-03-30 11:04:08,336] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:04:08,349] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-04.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-04.parquet']
[2024-03-30 11:04:08,447] {subprocess.py:85} INFO - Output:
[2024-03-30 11:04:14,968] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:04:15,441] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220402T060000, start_date=20240330T110407, end_date=20240330T110415
[2024-03-30 11:04:15,929] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:04:17,320] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:30:05,604] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-03-30 11:30:05,617] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-03-30 11:30:05,618] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:30:05,618] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:30:05,618] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:30:05,631] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-04-02 06:00:00+00:00
[2024-03-30 11:30:05,638] {standard_task_runner.py:52} INFO - Started process 26518 to run task
[2024-03-30 11:30:05,644] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-04-02T06:00:00+00:00', '--job-id', '2782', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpl5y9yw_s', '--error-file', '/tmp/tmpvippoe08']
[2024-03-30 11:30:05,649] {standard_task_runner.py:77} INFO - Job 2782: Subtask download_dataset_task
[2024-03-30 11:30:05,715] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:30:05,754] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:30:05,777] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-04-02T06:00:00+00:00
[2024-03-30 11:30:05,779] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:30:05,780] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-04.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-04.parquet']
[2024-03-30 11:30:05,795] {subprocess.py:85} INFO - Output:
[2024-03-30 11:30:10,362] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:30:10,394] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220402T060000, start_date=20240330T113005, end_date=20240330T113010
[2024-03-30 11:30:10,443] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:30:10,487] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:51:14,365] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-03-30 11:51:14,398] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-03-30 11:51:14,399] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:51:14,399] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:51:14,400] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:51:14,430] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-04-02 06:00:00+00:00
[2024-03-30 11:51:14,462] {standard_task_runner.py:52} INFO - Started process 27757 to run task
[2024-03-30 11:51:14,485] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-04-02T06:00:00+00:00', '--job-id', '2851', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpnmgcvk7q', '--error-file', '/tmp/tmpvehxj70k']
[2024-03-30 11:51:14,507] {standard_task_runner.py:77} INFO - Job 2851: Subtask download_dataset_task
[2024-03-30 11:51:14,638] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:51:14,701] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:51:14,737] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-04-02T06:00:00+00:00
[2024-03-30 11:51:14,739] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:51:14,740] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-04.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-04.parquet']
[2024-03-30 11:51:14,761] {subprocess.py:85} INFO - Output:
[2024-03-30 11:51:19,023] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:51:19,084] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220402T060000, start_date=20240330T115114, end_date=20240330T115119
[2024-03-30 11:51:19,164] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:51:19,575] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-04-28 09:15:33,013] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:33,050] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:33,051] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:33,051] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-28 09:15:33,052] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:33,088] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-04-02 06:00:00+00:00
[2024-04-28 09:15:33,102] {standard_task_runner.py:52} INFO - Started process 1441 to run task
[2024-04-28 09:15:33,119] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-04-02T06:00:00+00:00', '--job-id', '3004', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp3qp2pgnw', '--error-file', '/tmp/tmpvvgfwpfj']
[2024-04-28 09:15:33,136] {standard_task_runner.py:77} INFO - Job 3004: Subtask download_dataset_task
[2024-04-28 09:15:33,322] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [running]> on host 6c6a4ca9ff8e
[2024-04-28 09:15:33,405] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-28 09:15:33,467] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-04-02T06:00:00+00:00
[2024-04-28 09:15:33,469] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-28 09:15:33,470] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-04.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-04.parquet']
[2024-04-28 09:15:33,490] {subprocess.py:85} INFO - Output:
[2024-04-28 09:15:38,479] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-28 09:15:38,833] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220402T060000, start_date=20240428T091533, end_date=20240428T091538
[2024-04-28 09:15:39,389] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-28 09:15:39,464] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:13:48,860] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-04-30 02:13:48,896] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-04-30 02:13:48,897] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:13:48,898] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-30 02:13:48,898] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:13:48,918] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-04-02 06:00:00+00:00
[2024-04-30 02:13:48,933] {standard_task_runner.py:52} INFO - Started process 361 to run task
[2024-04-30 02:13:48,955] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-04-02T06:00:00+00:00', '--job-id', '3038', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp2u7ktj9s', '--error-file', '/tmp/tmpoq8ygzws']
[2024-04-30 02:13:48,974] {standard_task_runner.py:77} INFO - Job 3038: Subtask download_dataset_task
[2024-04-30 02:13:49,077] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [running]> on host a1ae6a0259c5
[2024-04-30 02:13:49,133] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:13:49,167] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-04-02T06:00:00+00:00
[2024-04-30 02:13:49,168] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 02:13:49,169] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-04.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-04.parquet']
[2024-04-30 02:13:49,186] {subprocess.py:85} INFO - Output:
[2024-04-30 02:13:53,913] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 02:13:54,193] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220402T060000, start_date=20240430T021348, end_date=20240430T021354
[2024-04-30 02:13:54,288] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 02:13:54,447] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:58:14,779] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:14,839] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:14,839] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:14,840] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 02:58:14,840] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:14,883] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-04-02 06:00:00+00:00
[2024-04-30 02:58:14,916] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-04-02T06:00:00+00:00', '--job-id', '3106', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp_ccnf0vc', '--error-file', '/tmp/tmpoj01gmb1']
[2024-04-30 02:58:14,927] {standard_task_runner.py:77} INFO - Job 3106: Subtask download_dataset_task
[2024-04-30 02:58:14,897] {standard_task_runner.py:52} INFO - Started process 426 to run task
[2024-04-30 02:58:15,194] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 02:58:15,356] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:58:15,432] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-04-02T06:00:00+00:00
[2024-04-30 02:58:15,438] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 02:58:15,440] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-04.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-04.parquet']
[2024-04-30 02:58:15,499] {subprocess.py:85} INFO - Output:
[2024-04-30 02:58:19,878] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 02:58:20,195] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220402T060000, start_date=20240430T025814, end_date=20240430T025820
[2024-04-30 02:58:20,306] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 02:58:20,622] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:01:35,605] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:35,618] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:35,618] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:35,618] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:01:35,618] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:35,630] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-04-02 06:00:00+00:00
[2024-04-30 03:01:35,638] {standard_task_runner.py:52} INFO - Started process 798 to run task
[2024-04-30 03:01:35,645] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-04-02T06:00:00+00:00', '--job-id', '3169', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpe5n4k0s0', '--error-file', '/tmp/tmp3i9zk0v_']
[2024-04-30 03:01:35,652] {standard_task_runner.py:77} INFO - Job 3169: Subtask download_dataset_task
[2024-04-30 03:01:35,742] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:01:35,797] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:01:35,826] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-04-02T06:00:00+00:00
[2024-04-30 03:01:35,827] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 03:01:35,828] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-04.parquet > /opt/***/cleaned_data/yellowtaxi_tripdata_2022-04.parquet']
[2024-04-30 03:01:35,842] {subprocess.py:85} INFO - Output:
[2024-04-30 03:01:40,346] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 03:01:40,585] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220402T060000, start_date=20240430T030135, end_date=20240430T030140
[2024-04-30 03:01:40,752] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:01:40,845] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:30:04,960] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-04-30 04:30:05,050] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [queued]>
[2024-04-30 04:30:05,053] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:30:05,053] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:30:05,053] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:30:05,393] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-04-02 06:00:00+00:00
[2024-04-30 04:30:05,413] {standard_task_runner.py:52} INFO - Started process 5223 to run task
[2024-04-30 04:30:05,441] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-04-02T06:00:00+00:00', '--job-id', '3248', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpi09h35ft', '--error-file', '/tmp/tmpdtq369w5']
[2024-04-30 04:30:05,460] {standard_task_runner.py:77} INFO - Job 3248: Subtask download_dataset_task
[2024-04-30 04:30:05,726] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-04-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:30:05,985] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:30:06,076] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-04-02T06:00:00+00:00
[2024-04-30 04:30:06,078] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 04:30:06,088] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-04.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-04.parquet']
[2024-04-30 04:30:06,198] {subprocess.py:85} INFO - Output:
[2024-04-30 04:30:11,142] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 04:30:11,408] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220402T060000, start_date=20240430T043004, end_date=20240430T043011
[2024-04-30 04:30:11,812] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 04:30:12,187] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
