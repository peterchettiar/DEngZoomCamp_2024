[2024-03-29 08:27:22,664] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [queued]>
[2024-03-29 08:27:22,707] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [queued]>
[2024-03-29 08:27:22,708] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:27:22,709] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:27:22,709] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:27:22,757] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-07-02 06:00:00+00:00
[2024-03-29 08:27:22,775] {standard_task_runner.py:52} INFO - Started process 1572 to run task
[2024-03-29 08:27:22,799] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-07-02T06:00:00+00:00', '--job-id', '1779', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp885z010k', '--error-file', '/tmp/tmpp29l_6p6']
[2024-03-29 08:27:22,806] {standard_task_runner.py:77} INFO - Job 1779: Subtask download_dataset_task
[2024-03-29 08:27:22,990] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:27:23,129] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:27:23,257] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-07-02T06:00:00+00:00
[2024-03-29 08:27:23,264] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:27:23,266] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-07.parquet > /opt/***/yellowtaxi_tripdata_2023-07.parquet']
[2024-03-29 08:27:23,360] {subprocess.py:85} INFO - Output:
[2024-03-29 08:27:29,695] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:27:29,802] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230702T060000, start_date=20240329T082722, end_date=20240329T082729
[2024-03-29 08:27:29,917] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:27:30,408] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:53:26,312] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [queued]>
[2024-03-30 03:53:26,431] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [queued]>
[2024-03-30 03:53:26,431] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:53:26,431] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:53:26,431] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:53:26,514] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-07-02 06:00:00+00:00
[2024-03-30 03:53:26,583] {standard_task_runner.py:52} INFO - Started process 2110 to run task
[2024-03-30 03:53:26,610] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-07-02T06:00:00+00:00', '--job-id', '1991', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp_u28iqej', '--error-file', '/tmp/tmppr6z9bek']
[2024-03-30 03:53:26,670] {standard_task_runner.py:77} INFO - Job 1991: Subtask download_dataset_task
[2024-03-30 03:53:26,863] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:53:26,963] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:53:27,095] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-07-02T06:00:00+00:00
[2024-03-30 03:53:27,103] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:53:27,105] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-07.parquet > /opt/***/yellowtaxi_tripdata_2023-07.parquet']
[2024-03-30 03:53:27,143] {subprocess.py:85} INFO - Output:
[2024-03-30 03:53:33,705] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:53:33,773] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230702T060000, start_date=20240330T035326, end_date=20240330T035333
[2024-03-30 03:53:33,855] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:53:34,009] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:19:03,367] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:19:03,421] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:19:03,423] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:19:03,423] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:19:03,425] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:19:03,514] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-07-02 06:00:00+00:00
[2024-03-30 04:19:03,667] {standard_task_runner.py:52} INFO - Started process 3787 to run task
[2024-03-30 04:19:03,710] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-07-02T06:00:00+00:00', '--job-id', '2136', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpfqt4_ry0', '--error-file', '/tmp/tmpb_ql048d']
[2024-03-30 04:19:03,758] {standard_task_runner.py:77} INFO - Job 2136: Subtask download_dataset_task
[2024-03-30 04:19:04,386] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:19:05,524] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:19:05,683] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-07-02T06:00:00+00:00
[2024-03-30 04:19:05,686] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:19:05,691] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-07.parquet > /opt/***/yellowtaxi_tripdata_2023-07.parquet']
[2024-03-30 04:19:05,766] {subprocess.py:85} INFO - Output:
[2024-03-30 04:19:11,984] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:19:12,085] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230702T060000, start_date=20240330T041903, end_date=20240330T041912
[2024-03-30 04:19:12,177] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:19:12,253] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:25:34,072] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:25:34,166] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:25:34,167] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:25:34,168] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:25:34,169] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:25:34,261] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-07-02 06:00:00+00:00
[2024-03-30 04:25:34,310] {standard_task_runner.py:52} INFO - Started process 4399 to run task
[2024-03-30 04:25:34,369] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-07-02T06:00:00+00:00', '--job-id', '2215', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp9g47vl99', '--error-file', '/tmp/tmp92qbnrnf']
[2024-03-30 04:25:34,409] {standard_task_runner.py:77} INFO - Job 2215: Subtask download_dataset_task
[2024-03-30 04:25:34,699] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:25:34,811] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:25:34,863] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-07-02T06:00:00+00:00
[2024-03-30 04:25:34,865] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:25:34,866] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-07.parquet > /opt/***/yellowtaxi_tripdata_2023-07.parquet']
[2024-03-30 04:25:34,925] {subprocess.py:85} INFO - Output:
[2024-03-30 04:25:41,091] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:25:41,196] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230702T060000, start_date=20240330T042534, end_date=20240330T042541
[2024-03-30 04:25:41,411] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:25:41,978] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:44:52,709] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:44:53,169] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:44:53,247] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:44:53,249] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:44:53,275] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:44:55,164] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-07-02 06:00:00+00:00
[2024-03-30 04:44:55,380] {standard_task_runner.py:52} INFO - Started process 5779 to run task
[2024-03-30 04:44:55,516] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-07-02T06:00:00+00:00', '--job-id', '2358', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpvnlfgekr', '--error-file', '/tmp/tmpfo0rsb5l']
[2024-03-30 04:44:55,601] {standard_task_runner.py:77} INFO - Job 2358: Subtask download_dataset_task
[2024-03-30 04:44:56,380] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:44:56,677] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:44:56,773] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-07-02T06:00:00+00:00
[2024-03-30 04:44:56,781] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:44:56,791] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-07.parquet > /opt/***/yellowtaxi_tripdata_2023-07.parquet']
[2024-03-30 04:44:56,882] {subprocess.py:85} INFO - Output:
[2024-03-30 04:45:02,845] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:45:02,947] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230702T060000, start_date=20240330T044452, end_date=20240330T044502
[2024-03-30 04:45:03,066] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:45:03,183] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 05:00:40,304] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:40,334] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:40,334] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:40,335] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 05:00:40,335] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:40,385] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-07-02 06:00:00+00:00
[2024-03-30 05:00:40,414] {standard_task_runner.py:52} INFO - Started process 6954 to run task
[2024-03-30 05:00:40,439] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-07-02T06:00:00+00:00', '--job-id', '2490', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmptktubt77', '--error-file', '/tmp/tmpy6vs1jh0']
[2024-03-30 05:00:40,444] {standard_task_runner.py:77} INFO - Job 2490: Subtask download_dataset_task
[2024-03-30 05:00:40,587] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 05:00:40,721] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 05:00:40,770] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-07-02T06:00:00+00:00
[2024-03-30 05:00:40,772] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 05:00:40,777] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-07.parquet > /opt/***/yellowtaxi_tripdata_2023-07.parquet']
[2024-03-30 05:00:40,799] {subprocess.py:85} INFO - Output:
[2024-03-30 05:00:46,874] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 05:00:46,923] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230702T060000, start_date=20240330T050040, end_date=20240330T050046
[2024-03-30 05:00:46,993] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 05:00:47,051] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:02:23,202] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [queued]>
[2024-03-30 09:02:23,284] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [queued]>
[2024-03-30 09:02:23,284] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:02:23,284] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:02:23,284] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:02:23,354] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-07-02 06:00:00+00:00
[2024-03-30 09:02:23,376] {standard_task_runner.py:52} INFO - Started process 18376 to run task
[2024-03-30 09:02:23,397] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-07-02T06:00:00+00:00', '--job-id', '2577', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp6i9p0qgp', '--error-file', '/tmp/tmpg72imtlz']
[2024-03-30 09:02:23,411] {standard_task_runner.py:77} INFO - Job 2577: Subtask download_dataset_task
[2024-03-30 09:02:23,713] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:02:23,977] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:02:24,104] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-07-02T06:00:00+00:00
[2024-03-30 09:02:24,109] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 09:02:24,111] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-07.parquet > /opt/***/yellowtaxi_tripdata_2023-07.parquet']
[2024-03-30 09:02:24,168] {subprocess.py:85} INFO - Output:
[2024-03-30 09:02:30,924] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 09:02:31,755] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230702T060000, start_date=20240330T090223, end_date=20240330T090231
[2024-03-30 09:02:32,586] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:02:33,485] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:57:20,978] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [queued]>
[2024-03-30 11:57:21,001] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [queued]>
[2024-03-30 11:57:21,002] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:57:21,002] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:57:21,002] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:57:21,033] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-07-02 06:00:00+00:00
[2024-03-30 11:57:21,045] {standard_task_runner.py:52} INFO - Started process 28555 to run task
[2024-03-30 11:57:21,056] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-07-02T06:00:00+00:00', '--job-id', '2901', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpet02350e', '--error-file', '/tmp/tmp5oi1irki']
[2024-03-30 11:57:21,092] {standard_task_runner.py:77} INFO - Job 2901: Subtask download_dataset_task
[2024-03-30 11:57:21,193] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:57:21,309] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:57:21,369] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-07-02T06:00:00+00:00
[2024-03-30 11:57:21,372] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:57:21,373] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-07.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2023-07.parquet']
[2024-03-30 11:57:21,413] {subprocess.py:85} INFO - Output:
[2024-03-30 11:57:27,370] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:57:27,450] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230702T060000, start_date=20240330T115720, end_date=20240330T115727
[2024-03-30 11:57:27,519] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:57:27,601] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:02:15,837] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [queued]>
[2024-04-30 03:02:15,908] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [queued]>
[2024-04-30 03:02:15,912] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:02:15,914] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:02:15,915] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:02:16,026] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-07-02 06:00:00+00:00
[2024-04-30 03:02:16,126] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-07-02T06:00:00+00:00', '--job-id', '3205', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp0fbmzh4k', '--error-file', '/tmp/tmpuhh4orid']
[2024-04-30 03:02:16,142] {standard_task_runner.py:77} INFO - Job 3205: Subtask download_dataset_task
[2024-04-30 03:02:16,080] {standard_task_runner.py:52} INFO - Started process 996 to run task
[2024-04-30 03:02:16,516] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:02:16,847] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:02:16,978] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-07-02T06:00:00+00:00
[2024-04-30 03:02:16,981] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 03:02:16,982] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-07.parquet > /opt/***/cleaned_data/yellowtaxi_tripdata_2023-07.parquet']
[2024-04-30 03:02:17,034] {subprocess.py:85} INFO - Output:
[2024-04-30 03:02:21,665] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 03:02:21,706] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230702T060000, start_date=20240430T030215, end_date=20240430T030221
[2024-04-30 03:02:21,736] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:02:21,786] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:35:04,491] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [queued]>
[2024-04-30 04:35:04,505] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [queued]>
[2024-04-30 04:35:04,506] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:35:04,506] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:35:04,506] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:35:04,520] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-07-02 06:00:00+00:00
[2024-04-30 04:35:04,528] {standard_task_runner.py:52} INFO - Started process 5793 to run task
[2024-04-30 04:35:04,534] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-07-02T06:00:00+00:00', '--job-id', '3310', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp5vuuajb3', '--error-file', '/tmp/tmp7ffhat32']
[2024-04-30 04:35:04,540] {standard_task_runner.py:77} INFO - Job 3310: Subtask download_dataset_task
[2024-04-30 04:35:04,628] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-07-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:35:04,692] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:35:04,725] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-07-02T06:00:00+00:00
[2024-04-30 04:35:04,727] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 04:35:04,728] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-07.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2023-07.parquet']
[2024-04-30 04:35:04,749] {subprocess.py:85} INFO - Output:
[2024-04-30 04:35:09,012] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 04:35:09,057] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230702T060000, start_date=20240430T043504, end_date=20240430T043509
[2024-04-30 04:35:09,100] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 04:35:09,147] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
