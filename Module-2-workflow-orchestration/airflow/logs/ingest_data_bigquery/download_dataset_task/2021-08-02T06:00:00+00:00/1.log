[2024-03-29 07:24:28,539] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:28,558] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:28,559] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:28,559] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:24:28,559] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:28,583] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-08-02 06:00:00+00:00
[2024-03-29 07:24:28,598] {standard_task_runner.py:52} INFO - Started process 513 to run task
[2024-03-29 07:24:28,645] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-08-02T06:00:00+00:00', '--job-id', '1446', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp6a2ij3ck', '--error-file', '/tmp/tmp46m71reh']
[2024-03-29 07:24:28,670] {standard_task_runner.py:77} INFO - Job 1446: Subtask download_dataset_task
[2024-03-29 07:24:28,993] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:24:29,330] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:24:29,483] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T06:00:00+00:00
[2024-03-29 07:24:29,502] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:24:29,509] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet > /opt/***/yellowtaxi_tripdata_2021-08.parquet']
[2024-03-29 07:24:29,681] {subprocess.py:85} INFO - Output:
[2024-03-29 07:24:35,814] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:24:35,996] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210802T060000, start_date=20240329T072428, end_date=20240329T072435
[2024-03-29 07:24:36,085] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:24:36,373] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:30:46,382] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-29 07:30:46,444] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-29 07:30:46,444] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:30:46,444] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:30:46,444] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:30:46,502] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-08-02 06:00:00+00:00
[2024-03-29 07:30:46,523] {standard_task_runner.py:52} INFO - Started process 1005 to run task
[2024-03-29 07:30:46,561] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-08-02T06:00:00+00:00', '--job-id', '1506', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpkpd_e5so', '--error-file', '/tmp/tmpg3y9waz8']
[2024-03-29 07:30:46,606] {standard_task_runner.py:77} INFO - Job 1506: Subtask download_dataset_task
[2024-03-29 07:30:46,810] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:30:46,978] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:30:47,048] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T06:00:00+00:00
[2024-03-29 07:30:47,049] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:30:47,050] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet > /opt/***/yellowtaxi_tripdata_2021-08.parquet']
[2024-03-29 07:30:47,141] {subprocess.py:85} INFO - Output:
[2024-03-29 07:30:52,759] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:30:53,047] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210802T060000, start_date=20240329T073046, end_date=20240329T073053
[2024-03-29 07:30:53,172] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:30:53,461] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:37:30,450] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:30,546] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:30,548] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:30,548] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:37:30,548] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:30,595] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-08-02 06:00:00+00:00
[2024-03-29 07:37:30,624] {standard_task_runner.py:52} INFO - Started process 1528 to run task
[2024-03-29 07:37:30,672] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-08-02T06:00:00+00:00', '--job-id', '1568', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpnirknds1', '--error-file', '/tmp/tmprbw3t02y']
[2024-03-29 07:37:30,706] {standard_task_runner.py:77} INFO - Job 1568: Subtask download_dataset_task
[2024-03-29 07:37:31,123] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:37:31,315] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:37:31,425] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T06:00:00+00:00
[2024-03-29 07:37:31,438] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:37:31,440] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet > /opt/***/yellowtaxi_tripdata_2021-08.parquet']
[2024-03-29 07:37:31,504] {subprocess.py:85} INFO - Output:
[2024-03-29 07:37:37,404] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:37:37,530] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210802T060000, start_date=20240329T073730, end_date=20240329T073737
[2024-03-29 07:37:37,641] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:37:38,225] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:08:29,363] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:29,397] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:29,397] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:29,397] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:08:29,397] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:29,438] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-08-02 06:00:00+00:00
[2024-03-29 08:08:29,453] {standard_task_runner.py:52} INFO - Started process 208 to run task
[2024-03-29 08:08:29,478] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-08-02T06:00:00+00:00', '--job-id', '1631', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp4urezxa8', '--error-file', '/tmp/tmply0xk7l6']
[2024-03-29 08:08:29,498] {standard_task_runner.py:77} INFO - Job 1631: Subtask download_dataset_task
[2024-03-29 08:08:29,664] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:08:29,831] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:08:29,889] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T06:00:00+00:00
[2024-03-29 08:08:29,891] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:08:29,892] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet > /opt/***/yellowtaxi_tripdata_2021-08.parquet']
[2024-03-29 08:08:29,931] {subprocess.py:85} INFO - Output:
[2024-03-29 08:08:35,712] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:08:36,192] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210802T060000, start_date=20240329T080829, end_date=20240329T080836
[2024-03-29 08:08:36,443] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:08:36,641] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:10:56,500] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-29 08:10:56,623] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-29 08:10:56,624] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:10:56,624] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:10:56,625] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:10:56,713] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-08-02 06:00:00+00:00
[2024-03-29 08:10:56,729] {standard_task_runner.py:52} INFO - Started process 487 to run task
[2024-03-29 08:10:56,758] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-08-02T06:00:00+00:00', '--job-id', '1674', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp4vu0gd_k', '--error-file', '/tmp/tmpt_5r0g00']
[2024-03-29 08:10:56,788] {standard_task_runner.py:77} INFO - Job 1674: Subtask download_dataset_task
[2024-03-29 08:10:57,238] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:10:57,634] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:10:57,746] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T06:00:00+00:00
[2024-03-29 08:10:57,751] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:10:57,755] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet > /opt/***/yellowtaxi_tripdata_2021-08.parquet']
[2024-03-29 08:10:57,837] {subprocess.py:85} INFO - Output:
[2024-03-29 08:11:03,492] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:11:03,751] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210802T060000, start_date=20240329T081056, end_date=20240329T081103
[2024-03-29 08:11:03,939] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:11:04,154] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:30:05,490] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:05,552] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:05,553] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:05,553] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:30:05,554] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:05,586] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-08-02 06:00:00+00:00
[2024-03-30 03:30:05,595] {standard_task_runner.py:52} INFO - Started process 454 to run task
[2024-03-30 03:30:05,630] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-08-02T06:00:00+00:00', '--job-id', '1823', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp2zln7k8z', '--error-file', '/tmp/tmp8j3yiczr']
[2024-03-30 03:30:05,693] {standard_task_runner.py:77} INFO - Job 1823: Subtask download_dataset_task
[2024-03-30 03:30:05,998] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:30:06,251] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:30:06,299] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T06:00:00+00:00
[2024-03-30 03:30:06,301] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:30:06,301] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet > /opt/***/yellowtaxi_tripdata_2021-08.parquet']
[2024-03-30 03:30:06,323] {subprocess.py:85} INFO - Output:
[2024-03-30 03:30:12,523] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:30:12,665] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210802T060000, start_date=20240330T033005, end_date=20240330T033012
[2024-03-30 03:30:12,763] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:30:13,108] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:41:57,476] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-30 03:41:57,544] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-30 03:41:57,544] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:41:57,544] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:41:57,544] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:41:57,618] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-08-02 06:00:00+00:00
[2024-03-30 03:41:57,672] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-08-02T06:00:00+00:00', '--job-id', '1899', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpxa0dob3d', '--error-file', '/tmp/tmpw27w8alw']
[2024-03-30 03:41:57,691] {standard_task_runner.py:77} INFO - Job 1899: Subtask download_dataset_task
[2024-03-30 03:41:57,667] {standard_task_runner.py:52} INFO - Started process 1277 to run task
[2024-03-30 03:41:57,921] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:41:58,077] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:41:58,153] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T06:00:00+00:00
[2024-03-30 03:41:58,155] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:41:58,156] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet > /opt/***/yellowtaxi_tripdata_2021-08.parquet']
[2024-03-30 03:41:58,233] {subprocess.py:85} INFO - Output:
[2024-03-30 03:42:03,861] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:42:04,169] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210802T060000, start_date=20240330T034157, end_date=20240330T034204
[2024-03-30 03:42:04,312] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:42:04,452] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:18:08,587] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:08,768] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:08,769] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:08,769] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:18:08,769] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:08,912] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-08-02 06:00:00+00:00
[2024-03-30 04:18:09,010] {standard_task_runner.py:52} INFO - Started process 3532 to run task
[2024-03-30 04:18:09,057] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-08-02T06:00:00+00:00', '--job-id', '2080', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpohsdyqwf', '--error-file', '/tmp/tmptgkahieb']
[2024-03-30 04:18:09,092] {standard_task_runner.py:77} INFO - Job 2080: Subtask download_dataset_task
[2024-03-30 04:18:09,638] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:18:09,941] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:18:10,067] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T06:00:00+00:00
[2024-03-30 04:18:10,076] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:18:10,084] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet > /opt/***/yellowtaxi_tripdata_2021-08.parquet']
[2024-03-30 04:18:10,248] {subprocess.py:85} INFO - Output:
[2024-03-30 04:18:15,873] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:18:16,211] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210802T060000, start_date=20240330T041808, end_date=20240330T041816
[2024-03-30 04:18:16,332] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:18:16,700] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:24:42,871] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-30 04:24:42,920] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-30 04:24:42,920] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:24:42,920] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:24:42,921] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:24:42,964] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-08-02 06:00:00+00:00
[2024-03-30 04:24:42,993] {standard_task_runner.py:52} INFO - Started process 4142 to run task
[2024-03-30 04:24:43,020] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-08-02T06:00:00+00:00', '--job-id', '2159', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpckc0bo9y', '--error-file', '/tmp/tmp8es6fqfy']
[2024-03-30 04:24:43,059] {standard_task_runner.py:77} INFO - Job 2159: Subtask download_dataset_task
[2024-03-30 04:24:43,439] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:24:43,675] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:24:43,754] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T06:00:00+00:00
[2024-03-30 04:24:43,756] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:24:43,757] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet > /opt/***/yellowtaxi_tripdata_2021-08.parquet']
[2024-03-30 04:24:43,888] {subprocess.py:85} INFO - Output:
[2024-03-30 04:24:49,461] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:24:49,768] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210802T060000, start_date=20240330T042442, end_date=20240330T042449
[2024-03-30 04:24:49,957] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:24:50,144] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:38:48,047] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-30 04:38:48,226] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-30 04:38:48,226] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:38:48,226] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:38:48,226] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:38:48,483] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-08-02 06:00:00+00:00
[2024-03-30 04:38:48,606] {standard_task_runner.py:52} INFO - Started process 5239 to run task
[2024-03-30 04:38:48,896] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-08-02T06:00:00+00:00', '--job-id', '2281', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpheq02qgl', '--error-file', '/tmp/tmpxb3n5q82']
[2024-03-30 04:38:49,178] {standard_task_runner.py:77} INFO - Job 2281: Subtask download_dataset_task
[2024-03-30 04:38:49,908] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:38:51,050] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:38:51,192] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T06:00:00+00:00
[2024-03-30 04:38:51,199] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:38:51,204] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet > /opt/***/yellowtaxi_tripdata_2021-08.parquet']
[2024-03-30 04:38:51,325] {subprocess.py:85} INFO - Output:
[2024-03-30 04:38:57,339] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:38:57,545] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210802T060000, start_date=20240330T043848, end_date=20240330T043857
[2024-03-30 04:38:57,627] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:38:58,223] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:59:26,935] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:27,073] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:27,073] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:27,076] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:59:27,076] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:27,190] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-08-02 06:00:00+00:00
[2024-03-30 04:59:27,211] {standard_task_runner.py:52} INFO - Started process 6628 to run task
[2024-03-30 04:59:27,238] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-08-02T06:00:00+00:00', '--job-id', '2410', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp55y85st4', '--error-file', '/tmp/tmp00oqzbx2']
[2024-03-30 04:59:27,253] {standard_task_runner.py:77} INFO - Job 2410: Subtask download_dataset_task
[2024-03-30 04:59:27,493] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:59:27,650] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:59:27,764] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T06:00:00+00:00
[2024-03-30 04:59:27,766] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:59:27,768] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet > /opt/***/yellowtaxi_tripdata_2021-08.parquet']
[2024-03-30 04:59:27,850] {subprocess.py:85} INFO - Output:
[2024-03-30 04:59:33,577] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:59:34,033] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210802T060000, start_date=20240330T045926, end_date=20240330T045934
[2024-03-30 04:59:34,160] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:59:34,431] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:01:30,254] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:30,303] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:30,303] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:30,303] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:01:30,303] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:30,336] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-08-02 06:00:00+00:00
[2024-03-30 09:01:30,375] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-08-02T06:00:00+00:00', '--job-id', '2521', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp7ucpcfq3', '--error-file', '/tmp/tmp2_9mhcmz']
[2024-03-30 09:01:30,386] {standard_task_runner.py:77} INFO - Job 2521: Subtask download_dataset_task
[2024-03-30 09:01:30,352] {standard_task_runner.py:52} INFO - Started process 18123 to run task
[2024-03-30 09:01:30,595] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:01:30,738] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:01:30,799] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T06:00:00+00:00
[2024-03-30 09:01:30,801] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 09:01:30,802] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet > /opt/***/yellowtaxi_tripdata_2021-08.parquet']
[2024-03-30 09:01:30,947] {subprocess.py:85} INFO - Output:
[2024-03-30 09:01:36,567] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 09:01:36,842] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210802T060000, start_date=20240330T090130, end_date=20240330T090136
[2024-03-30 09:01:37,139] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:01:37,345] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 10:50:02,847] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-30 10:50:02,944] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-30 10:50:02,946] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:50:02,946] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 10:50:02,946] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:50:03,065] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-08-02 06:00:00+00:00
[2024-03-30 10:50:03,153] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-08-02T06:00:00+00:00', '--job-id', '2635', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpwxl6jhmy', '--error-file', '/tmp/tmpqog3x61r']
[2024-03-30 10:50:03,136] {standard_task_runner.py:52} INFO - Started process 23492 to run task
[2024-03-30 10:50:03,183] {standard_task_runner.py:77} INFO - Job 2635: Subtask download_dataset_task
[2024-03-30 10:50:03,617] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 10:50:03,827] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 10:50:03,895] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T06:00:00+00:00
[2024-03-30 10:50:03,897] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 10:50:03,911] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet > /opt/***raw_data/yellowtaxi_tripdata_2021-08.parquet']
[2024-03-30 10:50:03,959] {subprocess.py:85} INFO - Output:
[2024-03-30 10:50:03,976] {subprocess.py:89} INFO - bash: /opt/***raw_data/yellowtaxi_tripdata_2021-08.parquet: No such file or directory
[2024-03-30 10:50:03,978] {subprocess.py:93} INFO - Command exited with return code 1
[2024-03-30 10:50:04,083] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:50:04,112] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210802T060000, start_date=20240330T105002, end_date=20240330T105004
[2024-03-30 10:50:04,205] {standard_task_runner.py:92} ERROR - Failed to execute job 2635 for task download_dataset_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:50:04,279] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 10:50:04,443] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 10:54:54,500] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-30 10:54:54,613] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-30 10:54:54,613] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:54:54,613] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 10:54:54,613] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:54:54,687] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-08-02 06:00:00+00:00
[2024-03-30 10:54:54,721] {standard_task_runner.py:52} INFO - Started process 23794 to run task
[2024-03-30 10:54:54,756] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-08-02T06:00:00+00:00', '--job-id', '2650', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpu5ts2t4c', '--error-file', '/tmp/tmph0i3h9vs']
[2024-03-30 10:54:54,761] {standard_task_runner.py:77} INFO - Job 2650: Subtask download_dataset_task
[2024-03-30 10:54:54,936] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 10:54:55,107] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 10:54:55,158] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T06:00:00+00:00
[2024-03-30 10:54:55,160] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 10:54:55,161] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet > /opt/***raw_data/yellowtaxi_tripdata_2021-08.parquet']
[2024-03-30 10:54:55,213] {subprocess.py:85} INFO - Output:
[2024-03-30 10:54:55,264] {subprocess.py:89} INFO - bash: /opt/***raw_data/yellowtaxi_tripdata_2021-08.parquet: No such file or directory
[2024-03-30 10:54:55,266] {subprocess.py:93} INFO - Command exited with return code 1
[2024-03-30 10:54:55,449] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:54:55,469] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210802T060000, start_date=20240330T105454, end_date=20240330T105455
[2024-03-30 10:54:55,576] {standard_task_runner.py:92} ERROR - Failed to execute job 2650 for task download_dataset_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:54:55,645] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 10:54:55,816] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:03:57,864] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-30 11:03:57,940] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-30 11:03:57,940] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:03:57,940] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:03:57,940] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:03:57,976] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-08-02 06:00:00+00:00
[2024-03-30 11:03:58,025] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-08-02T06:00:00+00:00', '--job-id', '2680', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpgiat0q5m', '--error-file', '/tmp/tmps061qh9y']
[2024-03-30 11:03:58,044] {standard_task_runner.py:77} INFO - Job 2680: Subtask download_dataset_task
[2024-03-30 11:03:57,992] {standard_task_runner.py:52} INFO - Started process 24347 to run task
[2024-03-30 11:03:58,698] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:03:58,932] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:03:59,023] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T06:00:00+00:00
[2024-03-30 11:03:59,025] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:03:59,041] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-08.parquet']
[2024-03-30 11:03:59,200] {subprocess.py:85} INFO - Output:
[2024-03-30 11:04:04,940] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:04:05,045] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210802T060000, start_date=20240330T110357, end_date=20240330T110405
[2024-03-30 11:04:05,304] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:04:05,511] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:15:07,997] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-30 11:15:08,128] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-30 11:15:08,128] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:15:08,128] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:15:08,128] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:15:08,183] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-08-02 06:00:00+00:00
[2024-03-30 11:15:08,214] {standard_task_runner.py:52} INFO - Started process 25255 to run task
[2024-03-30 11:15:08,261] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-08-02T06:00:00+00:00', '--job-id', '2725', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpmq0wvr8c', '--error-file', '/tmp/tmpja_5v_ww']
[2024-03-30 11:15:08,303] {standard_task_runner.py:77} INFO - Job 2725: Subtask download_dataset_task
[2024-03-30 11:15:08,625] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:15:08,871] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:15:09,001] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T06:00:00+00:00
[2024-03-30 11:15:09,005] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:15:09,009] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-08.parquet']
[2024-03-30 11:15:09,083] {subprocess.py:85} INFO - Output:
[2024-03-30 11:15:14,768] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:15:15,079] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210802T060000, start_date=20240330T111508, end_date=20240330T111515
[2024-03-30 11:15:15,168] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:15:15,270] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:33:51,823] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-30 11:33:51,923] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-03-30 11:33:51,923] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:33:51,924] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:33:51,924] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:33:51,967] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-08-02 06:00:00+00:00
[2024-03-30 11:33:52,031] {standard_task_runner.py:52} INFO - Started process 26834 to run task
[2024-03-30 11:33:52,023] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-08-02T06:00:00+00:00', '--job-id', '2801', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp98sbh6ws', '--error-file', '/tmp/tmpiy9p1m1z']
[2024-03-30 11:33:52,075] {standard_task_runner.py:77} INFO - Job 2801: Subtask download_dataset_task
[2024-03-30 11:33:52,263] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:33:52,388] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:33:52,458] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T06:00:00+00:00
[2024-03-30 11:33:52,460] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:33:52,461] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-08.parquet']
[2024-03-30 11:33:52,554] {subprocess.py:85} INFO - Output:
[2024-03-30 11:33:58,537] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:33:58,632] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210802T060000, start_date=20240330T113351, end_date=20240330T113358
[2024-03-30 11:33:58,720] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:33:58,842] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-28 09:15:29,749] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:29,860] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:29,861] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:29,865] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-28 09:15:29,865] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:30,011] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-08-02 06:00:00+00:00
[2024-04-28 09:15:30,085] {standard_task_runner.py:52} INFO - Started process 1379 to run task
[2024-04-28 09:15:30,119] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-08-02T06:00:00+00:00', '--job-id', '2993', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpc4k9jviw', '--error-file', '/tmp/tmpt50vcxh4']
[2024-04-28 09:15:30,273] {standard_task_runner.py:77} INFO - Job 2993: Subtask download_dataset_task
[2024-04-28 09:15:30,568] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [running]> on host 6c6a4ca9ff8e
[2024-04-28 09:15:30,893] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-28 09:15:31,084] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T06:00:00+00:00
[2024-04-28 09:15:31,085] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-28 09:15:31,096] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-08.parquet']
[2024-04-28 09:15:31,266] {subprocess.py:85} INFO - Output:
[2024-04-28 09:15:35,459] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-28 09:15:35,881] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210802T060000, start_date=20240428T091529, end_date=20240428T091535
[2024-04-28 09:15:36,369] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-28 09:15:36,939] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:13:46,873] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-04-30 02:13:46,989] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-04-30 02:13:46,989] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:13:46,989] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-30 02:13:46,989] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:13:47,097] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-08-02 06:00:00+00:00
[2024-04-30 02:13:47,165] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-08-02T06:00:00+00:00', '--job-id', '3030', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp5x02uww9', '--error-file', '/tmp/tmp8__blw4q']
[2024-04-30 02:13:47,203] {standard_task_runner.py:77} INFO - Job 3030: Subtask download_dataset_task
[2024-04-30 02:13:47,141] {standard_task_runner.py:52} INFO - Started process 318 to run task
[2024-04-30 02:13:47,459] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [running]> on host a1ae6a0259c5
[2024-04-30 02:13:47,687] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:13:47,844] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T06:00:00+00:00
[2024-04-30 02:13:47,846] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 02:13:47,846] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-08.parquet']
[2024-04-30 02:13:48,019] {subprocess.py:85} INFO - Output:
[2024-04-30 02:13:52,510] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 02:13:52,763] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210802T060000, start_date=20240430T021346, end_date=20240430T021352
[2024-04-30 02:13:52,903] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 02:13:53,212] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:58:10,711] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:10,804] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:10,806] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:10,806] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 02:58:10,809] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:10,906] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-08-02 06:00:00+00:00
[2024-04-30 02:58:10,987] {standard_task_runner.py:52} INFO - Started process 364 to run task
[2024-04-30 02:58:11,059] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-08-02T06:00:00+00:00', '--job-id', '3091', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpr9fpos_n', '--error-file', '/tmp/tmpc_tl8714']
[2024-04-30 02:58:11,129] {standard_task_runner.py:77} INFO - Job 3091: Subtask download_dataset_task
[2024-04-30 02:58:11,664] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 02:58:11,829] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:58:11,885] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T06:00:00+00:00
[2024-04-30 02:58:11,887] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 02:58:11,888] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-08.parquet']
[2024-04-30 02:58:11,967] {subprocess.py:85} INFO - Output:
[2024-04-30 02:58:15,853] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 02:58:15,994] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210802T060000, start_date=20240430T025810, end_date=20240430T025815
[2024-04-30 02:58:16,163] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 02:58:16,282] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:01:04,624] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:04,678] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:04,678] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:04,679] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:01:04,679] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:04,727] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-08-02 06:00:00+00:00
[2024-04-30 03:01:04,784] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-08-02T06:00:00+00:00', '--job-id', '3131', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpgraaf7wx', '--error-file', '/tmp/tmpqs7wnrr3']
[2024-04-30 03:01:04,803] {standard_task_runner.py:77} INFO - Job 3131: Subtask download_dataset_task
[2024-04-30 03:01:04,763] {standard_task_runner.py:52} INFO - Started process 655 to run task
[2024-04-30 03:01:05,033] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:01:05,217] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:01:05,342] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T06:00:00+00:00
[2024-04-30 03:01:05,344] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 03:01:05,345] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet > /opt/***/cleaned_data/yellowtaxi_tripdata_2021-08.parquet']
[2024-04-30 03:01:05,413] {subprocess.py:85} INFO - Output:
[2024-04-30 03:01:09,411] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 03:01:09,514] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210802T060000, start_date=20240430T030104, end_date=20240430T030109
[2024-04-30 03:01:09,718] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:01:09,859] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:30:02,706] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-04-30 04:30:02,806] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [queued]>
[2024-04-30 04:30:02,812] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:30:02,818] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:30:02,818] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:30:02,906] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-08-02 06:00:00+00:00
[2024-04-30 04:30:02,968] {standard_task_runner.py:52} INFO - Started process 5203 to run task
[2024-04-30 04:30:03,034] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-08-02T06:00:00+00:00', '--job-id', '3245', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp5n0xwbjo', '--error-file', '/tmp/tmp8du3jbrq']
[2024-04-30 04:30:03,069] {standard_task_runner.py:77} INFO - Job 3245: Subtask download_dataset_task
[2024-04-30 04:30:03,341] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-08-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:30:03,628] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:30:03,726] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T06:00:00+00:00
[2024-04-30 04:30:03,729] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 04:30:03,734] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-08.parquet']
[2024-04-30 04:30:03,800] {subprocess.py:85} INFO - Output:
[2024-04-30 04:30:07,918] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 04:30:08,102] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210802T060000, start_date=20240430T043002, end_date=20240430T043008
[2024-04-30 04:30:08,333] {local_task_job.py:212} WARNING - State of this instance has been externally set to success. Terminating instance.
[2024-04-30 04:30:08,399] {process_utils.py:124} INFO - Sending Signals.SIGTERM to group 5203. PIDs of all processes in the group: [5203]
[2024-04-30 04:30:08,399] {process_utils.py:75} INFO - Sending the signal Signals.SIGTERM to group 5203
[2024-04-30 04:30:08,454] {process_utils.py:70} INFO - Process psutil.Process(pid=5203, status='terminated', exitcode=0, started='04:30:02') (5203) terminated with exit code 0
