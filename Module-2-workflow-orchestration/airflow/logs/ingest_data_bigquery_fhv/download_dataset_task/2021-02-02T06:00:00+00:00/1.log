[2024-05-18 12:24:02,965] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_fhv.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-05-18 12:24:02,978] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_fhv.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-05-18 12:24:02,978] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-05-18 12:24:02,978] {taskinstance.py:1239} INFO - Starting attempt 1 of 3
[2024-05-18 12:24:02,979] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-05-18 12:24:02,991] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-02-02 06:00:00+00:00
[2024-05-18 12:24:03,001] {standard_task_runner.py:52} INFO - Started process 5343 to run task
[2024-05-18 12:24:03,007] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery_fhv', 'download_dataset_task', 'scheduled__2021-02-02T06:00:00+00:00', '--job-id', '5057', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_fhv_dag .py', '--cfg-path', '/tmp/tmp_qbkwslb', '--error-file', '/tmp/tmp202bvcgt']
[2024-05-18 12:24:03,013] {standard_task_runner.py:77} INFO - Job 5057: Subtask download_dataset_task
[2024-05-18 12:24:03,089] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery_fhv.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [running]> on host 45b18388e83d
[2024-05-18 12:24:03,135] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-05-18 12:24:03,169] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery_fhv
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-02-02T06:00:00+00:00
[2024-05-18 12:24:03,172] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-05-18 12:24:03,174] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2021-02.csv.gz > /opt/***/raw_data/fhvtaxi_tripdata_2021-02.csv.gz && gunzip /opt/***/raw_data/fhvtaxi_tripdata_2021-02.csv.gz']
[2024-05-18 12:24:03,199] {subprocess.py:85} INFO - Output:
[2024-05-18 12:25:06,994] {subprocess.py:93} INFO - Command exited with return code 0
[2024-05-18 12:25:07,113] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery_fhv, task_id=download_dataset_task, execution_date=20210202T060000, start_date=20240518T122402, end_date=20240518T122507
[2024-05-18 12:25:07,162] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-05-18 12:25:07,202] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-05-18 12:50:09,208] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_fhv.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-05-18 12:50:09,227] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_fhv.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-05-18 12:50:09,228] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-05-18 12:50:09,228] {taskinstance.py:1239} INFO - Starting attempt 1 of 3
[2024-05-18 12:50:09,229] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-05-18 12:50:09,247] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-02-02 06:00:00+00:00
[2024-05-18 12:50:09,266] {standard_task_runner.py:52} INFO - Started process 7043 to run task
[2024-05-18 12:50:09,293] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery_fhv', 'download_dataset_task', 'scheduled__2021-02-02T06:00:00+00:00', '--job-id', '5168', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_fhv_dag .py', '--cfg-path', '/tmp/tmpl2redzed', '--error-file', '/tmp/tmpywf45yf7']
[2024-05-18 12:50:09,313] {standard_task_runner.py:77} INFO - Job 5168: Subtask download_dataset_task
[2024-05-18 12:50:09,407] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery_fhv.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [running]> on host 45b18388e83d
[2024-05-18 12:50:09,474] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-05-18 12:50:09,510] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery_fhv
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-02-02T06:00:00+00:00
[2024-05-18 12:50:09,511] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-05-18 12:50:09,512] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2021-02.csv.gz > /opt/***/raw_data/fhvtaxi_tripdata_2021-02.csv.gz && gunzip /opt/***/raw_data/fhvtaxi_tripdata_2021-02.csv.gz']
[2024-05-18 12:50:09,580] {subprocess.py:85} INFO - Output:
[2024-05-18 12:50:15,572] {subprocess.py:93} INFO - Command exited with return code 0
[2024-05-18 12:50:15,707] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery_fhv, task_id=download_dataset_task, execution_date=20210202T060000, start_date=20240518T125009, end_date=20240518T125015
[2024-05-18 12:50:15,889] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-05-18 12:50:16,548] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-05-18 13:04:48,559] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_fhv.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-05-18 13:04:48,749] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_fhv.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-05-18 13:04:48,755] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-05-18 13:04:48,759] {taskinstance.py:1239} INFO - Starting attempt 1 of 3
[2024-05-18 13:04:48,760] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-05-18 13:04:48,848] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-02-02 06:00:00+00:00
[2024-05-18 13:04:48,958] {standard_task_runner.py:52} INFO - Started process 8237 to run task
[2024-05-18 13:04:49,096] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery_fhv', 'download_dataset_task', 'scheduled__2021-02-02T06:00:00+00:00', '--job-id', '5280', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_fhv_dag .py', '--cfg-path', '/tmp/tmp0a4hkemy', '--error-file', '/tmp/tmp68bgjoij']
[2024-05-18 13:04:49,185] {standard_task_runner.py:77} INFO - Job 5280: Subtask download_dataset_task
[2024-05-18 13:04:50,192] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery_fhv.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [running]> on host 45b18388e83d
[2024-05-18 13:04:50,682] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-05-18 13:04:51,120] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery_fhv
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-02-02T06:00:00+00:00
[2024-05-18 13:04:51,153] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-05-18 13:04:51,200] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2021-02.csv.gz > /opt/***/raw_data/fhvtaxi_tripdata_2021-02.csv.gz && gunzip /opt/***/raw_data/fhvtaxi_tripdata_2021-02.csv.gz']
[2024-05-18 13:04:51,949] {subprocess.py:85} INFO - Output:
[2024-05-18 13:04:59,661] {subprocess.py:93} INFO - Command exited with return code 0
[2024-05-18 13:04:59,817] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery_fhv, task_id=download_dataset_task, execution_date=20210202T060000, start_date=20240518T130448, end_date=20240518T130459
[2024-05-18 13:05:00,022] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-05-18 13:05:00,168] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-05-18 13:15:01,583] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_fhv.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-05-18 13:15:01,705] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_fhv.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-05-18 13:15:01,707] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-05-18 13:15:01,735] {taskinstance.py:1239} INFO - Starting attempt 1 of 3
[2024-05-18 13:15:01,736] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-05-18 13:15:01,964] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-02-02 06:00:00+00:00
[2024-05-18 13:15:02,106] {standard_task_runner.py:52} INFO - Started process 9218 to run task
[2024-05-18 13:15:02,215] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery_fhv', 'download_dataset_task', 'scheduled__2021-02-02T06:00:00+00:00', '--job-id', '5378', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_fhv_dag .py', '--cfg-path', '/tmp/tmpvjt0fk1z', '--error-file', '/tmp/tmp6f_0ujtg']
[2024-05-18 13:15:02,291] {standard_task_runner.py:77} INFO - Job 5378: Subtask download_dataset_task
[2024-05-18 13:15:03,329] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery_fhv.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [running]> on host 45b18388e83d
[2024-05-18 13:15:03,779] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-05-18 13:15:03,987] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery_fhv
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-02-02T06:00:00+00:00
[2024-05-18 13:15:03,988] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-05-18 13:15:03,989] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2021-02.csv.gz > /opt/***/raw_data/fhvtaxi_tripdata_2021-02.csv.gz && gunzip /opt/***/raw_data/fhvtaxi_tripdata_2021-02.csv.gz']
[2024-05-18 13:15:04,264] {subprocess.py:85} INFO - Output:
[2024-05-18 13:15:08,309] {subprocess.py:93} INFO - Command exited with return code 0
[2024-05-18 13:15:08,604] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery_fhv, task_id=download_dataset_task, execution_date=20210202T060000, start_date=20240518T131501, end_date=20240518T131508
[2024-05-18 13:15:08,816] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-05-18 13:15:09,088] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
