[2024-05-18 13:54:47,391] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_fhvhv.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [queued]>
[2024-05-18 13:54:47,444] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_fhvhv.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [queued]>
[2024-05-18 13:54:47,447] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-05-18 13:54:47,447] {taskinstance.py:1239} INFO - Starting attempt 1 of 3
[2024-05-18 13:54:47,448] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-05-18 13:54:47,500] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2019-11-02 06:00:00+00:00
[2024-05-18 13:54:47,532] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery_fhvhv', 'download_dataset_task', 'scheduled__2019-11-02T06:00:00+00:00', '--job-id', '5421', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_fhvhv_dag.py', '--cfg-path', '/tmp/tmphiks1byf', '--error-file', '/tmp/tmpx6hxcrjh']
[2024-05-18 13:54:47,538] {standard_task_runner.py:77} INFO - Job 5421: Subtask download_dataset_task
[2024-05-18 13:54:47,520] {standard_task_runner.py:52} INFO - Started process 11308 to run task
[2024-05-18 13:54:47,873] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery_fhvhv.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [running]> on host 45b18388e83d
[2024-05-18 13:54:48,166] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-05-18 13:54:48,350] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery_fhvhv
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2019-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-11-02T06:00:00+00:00
[2024-05-18 13:54:48,352] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-05-18 13:54:48,354] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2019-11.parquet > /opt/***/raw_data/fhvhvtaxi_tripdata_2019-11.parquet']
[2024-05-18 13:54:48,480] {subprocess.py:85} INFO - Output:
[2024-05-18 13:55:27,361] {subprocess.py:93} INFO - Command exited with return code 0
[2024-05-18 13:55:28,185] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery_fhvhv, task_id=download_dataset_task, execution_date=20191102T060000, start_date=20240518T135447, end_date=20240518T135528
[2024-05-18 13:55:28,703] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-05-18 13:55:29,453] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-12-16 15:19:17,376] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_fhvhv.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [queued]>
[2024-12-16 15:19:17,440] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_fhvhv.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [queued]>
[2024-12-16 15:19:17,440] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-12-16 15:19:17,440] {taskinstance.py:1239} INFO - Starting attempt 1 of 3
[2024-12-16 15:19:17,440] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-12-16 15:19:17,507] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2019-11-02 06:00:00+00:00
[2024-12-16 15:19:17,529] {standard_task_runner.py:52} INFO - Started process 5976 to run task
[2024-12-16 15:19:17,558] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery_fhvhv', 'download_dataset_task', 'scheduled__2019-11-02T06:00:00+00:00', '--job-id', '5652', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_fhvhv_dag.py', '--cfg-path', '/tmp/tmp3yqd_hfm', '--error-file', '/tmp/tmptof7phyx']
[2024-12-16 15:19:17,573] {standard_task_runner.py:77} INFO - Job 5652: Subtask download_dataset_task
[2024-12-16 15:19:17,835] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery_fhvhv.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [running]> on host 78f99e82b508
[2024-12-16 15:19:18,112] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-12-16 15:19:18,217] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery_fhvhv
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2019-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-11-02T06:00:00+00:00
[2024-12-16 15:19:18,250] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-12-16 15:19:18,259] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2019-11.parquet > /opt/***/raw_data/fhvhvtaxi_tripdata_2019-11.parquet']
[2024-12-16 15:19:18,366] {subprocess.py:85} INFO - Output:
[2024-12-16 15:19:57,292] {subprocess.py:93} INFO - Command exited with return code 0
[2024-12-16 15:19:57,362] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery_fhvhv, task_id=download_dataset_task, execution_date=20191102T060000, start_date=20241216T151917, end_date=20241216T151957
[2024-12-16 15:19:57,671] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-12-16 15:19:57,826] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-12-29 14:02:16,882] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_fhvhv.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [queued]>
[2024-12-29 14:02:16,959] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_fhvhv.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [queued]>
[2024-12-29 14:02:16,962] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-12-29 14:02:16,963] {taskinstance.py:1239} INFO - Starting attempt 1 of 3
[2024-12-29 14:02:16,965] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-12-29 14:02:17,068] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2019-11-02 06:00:00+00:00
[2024-12-29 14:02:17,117] {standard_task_runner.py:52} INFO - Started process 835 to run task
[2024-12-29 14:02:17,155] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery_fhvhv', 'download_dataset_task', 'scheduled__2019-11-02T06:00:00+00:00', '--job-id', '5878', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_fhvhv_dag.py', '--cfg-path', '/tmp/tmpaf8_y5ew', '--error-file', '/tmp/tmpkfhc_g3c']
[2024-12-29 14:02:17,195] {standard_task_runner.py:77} INFO - Job 5878: Subtask download_dataset_task
[2024-12-29 14:02:17,460] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery_fhvhv.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [running]> on host 4b90d914d43e
[2024-12-29 14:02:17,809] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-12-29 14:02:17,982] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery_fhvhv
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2019-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-11-02T06:00:00+00:00
[2024-12-29 14:02:17,984] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-12-29 14:02:17,988] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2019-11.parquet > /opt/***/raw_data/fhvhvtaxi_tripdata_2019-11.parquet']
[2024-12-29 14:02:18,097] {subprocess.py:85} INFO - Output:
[2024-12-29 14:03:05,778] {subprocess.py:93} INFO - Command exited with return code 0
[2024-12-29 14:03:05,983] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery_fhvhv, task_id=download_dataset_task, execution_date=20191102T060000, start_date=20241229T140216, end_date=20241229T140305
[2024-12-29 14:03:06,180] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-12-29 14:03:06,392] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-01-01 04:56:31,954] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_fhvhv.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [queued]>
[2025-01-01 04:56:31,976] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_fhvhv.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [queued]>
[2025-01-01 04:56:31,977] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2025-01-01 04:56:31,978] {taskinstance.py:1239} INFO - Starting attempt 1 of 3
[2025-01-01 04:56:31,978] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2025-01-01 04:56:31,997] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2019-11-02 06:00:00+00:00
[2025-01-01 04:56:32,009] {standard_task_runner.py:52} INFO - Started process 3536 to run task
[2025-01-01 04:56:32,016] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery_fhvhv', 'download_dataset_task', 'scheduled__2019-11-02T06:00:00+00:00', '--job-id', '6193', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_fhvhv_dag.py', '--cfg-path', '/tmp/tmpuhvn_nev', '--error-file', '/tmp/tmp91yrl7hm']
[2025-01-01 04:56:32,022] {standard_task_runner.py:77} INFO - Job 6193: Subtask download_dataset_task
[2025-01-01 04:56:32,130] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery_fhvhv.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [running]> on host 4228b0d90dbc
[2025-01-01 04:56:32,196] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2025-01-01 04:56:32,229] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery_fhvhv
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2019-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-11-02T06:00:00+00:00
[2025-01-01 04:56:32,231] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2025-01-01 04:56:32,232] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2019-11.parquet > /opt/***/raw_data/fhvhvtaxi_tripdata_2019-11.parquet']
[2025-01-01 04:56:32,256] {subprocess.py:85} INFO - Output:
[2025-01-01 04:57:05,435] {subprocess.py:93} INFO - Command exited with return code 0
[2025-01-01 04:57:05,531] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery_fhvhv, task_id=download_dataset_task, execution_date=20191102T060000, start_date=20250101T045631, end_date=20250101T045705
[2025-01-01 04:57:05,675] {local_task_job.py:154} INFO - Task exited with return code 0
[2025-01-01 04:57:05,750] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-01-01 11:34:52,093] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_fhvhv.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [queued]>
[2025-01-01 11:34:52,108] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_fhvhv.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [queued]>
[2025-01-01 11:34:52,109] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2025-01-01 11:34:52,109] {taskinstance.py:1239} INFO - Starting attempt 1 of 3
[2025-01-01 11:34:52,109] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2025-01-01 11:34:52,126] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2019-11-02 06:00:00+00:00
[2025-01-01 11:34:52,137] {standard_task_runner.py:52} INFO - Started process 6568 to run task
[2025-01-01 11:34:52,144] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery_fhvhv', 'download_dataset_task', 'scheduled__2019-11-02T06:00:00+00:00', '--job-id', '6309', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_fhvhv_dag.py', '--cfg-path', '/tmp/tmp70juru_e', '--error-file', '/tmp/tmph5jqoa7l']
[2025-01-01 11:34:52,150] {standard_task_runner.py:77} INFO - Job 6309: Subtask download_dataset_task
[2025-01-01 11:34:52,241] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery_fhvhv.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [running]> on host b9549a156c09
[2025-01-01 11:34:52,290] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2025-01-01 11:34:52,320] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery_fhvhv
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2019-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-11-02T06:00:00+00:00
[2025-01-01 11:34:52,321] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2025-01-01 11:34:52,322] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2019-11.parquet > /opt/***/raw_data/fhvhvtaxi_tripdata_2019-11.parquet']
[2025-01-01 11:34:52,341] {subprocess.py:85} INFO - Output:
[2025-01-01 11:35:39,362] {subprocess.py:93} INFO - Command exited with return code 0
[2025-01-01 11:35:39,422] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery_fhvhv, task_id=download_dataset_task, execution_date=20191102T060000, start_date=20250101T113452, end_date=20250101T113539
[2025-01-01 11:35:39,490] {local_task_job.py:154} INFO - Task exited with return code 0
[2025-01-01 11:35:39,537] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
