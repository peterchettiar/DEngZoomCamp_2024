[2024-03-26 17:33:42,840] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-26 17:33:42,922] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-26 17:33:42,923] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-26 17:33:42,923] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2024-03-26 17:33:42,923] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-26 17:33:43,046] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): ingest_to_postgres_task> on 2021-04-02 06:00:00+00:00
[2024-03-26 17:33:43,078] {standard_task_runner.py:52} INFO - Started process 2813 to run task
[2024-03-26 17:33:43,172] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data', 'ingest_to_postgres_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '401', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_dag.py', '--cfg-path', '/tmp/tmp_4y04gd8', '--error-file', '/tmp/tmpjtf43h8o']
[2024-03-26 17:33:43,184] {standard_task_runner.py:77} INFO - Job 401: Subtask ingest_to_postgres_task
[2024-03-26 17:33:43,553] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host d71984e59113
[2024-03-26 17:33:43,678] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-26 17:33:43,734] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data
AIRFLOW_CTX_TASK_ID=ingest_to_postgres_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-03-26 17:33:43,736] {logging_mixin.py:109} INFO - yellow_taxi_2021_04 /opt/***/yellowtaxi_tripdata_2021-04.parquet 2021-04-02T06:00:00+00:00
[2024-03-26 17:33:43,736] {logging_mixin.py:109} INFO - Starting data ingestion process...
[2024-03-26 17:33:43,785] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/ingest_scipt.py", line 22, in ingest_callable
    df = pd.read_csv(parquet_file)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 688, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 460, in _read
    data = parser.read(nrows)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 1198, in read
    ret = self._engine.read(nrows)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 2157, in read
    data = self._reader.read(nrows)
  File "pandas/_libs/parsers.pyx", line 847, in pandas._libs.parsers.TextReader.read
  File "pandas/_libs/parsers.pyx", line 862, in pandas._libs.parsers.TextReader._read_low_memory
  File "pandas/_libs/parsers.pyx", line 918, in pandas._libs.parsers.TextReader._read_rows
  File "pandas/_libs/parsers.pyx", line 905, in pandas._libs.parsers.TextReader._tokenize_rows
  File "pandas/_libs/parsers.pyx", line 2042, in pandas._libs.parsers.raise_parser_error
pandas.errors.ParserError: Error tokenizing data. C error: Expected 2 fields in line 3, saw 3

[2024-03-26 17:33:43,814] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=ingest_data, task_id=ingest_to_postgres_task, execution_date=20210402T060000, start_date=20240326T173342, end_date=20240326T173343
[2024-03-26 17:33:43,906] {standard_task_runner.py:92} ERROR - Failed to execute job 401 for task ingest_to_postgres_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/ingest_scipt.py", line 22, in ingest_callable
    df = pd.read_csv(parquet_file)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 688, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 460, in _read
    data = parser.read(nrows)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 1198, in read
    ret = self._engine.read(nrows)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 2157, in read
    data = self._reader.read(nrows)
  File "pandas/_libs/parsers.pyx", line 847, in pandas._libs.parsers.TextReader.read
  File "pandas/_libs/parsers.pyx", line 862, in pandas._libs.parsers.TextReader._read_low_memory
  File "pandas/_libs/parsers.pyx", line 918, in pandas._libs.parsers.TextReader._read_rows
  File "pandas/_libs/parsers.pyx", line 905, in pandas._libs.parsers.TextReader._tokenize_rows
  File "pandas/_libs/parsers.pyx", line 2042, in pandas._libs.parsers.raise_parser_error
pandas.errors.ParserError: Error tokenizing data. C error: Expected 2 fields in line 3, saw 3

[2024-03-26 17:33:43,979] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-26 17:33:44,170] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-26 17:48:29,128] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-26 17:48:29,218] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-26 17:48:29,219] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-26 17:48:29,220] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2024-03-26 17:48:29,221] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-26 17:48:29,252] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): ingest_to_postgres_task> on 2021-04-02 06:00:00+00:00
[2024-03-26 17:48:29,266] {standard_task_runner.py:52} INFO - Started process 221 to run task
[2024-03-26 17:48:29,290] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data', 'ingest_to_postgres_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '480', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_dag.py', '--cfg-path', '/tmp/tmpq3tbv18e', '--error-file', '/tmp/tmptn2bb5ox']
[2024-03-26 17:48:29,291] {standard_task_runner.py:77} INFO - Job 480: Subtask ingest_to_postgres_task
[2024-03-26 17:48:29,528] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host 05f84def3a12
[2024-03-26 17:48:29,721] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-26 17:48:29,787] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data
AIRFLOW_CTX_TASK_ID=ingest_to_postgres_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-03-26 17:48:29,788] {logging_mixin.py:109} INFO - yellow_taxi_2021_04 /opt/***/yellowtaxi_tripdata_2021-04.parquet 2021-04-02T06:00:00+00:00
[2024-03-26 17:48:29,789] {logging_mixin.py:109} INFO - Starting data ingestion process...
[2024-03-26 17:48:29,843] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/ingest_scipt.py", line 22, in ingest_callable
    df = pd.read_csv(parquet_file)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 688, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 460, in _read
    data = parser.read(nrows)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 1198, in read
    ret = self._engine.read(nrows)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 2157, in read
    data = self._reader.read(nrows)
  File "pandas/_libs/parsers.pyx", line 847, in pandas._libs.parsers.TextReader.read
  File "pandas/_libs/parsers.pyx", line 862, in pandas._libs.parsers.TextReader._read_low_memory
  File "pandas/_libs/parsers.pyx", line 918, in pandas._libs.parsers.TextReader._read_rows
  File "pandas/_libs/parsers.pyx", line 905, in pandas._libs.parsers.TextReader._tokenize_rows
  File "pandas/_libs/parsers.pyx", line 2042, in pandas._libs.parsers.raise_parser_error
pandas.errors.ParserError: Error tokenizing data. C error: Expected 2 fields in line 3, saw 3

[2024-03-26 17:48:29,899] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=ingest_data, task_id=ingest_to_postgres_task, execution_date=20210402T060000, start_date=20240326T174829, end_date=20240326T174829
[2024-03-26 17:48:29,935] {standard_task_runner.py:92} ERROR - Failed to execute job 480 for task ingest_to_postgres_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/ingest_scipt.py", line 22, in ingest_callable
    df = pd.read_csv(parquet_file)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 688, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 460, in _read
    data = parser.read(nrows)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 1198, in read
    ret = self._engine.read(nrows)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 2157, in read
    data = self._reader.read(nrows)
  File "pandas/_libs/parsers.pyx", line 847, in pandas._libs.parsers.TextReader.read
  File "pandas/_libs/parsers.pyx", line 862, in pandas._libs.parsers.TextReader._read_low_memory
  File "pandas/_libs/parsers.pyx", line 918, in pandas._libs.parsers.TextReader._read_rows
  File "pandas/_libs/parsers.pyx", line 905, in pandas._libs.parsers.TextReader._tokenize_rows
  File "pandas/_libs/parsers.pyx", line 2042, in pandas._libs.parsers.raise_parser_error
pandas.errors.ParserError: Error tokenizing data. C error: Expected 2 fields in line 3, saw 3

[2024-03-26 17:48:29,991] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-26 17:48:30,130] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-26 17:52:05,565] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-26 17:52:05,728] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-26 17:52:05,728] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-26 17:52:05,728] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2024-03-26 17:52:05,728] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-26 17:52:05,890] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): ingest_to_postgres_task> on 2021-04-02 06:00:00+00:00
[2024-03-26 17:52:05,903] {standard_task_runner.py:52} INFO - Started process 642 to run task
[2024-03-26 17:52:05,919] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data', 'ingest_to_postgres_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '557', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_dag.py', '--cfg-path', '/tmp/tmp9r88lwwy', '--error-file', '/tmp/tmpz6wia0yb']
[2024-03-26 17:52:05,921] {standard_task_runner.py:77} INFO - Job 557: Subtask ingest_to_postgres_task
[2024-03-26 17:52:06,353] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host 05f84def3a12
[2024-03-26 17:52:06,681] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-26 17:52:06,923] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data
AIRFLOW_CTX_TASK_ID=ingest_to_postgres_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-03-26 17:52:06,925] {logging_mixin.py:109} INFO - yellow_taxi_2021_04 /opt/***/yellowtaxi_tripdata_2021-04.parquet 2021-04-02T06:00:00+00:00
[2024-03-26 17:52:06,925] {logging_mixin.py:109} INFO - Starting data ingestion process...
[2024-03-26 17:52:07,029] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/ingest_scipt.py", line 22, in ingest_callable
    df = pd.read_csv(parquet_file)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 688, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 460, in _read
    data = parser.read(nrows)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 1198, in read
    ret = self._engine.read(nrows)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 2157, in read
    data = self._reader.read(nrows)
  File "pandas/_libs/parsers.pyx", line 847, in pandas._libs.parsers.TextReader.read
  File "pandas/_libs/parsers.pyx", line 862, in pandas._libs.parsers.TextReader._read_low_memory
  File "pandas/_libs/parsers.pyx", line 918, in pandas._libs.parsers.TextReader._read_rows
  File "pandas/_libs/parsers.pyx", line 905, in pandas._libs.parsers.TextReader._tokenize_rows
  File "pandas/_libs/parsers.pyx", line 2042, in pandas._libs.parsers.raise_parser_error
pandas.errors.ParserError: Error tokenizing data. C error: Expected 2 fields in line 3, saw 3

[2024-03-26 17:52:07,156] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=ingest_data, task_id=ingest_to_postgres_task, execution_date=20210402T060000, start_date=20240326T175205, end_date=20240326T175207
[2024-03-26 17:52:07,321] {standard_task_runner.py:92} ERROR - Failed to execute job 557 for task ingest_to_postgres_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/ingest_scipt.py", line 22, in ingest_callable
    df = pd.read_csv(parquet_file)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 688, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 460, in _read
    data = parser.read(nrows)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 1198, in read
    ret = self._engine.read(nrows)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 2157, in read
    data = self._reader.read(nrows)
  File "pandas/_libs/parsers.pyx", line 847, in pandas._libs.parsers.TextReader.read
  File "pandas/_libs/parsers.pyx", line 862, in pandas._libs.parsers.TextReader._read_low_memory
  File "pandas/_libs/parsers.pyx", line 918, in pandas._libs.parsers.TextReader._read_rows
  File "pandas/_libs/parsers.pyx", line 905, in pandas._libs.parsers.TextReader._tokenize_rows
  File "pandas/_libs/parsers.pyx", line 2042, in pandas._libs.parsers.raise_parser_error
pandas.errors.ParserError: Error tokenizing data. C error: Expected 2 fields in line 3, saw 3

[2024-03-26 17:52:07,420] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-26 17:52:07,599] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-26 18:02:44,944] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-26 18:02:44,979] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-26 18:02:44,979] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-26 18:02:44,979] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2024-03-26 18:02:44,979] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-26 18:02:45,016] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): ingest_to_postgres_task> on 2021-04-02 06:00:00+00:00
[2024-03-26 18:02:45,043] {standard_task_runner.py:52} INFO - Started process 1361 to run task
[2024-03-26 18:02:45,082] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data', 'ingest_to_postgres_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '629', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_dag.py', '--cfg-path', '/tmp/tmpg4npqacq', '--error-file', '/tmp/tmpshrgvy8x']
[2024-03-26 18:02:45,083] {standard_task_runner.py:77} INFO - Job 629: Subtask ingest_to_postgres_task
[2024-03-26 18:02:45,271] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host 05f84def3a12
[2024-03-26 18:02:45,425] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-26 18:02:45,484] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data
AIRFLOW_CTX_TASK_ID=ingest_to_postgres_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-03-26 18:02:45,486] {logging_mixin.py:109} INFO - yellow_taxi_2021_04 /opt/***/yellowtaxi_tripdata_2021-04.parquet 2021-04-02T06:00:00+00:00
[2024-03-26 18:02:45,486] {logging_mixin.py:109} INFO - Starting data ingestion process...
[2024-03-26 18:02:48,531] {logging_mixin.py:109} INFO - Writing data to table yellow_taxi_2021_04 in the database...
[2024-03-27 02:48:02,499] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-27 02:48:02,667] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-27 02:48:02,674] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-27 02:48:02,675] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2024-03-27 02:48:02,676] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-27 02:48:02,762] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): ingest_to_postgres_task> on 2021-04-02 06:00:00+00:00
[2024-03-27 02:48:02,813] {standard_task_runner.py:52} INFO - Started process 1418 to run task
[2024-03-27 02:48:02,896] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data', 'ingest_to_postgres_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '741', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_dag.py', '--cfg-path', '/tmp/tmpgbp6fp1v', '--error-file', '/tmp/tmpa7bw2clm']
[2024-03-27 02:48:02,904] {standard_task_runner.py:77} INFO - Job 741: Subtask ingest_to_postgres_task
[2024-03-27 02:48:03,306] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host 05f84def3a12
[2024-03-27 02:48:03,768] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-27 02:48:03,950] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data
AIRFLOW_CTX_TASK_ID=ingest_to_postgres_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-03-27 02:48:03,952] {logging_mixin.py:109} INFO - yellow_taxi_2021_04 /opt/***/yellowtaxi_tripdata_2021-04.parquet 2021-04-02T06:00:00+00:00
[2024-03-27 02:48:03,952] {logging_mixin.py:109} INFO - Starting data ingestion process...
[2024-03-27 02:48:11,583] {logging_mixin.py:109} INFO - Writing data to table yellow_taxi_2021_04 in the database...
[2024-03-28 01:58:39,744] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-28 01:58:39,809] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-28 01:58:39,810] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-28 01:58:39,810] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2024-03-28 01:58:39,810] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-28 01:58:39,862] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): ingest_to_postgres_task> on 2021-04-02 06:00:00+00:00
[2024-03-28 01:58:39,870] {standard_task_runner.py:52} INFO - Started process 763 to run task
[2024-03-28 01:58:39,909] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data', 'ingest_to_postgres_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '819', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_dag.py', '--cfg-path', '/tmp/tmpjgdznwyx', '--error-file', '/tmp/tmpenwyyyqr']
[2024-03-28 01:58:39,911] {standard_task_runner.py:77} INFO - Job 819: Subtask ingest_to_postgres_task
[2024-03-28 01:58:40,168] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host 05f84def3a12
[2024-03-28 01:58:40,323] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-28 01:58:40,401] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data
AIRFLOW_CTX_TASK_ID=ingest_to_postgres_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-03-28 01:58:40,405] {logging_mixin.py:109} INFO - yellow_taxi_2021_04 /opt/***/yellowtaxi_tripdata_2021-04.parquet 2021-04-02T06:00:00+00:00
[2024-03-28 01:58:40,406] {logging_mixin.py:109} INFO - Starting data ingestion process...
[2024-03-28 01:58:44,388] {logging_mixin.py:109} INFO - Writing data to table yellow_taxi_2021_04 in the database...
[2024-03-28 09:01:36,596] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-28 09:01:36,623] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-28 09:01:36,624] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-28 09:01:36,624] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2024-03-28 09:01:36,624] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-28 09:01:36,879] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): ingest_to_postgres_task> on 2021-04-02 06:00:00+00:00
[2024-03-28 09:01:36,890] {standard_task_runner.py:52} INFO - Started process 553 to run task
[2024-03-28 09:01:36,904] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data', 'ingest_to_postgres_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '962', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_dag.py', '--cfg-path', '/tmp/tmphdn8cp8o', '--error-file', '/tmp/tmp88c7arwt']
[2024-03-28 09:01:36,906] {standard_task_runner.py:77} INFO - Job 962: Subtask ingest_to_postgres_task
[2024-03-28 09:01:37,509] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host 05f84def3a12
[2024-03-28 09:01:37,941] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-28 09:01:38,110] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data
AIRFLOW_CTX_TASK_ID=ingest_to_postgres_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-03-28 09:01:38,117] {logging_mixin.py:109} INFO - yellow_taxi_2021_04 /opt/***/yellowtaxi_tripdata_2021-04.parquet 2021-04-02T06:00:00+00:00
[2024-03-28 09:01:38,118] {logging_mixin.py:109} INFO - Starting data ingestion process...
[2024-03-28 09:01:45,740] {logging_mixin.py:109} INFO - Writing data to table yellow_taxi_2021_04 in the database...
[2024-03-28 09:31:43,200] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-28 09:31:43,220] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-28 09:31:43,220] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-28 09:31:43,220] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2024-03-28 09:31:43,220] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-28 09:31:43,245] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): ingest_to_postgres_task> on 2021-04-02 06:00:00+00:00
[2024-03-28 09:31:43,253] {standard_task_runner.py:52} INFO - Started process 1193 to run task
[2024-03-28 09:31:43,268] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data', 'ingest_to_postgres_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '1038', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_dag.py', '--cfg-path', '/tmp/tmp26s0t83o', '--error-file', '/tmp/tmp1cwf3tyl']
[2024-03-28 09:31:43,269] {standard_task_runner.py:77} INFO - Job 1038: Subtask ingest_to_postgres_task
[2024-03-28 09:31:43,382] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host 05f84def3a12
[2024-03-28 09:31:43,461] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-28 09:31:43,519] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data
AIRFLOW_CTX_TASK_ID=ingest_to_postgres_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-03-28 09:31:43,520] {logging_mixin.py:109} INFO - yellow_taxi_2021_04 /opt/***/yellowtaxi_tripdata_2021-04.parquet 2021-04-02T06:00:00+00:00
[2024-03-28 09:31:43,520] {logging_mixin.py:109} INFO - Starting data ingestion process...
[2024-03-28 09:31:44,772] {logging_mixin.py:109} INFO - Writing data to table yellow_taxi_2021_04 in the database...
[2024-03-28 09:46:46,974] {local_task_job.py:212} WARNING - State of this instance has been externally set to None. Terminating instance.
[2024-03-28 09:46:47,016] {process_utils.py:124} INFO - Sending Signals.SIGTERM to group 1193. PIDs of all processes in the group: [1193]
[2024-03-28 09:46:47,023] {process_utils.py:75} INFO - Sending the signal Signals.SIGTERM to group 1193
[2024-03-28 09:46:47,025] {taskinstance.py:1408} ERROR - Received SIGTERM. Terminating subprocesses.
[2024-03-28 09:46:47,070] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/ingest_script.py", line 38, in ingest_callable
    chunk.to_sql(name=table_name, con=connection, if_exists="append", index=False)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/generic.py", line 2615, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 598, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 1398, in to_sql
    table.insert(chunksize, method=method)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 830, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 747, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1514, in _handle_dbapi_exception
    util.raise_(exc_info[1], with_traceback=exc_info[2])
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1410, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2024-03-28 09:46:47,119] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=ingest_data, task_id=ingest_to_postgres_task, execution_date=20210402T060000, start_date=, end_date=20240328T094647
[2024-03-28 09:46:47,182] {standard_task_runner.py:92} ERROR - Failed to execute job 1038 for task ingest_to_postgres_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/ingest_script.py", line 38, in ingest_callable
    chunk.to_sql(name=table_name, con=connection, if_exists="append", index=False)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/generic.py", line 2615, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 598, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 1398, in to_sql
    table.insert(chunksize, method=method)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 830, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 747, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1514, in _handle_dbapi_exception
    util.raise_(exc_info[1], with_traceback=exc_info[2])
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1410, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "dag_run_dag_id_run_id_key"
DETAIL:  Key (dag_id, run_id)=(ingest_data, scheduled__2021-04-02T06:00:00+00:00) already exists.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1382, in _run_raw_task
    self.handle_failure(e, test_mode, error_file=error_file, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "dag_run_dag_id_run_id_key"
DETAIL:  Key (dag_id, run_id)=(ingest_data, scheduled__2021-04-02T06:00:00+00:00) already exists.

[SQL: INSERT INTO dag_run (id, dag_id, queued_at, execution_date, start_date, end_date, state, run_id, creating_job_id, external_trigger, run_type, conf, data_interval_start, data_interval_end, last_scheduling_decision, dag_hash) VALUES (%(id)s, %(dag_id)s, %(queued_at)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(state)s, %(run_id)s, %(creating_job_id)s, %(external_trigger)s, %(run_type)s, %(conf)s, %(data_interval_start)s, %(data_interval_end)s, %(last_scheduling_decision)s, %(dag_hash)s)]
[parameters: {'id': 511, 'dag_id': 'ingest_data', 'queued_at': datetime.datetime(2024, 3, 28, 9, 30, 22, 403384, tzinfo=Timezone('UTC')), 'execution_date': datetime.datetime(2021, 4, 2, 6, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2024, 3, 28, 9, 30, 22, 447681, tzinfo=Timezone('UTC')), 'end_date': None, 'state': 'running', 'run_id': 'scheduled__2021-04-02T06:00:00+00:00', 'creating_job_id': 976, 'external_trigger': False, 'run_type': 'scheduled', 'conf': <psycopg2.extensions.Binary object at 0x7f1e74e0be40>, 'data_interval_start': datetime.datetime(2021, 4, 2, 6, 0, tzinfo=Timezone('UTC')), 'data_interval_end': datetime.datetime(2021, 5, 2, 6, 0, tzinfo=Timezone('UTC')), 'last_scheduling_decision': datetime.datetime(2024, 3, 28, 9, 31, 42, 309806, tzinfo=Timezone('UTC')), 'dag_hash': '55efe8375f9b611cf5027f28ed4166ac'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2024-03-28 09:46:47,404] {process_utils.py:70} INFO - Process psutil.Process(pid=1193, status='terminated', exitcode=1, started='09:31:42') (1193) terminated with exit code 1
[2024-03-28 10:08:00,544] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-28 10:08:00,608] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [queued]>
[2024-03-28 10:08:00,608] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-28 10:08:00,609] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2024-03-28 10:08:00,609] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-28 10:08:00,663] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): ingest_to_postgres_task> on 2021-04-02 06:00:00+00:00
[2024-03-28 10:08:00,723] {standard_task_runner.py:52} INFO - Started process 460 to run task
[2024-03-28 10:08:00,738] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data', 'ingest_to_postgres_task', 'scheduled__2021-04-02T06:00:00+00:00', '--job-id', '1127', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_dag.py', '--cfg-path', '/tmp/tmpoqpu2t3t', '--error-file', '/tmp/tmpuo0fve3o']
[2024-03-28 10:08:00,739] {standard_task_runner.py:77} INFO - Job 1127: Subtask ingest_to_postgres_task
[2024-03-28 10:08:01,177] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data.ingest_to_postgres_task scheduled__2021-04-02T06:00:00+00:00 [running]> on host 05f84def3a12
[2024-03-28 10:08:01,377] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-28 10:08:01,501] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data
AIRFLOW_CTX_TASK_ID=ingest_to_postgres_task
AIRFLOW_CTX_EXECUTION_DATE=2021-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-02T06:00:00+00:00
[2024-03-28 10:08:01,508] {logging_mixin.py:109} INFO - yellow_taxi_2021_04 /opt/***/yellowtaxi_tripdata_2021-04.parquet 2021-04-02T06:00:00+00:00
[2024-03-28 10:08:01,509] {logging_mixin.py:109} INFO - Starting data ingestion process...
[2024-03-28 10:08:06,550] {logging_mixin.py:109} INFO - Writing data to table yellow_taxi_2021_04 in the database...
