[2024-05-02 04:03:37,273] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_yt.download_dataset_task scheduled__2020-12-02T06:00:00+00:00 [queued]>
[2024-05-02 04:03:37,327] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_yt.download_dataset_task scheduled__2020-12-02T06:00:00+00:00 [queued]>
[2024-05-02 04:03:37,329] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-05-02 04:03:37,330] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-05-02 04:03:37,331] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-05-02 04:03:37,371] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2020-12-02 06:00:00+00:00
[2024-05-02 04:03:37,397] {standard_task_runner.py:52} INFO - Started process 5259 to run task
[2024-05-02 04:03:37,437] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery_yt', 'download_dataset_task', 'scheduled__2020-12-02T06:00:00+00:00', '--job-id', '3744', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_yt_dag.py', '--cfg-path', '/tmp/tmp9vwqfpjm', '--error-file', '/tmp/tmp97qtcgu8']
[2024-05-02 04:03:37,459] {standard_task_runner.py:77} INFO - Job 3744: Subtask download_dataset_task
[2024-05-02 04:03:37,674] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery_yt.download_dataset_task scheduled__2020-12-02T06:00:00+00:00 [running]> on host bef445d594dc
[2024-05-02 04:03:37,800] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-05-02 04:03:37,880] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery_yt
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2020-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-12-02T06:00:00+00:00
[2024-05-02 04:03:37,881] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-05-02 04:03:37,882] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2020-12.csv.gz > /opt/***/raw_data/yellowtaxi_tripdata_2020-12.csv.gz | gzip -d > /opt/***/raw_data/yellowtaxi_tripdata_2020-12.csv && rm /opt/***/raw_data/yellowtaxi_tripdata_2020-12.csv.gz']
[2024-05-02 04:03:37,957] {subprocess.py:85} INFO - Output:
[2024-05-02 04:03:37,968] {subprocess.py:89} INFO - 
[2024-05-02 04:03:37,968] {subprocess.py:89} INFO - gzip: stdin: unexpected end of file
[2024-05-02 04:03:39,240] {subprocess.py:93} INFO - Command exited with return code 1
[2024-05-02 04:03:39,267] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-05-02 04:03:39,292] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery_yt, task_id=download_dataset_task, execution_date=20201202T060000, start_date=20240502T040337, end_date=20240502T040339
[2024-05-02 04:03:39,339] {standard_task_runner.py:92} ERROR - Failed to execute job 3744 for task download_dataset_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-05-02 04:03:39,408] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-05-02 04:03:39,537] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-05-03 08:04:06,344] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_yt.download_dataset_task scheduled__2020-12-02T06:00:00+00:00 [queued]>
[2024-05-03 08:04:06,461] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_yt.download_dataset_task scheduled__2020-12-02T06:00:00+00:00 [queued]>
[2024-05-03 08:04:06,462] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-05-03 08:04:06,462] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-05-03 08:04:06,462] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-05-03 08:04:06,585] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2020-12-02 06:00:00+00:00
[2024-05-03 08:04:06,637] {standard_task_runner.py:52} INFO - Started process 124 to run task
[2024-05-03 08:04:06,672] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery_yt', 'download_dataset_task', 'scheduled__2020-12-02T06:00:00+00:00', '--job-id', '3854', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_yt_dag.py', '--cfg-path', '/tmp/tmp16um8lnf', '--error-file', '/tmp/tmp0fmfwrti']
[2024-05-03 08:04:06,720] {standard_task_runner.py:77} INFO - Job 3854: Subtask download_dataset_task
[2024-05-03 08:04:07,339] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery_yt.download_dataset_task scheduled__2020-12-02T06:00:00+00:00 [running]> on host 5bfe1025092b
[2024-05-03 08:04:07,832] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-05-03 08:04:07,941] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery_yt
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2020-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-12-02T06:00:00+00:00
[2024-05-03 08:04:07,943] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-05-03 08:04:07,945] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2020-12.csv.gz > /opt/***/raw_data/yellowtaxi_tripdata_2020-12.csv.gz && gunzip /opt/***/raw_data/yellowtaxi_tripdata_2020-12.csv.gz']
[2024-05-03 08:04:08,009] {subprocess.py:85} INFO - Output:
[2024-05-03 08:04:20,152] {subprocess.py:93} INFO - Command exited with return code 0
[2024-05-03 08:04:20,272] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery_yt, task_id=download_dataset_task, execution_date=20201202T060000, start_date=20240503T080406, end_date=20240503T080420
[2024-05-03 08:04:20,587] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-05-03 08:04:21,573] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-05-03 08:55:57,460] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_yt.download_dataset_task scheduled__2020-12-02T06:00:00+00:00 [queued]>
[2024-05-03 08:55:57,484] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_yt.download_dataset_task scheduled__2020-12-02T06:00:00+00:00 [queued]>
[2024-05-03 08:55:57,485] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-05-03 08:55:57,485] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-05-03 08:55:57,485] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-05-03 08:55:57,497] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2020-12-02 06:00:00+00:00
[2024-05-03 08:55:57,504] {standard_task_runner.py:52} INFO - Started process 1668 to run task
[2024-05-03 08:55:57,510] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery_yt', 'download_dataset_task', 'scheduled__2020-12-02T06:00:00+00:00', '--job-id', '3961', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_yt_dag.py', '--cfg-path', '/tmp/tmpneed0k81', '--error-file', '/tmp/tmpmnb88igg']
[2024-05-03 08:55:57,515] {standard_task_runner.py:77} INFO - Job 3961: Subtask download_dataset_task
[2024-05-03 08:55:57,585] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery_yt.download_dataset_task scheduled__2020-12-02T06:00:00+00:00 [running]> on host 5bfe1025092b
[2024-05-03 08:55:57,633] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-05-03 08:55:57,656] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery_yt
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2020-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-12-02T06:00:00+00:00
[2024-05-03 08:55:57,658] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-05-03 08:55:57,659] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2020-12.csv.gz > /opt/***/raw_data/yellowtaxi_tripdata_2020-12.csv.gz && gunzip /opt/***/raw_data/yellowtaxi_tripdata_2020-12.csv.gz']
[2024-05-03 08:55:57,671] {subprocess.py:85} INFO - Output:
[2024-05-03 08:56:00,527] {subprocess.py:93} INFO - Command exited with return code 0
[2024-05-03 08:56:00,577] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery_yt, task_id=download_dataset_task, execution_date=20201202T060000, start_date=20240503T085557, end_date=20240503T085600
[2024-05-03 08:56:00,634] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-05-03 08:56:00,677] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-05-03 15:26:56,585] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_yt.download_dataset_task scheduled__2020-12-02T06:00:00+00:00 [queued]>
[2024-05-03 15:26:56,599] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_yt.download_dataset_task scheduled__2020-12-02T06:00:00+00:00 [queued]>
[2024-05-03 15:26:56,600] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-05-03 15:26:56,600] {taskinstance.py:1239} INFO - Starting attempt 1 of 3
[2024-05-03 15:26:56,600] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-05-03 15:26:56,613] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2020-12-02 06:00:00+00:00
[2024-05-03 15:26:56,620] {standard_task_runner.py:52} INFO - Started process 358 to run task
[2024-05-03 15:26:56,625] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery_yt', 'download_dataset_task', 'scheduled__2020-12-02T06:00:00+00:00', '--job-id', '4080', '--raw', '--subdir', 'DAGS_FOLDER/data_ingstion_gcs_yt_dag.py', '--cfg-path', '/tmp/tmphv5tnhp4', '--error-file', '/tmp/tmp2q3w0o3q']
[2024-05-03 15:26:56,629] {standard_task_runner.py:77} INFO - Job 4080: Subtask download_dataset_task
[2024-05-03 15:26:56,700] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery_yt.download_dataset_task scheduled__2020-12-02T06:00:00+00:00 [running]> on host 269238f68a58
[2024-05-03 15:26:56,742] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-05-03 15:26:56,765] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery_yt
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2020-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-12-02T06:00:00+00:00
[2024-05-03 15:26:56,766] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-05-03 15:26:56,767] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2020-12.csv.gz > /opt/***/raw_data/yellowtaxi_tripdata_2020-12.csv.gz && gunzip /opt/***/raw_data/yellowtaxi_tripdata_2020-12.csv.gz']
[2024-05-03 15:26:56,781] {subprocess.py:85} INFO - Output:
[2024-05-03 15:27:00,668] {subprocess.py:93} INFO - Command exited with return code 0
[2024-05-03 15:27:00,857] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery_yt, task_id=download_dataset_task, execution_date=20201202T060000, start_date=20240503T152656, end_date=20240503T152700
[2024-05-03 15:27:00,900] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-05-03 15:27:00,966] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-05-03 17:10:48,441] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_yt.download_dataset_task scheduled__2020-12-02T06:00:00+00:00 [queued]>
[2024-05-03 17:10:48,481] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_yt.download_dataset_task scheduled__2020-12-02T06:00:00+00:00 [queued]>
[2024-05-03 17:10:48,482] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-05-03 17:10:48,482] {taskinstance.py:1239} INFO - Starting attempt 1 of 3
[2024-05-03 17:10:48,482] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-05-03 17:10:48,508] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2020-12-02 06:00:00+00:00
[2024-05-03 17:10:48,517] {standard_task_runner.py:52} INFO - Started process 723 to run task
[2024-05-03 17:10:48,534] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery_yt', 'download_dataset_task', 'scheduled__2020-12-02T06:00:00+00:00', '--job-id', '4274', '--raw', '--subdir', 'DAGS_FOLDER/data_ingstion_gcs_yt_dag.py', '--cfg-path', '/tmp/tmplf3pu2d2', '--error-file', '/tmp/tmpmm863gai']
[2024-05-03 17:10:48,540] {standard_task_runner.py:77} INFO - Job 4274: Subtask download_dataset_task
[2024-05-03 17:10:48,647] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery_yt.download_dataset_task scheduled__2020-12-02T06:00:00+00:00 [running]> on host f0ab9bf9b587
[2024-05-03 17:10:48,720] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-05-03 17:10:48,760] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery_yt
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2020-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-12-02T06:00:00+00:00
[2024-05-03 17:10:48,761] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-05-03 17:10:48,762] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2020-12.csv.gz > /opt/***/raw_data/yellowtaxi_tripdata_2020-12.csv.gz && gunzip /opt/***/raw_data/yellowtaxi_tripdata_2020-12.csv.gz']
[2024-05-03 17:10:48,782] {subprocess.py:85} INFO - Output:
[2024-05-03 17:10:50,994] {subprocess.py:93} INFO - Command exited with return code 0
[2024-05-03 17:10:51,061] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery_yt, task_id=download_dataset_task, execution_date=20201202T060000, start_date=20240503T171048, end_date=20240503T171051
[2024-05-03 17:10:51,150] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-05-03 17:10:51,245] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-05-05 13:54:14,535] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_yt.download_dataset_task scheduled__2020-12-02T06:00:00+00:00 [queued]>
[2024-05-05 13:54:14,582] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_yt.download_dataset_task scheduled__2020-12-02T06:00:00+00:00 [queued]>
[2024-05-05 13:54:14,583] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-05-05 13:54:14,583] {taskinstance.py:1239} INFO - Starting attempt 1 of 3
[2024-05-05 13:54:14,585] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-05-05 13:54:14,649] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2020-12-02 06:00:00+00:00
[2024-05-05 13:54:14,673] {standard_task_runner.py:52} INFO - Started process 177 to run task
[2024-05-05 13:54:14,714] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery_yt', 'download_dataset_task', 'scheduled__2020-12-02T06:00:00+00:00', '--job-id', '4428', '--raw', '--subdir', 'DAGS_FOLDER/data_ingstion_gcs_yt_dag.py', '--cfg-path', '/tmp/tmpof0sbm4f', '--error-file', '/tmp/tmp_1gmycc8']
[2024-05-05 13:54:14,735] {standard_task_runner.py:77} INFO - Job 4428: Subtask download_dataset_task
[2024-05-05 13:54:14,943] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery_yt.download_dataset_task scheduled__2020-12-02T06:00:00+00:00 [running]> on host 43faca6eb596
[2024-05-05 13:54:15,156] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-05-05 13:54:15,280] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery_yt
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2020-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-12-02T06:00:00+00:00
[2024-05-05 13:54:15,281] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-05-05 13:54:15,282] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2020-12.csv.gz > /opt/***/raw_data/yellowtaxi_tripdata_2020-12.csv.gz && gunzip /opt/***/raw_data/yellowtaxi_tripdata_2020-12.csv.gz']
[2024-05-05 13:54:15,358] {subprocess.py:85} INFO - Output:
[2024-05-05 13:54:23,921] {subprocess.py:93} INFO - Command exited with return code 0
[2024-05-05 13:54:24,620] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery_yt, task_id=download_dataset_task, execution_date=20201202T060000, start_date=20240505T135414, end_date=20240505T135424
[2024-05-05 13:54:25,081] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-05-05 13:54:25,450] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-05-06 09:25:04,479] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_yt.download_dataset_task scheduled__2020-12-02T06:00:00+00:00 [queued]>
[2024-05-06 09:25:04,560] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery_yt.download_dataset_task scheduled__2020-12-02T06:00:00+00:00 [queued]>
[2024-05-06 09:25:04,569] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-05-06 09:25:04,570] {taskinstance.py:1239} INFO - Starting attempt 1 of 3
[2024-05-06 09:25:04,570] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-05-06 09:25:04,653] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2020-12-02 06:00:00+00:00
[2024-05-06 09:25:04,669] {standard_task_runner.py:52} INFO - Started process 273 to run task
[2024-05-06 09:25:04,678] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery_yt', 'download_dataset_task', 'scheduled__2020-12-02T06:00:00+00:00', '--job-id', '4583', '--raw', '--subdir', 'DAGS_FOLDER/data_ingstion_gcs_yt_dag.py', '--cfg-path', '/tmp/tmpb7mq78uc', '--error-file', '/tmp/tmpsob8o2d5']
[2024-05-06 09:25:04,727] {standard_task_runner.py:77} INFO - Job 4583: Subtask download_dataset_task
[2024-05-06 09:25:04,901] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery_yt.download_dataset_task scheduled__2020-12-02T06:00:00+00:00 [running]> on host 4d4efceb404e
[2024-05-06 09:25:05,001] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-05-06 09:25:05,047] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery_yt
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2020-12-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-12-02T06:00:00+00:00
[2024-05-06 09:25:05,051] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-05-06 09:25:05,051] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2020-12.csv.gz > /opt/***/raw_data/yellowtaxi_tripdata_2020-12.csv.gz && gunzip /opt/***/raw_data/yellowtaxi_tripdata_2020-12.csv.gz']
[2024-05-06 09:25:05,104] {subprocess.py:85} INFO - Output:
[2024-05-06 09:25:10,731] {subprocess.py:93} INFO - Command exited with return code 0
[2024-05-06 09:25:11,008] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery_yt, task_id=download_dataset_task, execution_date=20201202T060000, start_date=20240506T092504, end_date=20240506T092511
[2024-05-06 09:25:11,341] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-05-06 09:25:11,527] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
