[2024-03-29 08:27:14,345] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [queued]>
[2024-03-29 08:27:14,403] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [queued]>
[2024-03-29 08:27:14,404] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:27:14,405] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:27:14,405] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:27:14,471] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-07-02 06:00:00+00:00
[2024-03-29 08:27:14,496] {standard_task_runner.py:52} INFO - Started process 1504 to run task
[2024-03-29 08:27:14,514] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-07-02T06:00:00+00:00', '--job-id', '1768', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp70whsqy7', '--error-file', '/tmp/tmpbjdkekb8']
[2024-03-29 08:27:14,552] {standard_task_runner.py:77} INFO - Job 1768: Subtask download_dataset_task
[2024-03-29 08:27:14,724] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:27:14,811] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:27:14,873] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-07-02T06:00:00+00:00
[2024-03-29 08:27:14,875] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:27:14,876] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-07.parquet > /opt/***/yellowtaxi_tripdata_2022-07.parquet']
[2024-03-29 08:27:14,989] {subprocess.py:85} INFO - Output:
[2024-03-29 08:27:21,533] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:27:21,999] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220702T060000, start_date=20240329T082714, end_date=20240329T082721
[2024-03-29 08:27:22,156] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:27:22,311] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:53:05,317] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [queued]>
[2024-03-30 03:53:05,340] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [queued]>
[2024-03-30 03:53:05,341] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:53:05,342] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:53:05,342] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:53:05,362] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-07-02 06:00:00+00:00
[2024-03-30 03:53:05,386] {standard_task_runner.py:52} INFO - Started process 2017 to run task
[2024-03-30 03:53:05,401] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-07-02T06:00:00+00:00', '--job-id', '1975', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpoxod03n3', '--error-file', '/tmp/tmp40m22tnw']
[2024-03-30 03:53:05,419] {standard_task_runner.py:77} INFO - Job 1975: Subtask download_dataset_task
[2024-03-30 03:53:05,535] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:53:05,612] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:53:05,669] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-07-02T06:00:00+00:00
[2024-03-30 03:53:05,670] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:53:05,671] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-07.parquet > /opt/***/yellowtaxi_tripdata_2022-07.parquet']
[2024-03-30 03:53:05,697] {subprocess.py:85} INFO - Output:
[2024-03-30 03:53:12,288] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:53:12,333] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220702T060000, start_date=20240330T035305, end_date=20240330T035312
[2024-03-30 03:53:12,386] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:53:12,430] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:18:48,888] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:48,934] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:48,935] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:48,935] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:18:48,936] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:48,999] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-07-02 06:00:00+00:00
[2024-03-30 04:18:49,048] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-07-02T06:00:00+00:00', '--job-id', '2124', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmptjg391ar', '--error-file', '/tmp/tmplalaa5kb']
[2024-03-30 04:18:49,071] {standard_task_runner.py:77} INFO - Job 2124: Subtask download_dataset_task
[2024-03-30 04:18:49,020] {standard_task_runner.py:52} INFO - Started process 3699 to run task
[2024-03-30 04:18:49,267] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:18:49,413] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:18:49,533] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-07-02T06:00:00+00:00
[2024-03-30 04:18:49,535] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:18:49,535] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-07.parquet > /opt/***/yellowtaxi_tripdata_2022-07.parquet']
[2024-03-30 04:18:49,596] {subprocess.py:85} INFO - Output:
[2024-03-30 04:18:55,722] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:18:56,289] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220702T060000, start_date=20240330T041848, end_date=20240330T041856
[2024-03-30 04:18:56,491] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:18:56,778] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:25:25,531] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:25:25,580] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:25:25,582] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:25:25,583] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:25:25,583] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:25:25,633] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-07-02 06:00:00+00:00
[2024-03-30 04:25:25,667] {standard_task_runner.py:52} INFO - Started process 4326 to run task
[2024-03-30 04:25:25,696] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-07-02T06:00:00+00:00', '--job-id', '2203', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp2g3l7mfb', '--error-file', '/tmp/tmp5s4ol8q2']
[2024-03-30 04:25:25,732] {standard_task_runner.py:77} INFO - Job 2203: Subtask download_dataset_task
[2024-03-30 04:25:26,035] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:25:26,291] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:25:26,390] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-07-02T06:00:00+00:00
[2024-03-30 04:25:26,391] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:25:26,393] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-07.parquet > /opt/***/yellowtaxi_tripdata_2022-07.parquet']
[2024-03-30 04:25:26,483] {subprocess.py:85} INFO - Output:
[2024-03-30 04:25:32,709] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:25:33,047] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220702T060000, start_date=20240330T042525, end_date=20240330T042533
[2024-03-30 04:25:33,159] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:25:33,244] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:43:20,447] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:43:20,479] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [queued]>
[2024-03-30 04:43:20,479] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:43:20,479] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:43:20,479] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:43:20,490] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-07-02 06:00:00+00:00
[2024-03-30 04:43:20,497] {standard_task_runner.py:52} INFO - Started process 5569 to run task
[2024-03-30 04:43:20,502] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-07-02T06:00:00+00:00', '--job-id', '2323', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp954q5iw2', '--error-file', '/tmp/tmpidm2icxk']
[2024-03-30 04:43:20,508] {standard_task_runner.py:77} INFO - Job 2323: Subtask download_dataset_task
[2024-03-30 04:43:20,583] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:43:20,627] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:43:20,649] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-07-02T06:00:00+00:00
[2024-03-30 04:43:20,650] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:43:20,652] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-07.parquet > /opt/***/yellowtaxi_tripdata_2022-07.parquet']
[2024-03-30 04:43:20,674] {subprocess.py:85} INFO - Output:
[2024-03-30 04:43:26,725] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:43:26,769] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220702T060000, start_date=20240330T044320, end_date=20240330T044326
[2024-03-30 04:43:26,832] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:43:26,869] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 05:00:02,364] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:02,432] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:02,433] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:02,434] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 05:00:02,434] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:02,503] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-07-02 06:00:00+00:00
[2024-03-30 05:00:02,531] {standard_task_runner.py:52} INFO - Started process 6776 to run task
[2024-03-30 05:00:02,576] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-07-02T06:00:00+00:00', '--job-id', '2448', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpzkp631hb', '--error-file', '/tmp/tmp_y7fcufm']
[2024-03-30 05:00:02,599] {standard_task_runner.py:77} INFO - Job 2448: Subtask download_dataset_task
[2024-03-30 05:00:02,965] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 05:00:03,384] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 05:00:03,483] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-07-02T06:00:00+00:00
[2024-03-30 05:00:03,484] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 05:00:03,485] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-07.parquet > /opt/***/yellowtaxi_tripdata_2022-07.parquet']
[2024-03-30 05:00:03,543] {subprocess.py:85} INFO - Output:
[2024-03-30 05:00:10,318] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 05:00:10,411] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220702T060000, start_date=20240330T050002, end_date=20240330T050010
[2024-03-30 05:00:10,525] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 05:00:11,214] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:02:11,441] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [queued]>
[2024-03-30 09:02:11,484] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [queued]>
[2024-03-30 09:02:11,484] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:02:11,485] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:02:11,486] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:02:11,571] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-07-02 06:00:00+00:00
[2024-03-30 09:02:11,601] {standard_task_runner.py:52} INFO - Started process 18297 to run task
[2024-03-30 09:02:11,650] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-07-02T06:00:00+00:00', '--job-id', '2564', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpwdlnnx_e', '--error-file', '/tmp/tmppom7ba_b']
[2024-03-30 09:02:11,681] {standard_task_runner.py:77} INFO - Job 2564: Subtask download_dataset_task
[2024-03-30 09:02:11,975] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:02:12,089] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:02:12,140] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-07-02T06:00:00+00:00
[2024-03-30 09:02:12,142] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 09:02:12,143] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-07.parquet > /opt/***/yellowtaxi_tripdata_2022-07.parquet']
[2024-03-30 09:02:12,202] {subprocess.py:85} INFO - Output:
[2024-03-30 09:02:18,219] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 09:02:18,573] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220702T060000, start_date=20240330T090211, end_date=20240330T090218
[2024-03-30 09:02:18,776] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:02:19,148] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:31:08,907] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [queued]>
[2024-03-30 11:31:08,920] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [queued]>
[2024-03-30 11:31:08,921] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:31:08,921] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:31:08,921] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:31:08,932] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-07-02 06:00:00+00:00
[2024-03-30 11:31:08,938] {standard_task_runner.py:52} INFO - Started process 26653 to run task
[2024-03-30 11:31:08,942] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-07-02T06:00:00+00:00', '--job-id', '2793', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp7v4fmrqd', '--error-file', '/tmp/tmpbts0zp2v']
[2024-03-30 11:31:08,946] {standard_task_runner.py:77} INFO - Job 2793: Subtask download_dataset_task
[2024-03-30 11:31:09,008] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:31:09,049] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:31:09,073] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-07-02T06:00:00+00:00
[2024-03-30 11:31:09,075] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:31:09,076] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-07.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-07.parquet']
[2024-03-30 11:31:09,089] {subprocess.py:85} INFO - Output:
[2024-03-30 11:31:14,980] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:31:15,083] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220702T060000, start_date=20240330T113108, end_date=20240330T113115
[2024-03-30 11:31:15,165] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:31:15,207] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:51:56,412] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [queued]>
[2024-03-30 11:51:56,476] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [queued]>
[2024-03-30 11:51:56,478] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:51:56,485] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:51:56,485] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:51:56,547] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-07-02 06:00:00+00:00
[2024-03-30 11:51:56,582] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-07-02T06:00:00+00:00', '--job-id', '2870', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp4kmnduu5', '--error-file', '/tmp/tmpjelmyb2k']
[2024-03-30 11:51:56,592] {standard_task_runner.py:77} INFO - Job 2870: Subtask download_dataset_task
[2024-03-30 11:51:56,558] {standard_task_runner.py:52} INFO - Started process 28003 to run task
[2024-03-30 11:51:56,766] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:51:56,853] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:51:56,908] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-07-02T06:00:00+00:00
[2024-03-30 11:51:56,911] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:51:56,912] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-07.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-07.parquet']
[2024-03-30 11:51:56,962] {subprocess.py:85} INFO - Output:
[2024-03-30 11:52:01,382] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:52:01,452] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220702T060000, start_date=20240330T115156, end_date=20240330T115201
[2024-03-30 11:52:01,478] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:52:01,521] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:01:43,426] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:43,501] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:43,502] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:43,502] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:01:43,503] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:43,557] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-07-02 06:00:00+00:00
[2024-04-30 03:01:43,590] {standard_task_runner.py:52} INFO - Started process 840 to run task
[2024-04-30 03:01:43,636] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-07-02T06:00:00+00:00', '--job-id', '3173', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpdl3c65f4', '--error-file', '/tmp/tmp32u_fna5']
[2024-04-30 03:01:43,687] {standard_task_runner.py:77} INFO - Job 3173: Subtask download_dataset_task
[2024-04-30 03:01:44,078] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:01:44,290] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:01:44,367] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-07-02T06:00:00+00:00
[2024-04-30 03:01:44,369] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 03:01:44,370] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-07.parquet > /opt/***/cleaned_data/yellowtaxi_tripdata_2022-07.parquet']
[2024-04-30 03:01:44,443] {subprocess.py:85} INFO - Output:
[2024-04-30 03:01:48,819] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 03:01:49,209] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220702T060000, start_date=20240430T030143, end_date=20240430T030149
[2024-04-30 03:01:49,371] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:01:49,623] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:33:33,168] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [queued]>
[2024-04-30 04:33:33,204] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [queued]>
[2024-04-30 04:33:33,205] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:33:33,206] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:33:33,209] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:33:33,288] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-07-02 06:00:00+00:00
[2024-04-30 04:33:33,305] {standard_task_runner.py:52} INFO - Started process 5481 to run task
[2024-04-30 04:33:33,332] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-07-02T06:00:00+00:00', '--job-id', '3274', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpqpqw97q_', '--error-file', '/tmp/tmpe5r8y454']
[2024-04-30 04:33:33,339] {standard_task_runner.py:77} INFO - Job 3274: Subtask download_dataset_task
[2024-04-30 04:33:33,485] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-07-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:33:33,615] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:33:33,708] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-07-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-07-02T06:00:00+00:00
[2024-04-30 04:33:33,714] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 04:33:33,715] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-07.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-07.parquet']
[2024-04-30 04:33:33,740] {subprocess.py:85} INFO - Output:
[2024-04-30 04:33:37,736] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 04:33:38,157] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220702T060000, start_date=20240430T043333, end_date=20240430T043338
[2024-04-30 04:33:38,256] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 04:33:38,351] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
