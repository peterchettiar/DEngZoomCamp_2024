[2024-03-29 07:24:28,968] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:29,027] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:29,028] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:29,028] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:24:29,028] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:29,097] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-02-02 06:00:00+00:00
[2024-03-29 07:24:29,132] {standard_task_runner.py:52} INFO - Started process 515 to run task
[2024-03-29 07:24:29,201] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-02-02T06:00:00+00:00', '--job-id', '1447', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp94l0uizc', '--error-file', '/tmp/tmp1268wz68']
[2024-03-29 07:24:29,256] {standard_task_runner.py:77} INFO - Job 1447: Subtask download_dataset_task
[2024-03-29 07:24:29,908] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:24:30,068] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:24:30,131] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-02T06:00:00+00:00
[2024-03-29 07:24:30,135] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:24:30,138] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet > /opt/***/yellowtaxi_tripdata_2022-02.parquet']
[2024-03-29 07:24:30,209] {subprocess.py:85} INFO - Output:
[2024-03-29 07:24:36,095] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:24:36,189] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220202T060000, start_date=20240329T072428, end_date=20240329T072436
[2024-03-29 07:24:36,298] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:24:36,451] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:30:48,418] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-29 07:30:48,489] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-29 07:30:48,489] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:30:48,491] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:30:48,494] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:30:48,548] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-02-02 06:00:00+00:00
[2024-03-29 07:30:48,590] {standard_task_runner.py:52} INFO - Started process 1031 to run task
[2024-03-29 07:30:48,645] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-02-02T06:00:00+00:00', '--job-id', '1512', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpgekqmskh', '--error-file', '/tmp/tmpxdlw0454']
[2024-03-29 07:30:48,678] {standard_task_runner.py:77} INFO - Job 1512: Subtask download_dataset_task
[2024-03-29 07:30:49,038] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:30:49,126] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:30:49,179] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-02T06:00:00+00:00
[2024-03-29 07:30:49,182] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:30:49,183] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet > /opt/***/yellowtaxi_tripdata_2022-02.parquet']
[2024-03-29 07:30:49,226] {subprocess.py:85} INFO - Output:
[2024-03-29 07:30:55,385] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:30:55,572] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220202T060000, start_date=20240329T073048, end_date=20240329T073055
[2024-03-29 07:30:55,834] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:30:56,563] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:37:35,389] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:35,476] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:35,476] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:35,477] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:37:35,477] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:35,519] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-02-02 06:00:00+00:00
[2024-03-29 07:37:35,612] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-02-02T06:00:00+00:00', '--job-id', '1575', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpfye3bbxe', '--error-file', '/tmp/tmpb7w4r273']
[2024-03-29 07:37:35,644] {standard_task_runner.py:77} INFO - Job 1575: Subtask download_dataset_task
[2024-03-29 07:37:35,574] {standard_task_runner.py:52} INFO - Started process 1577 to run task
[2024-03-29 07:37:36,055] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:37:36,285] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:37:36,417] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-02T06:00:00+00:00
[2024-03-29 07:37:36,419] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:37:36,420] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet > /opt/***/yellowtaxi_tripdata_2022-02.parquet']
[2024-03-29 07:37:36,503] {subprocess.py:85} INFO - Output:
[2024-03-29 07:37:42,473] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:37:42,607] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220202T060000, start_date=20240329T073735, end_date=20240329T073742
[2024-03-29 07:37:42,792] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:37:42,949] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:08:30,883] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:30,907] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:30,907] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:30,907] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:08:30,907] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:30,924] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-02-02 06:00:00+00:00
[2024-03-29 08:08:30,942] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-02-02T06:00:00+00:00', '--job-id', '1637', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp0ql4uy2m', '--error-file', '/tmp/tmpp1magmf6']
[2024-03-29 08:08:30,934] {standard_task_runner.py:52} INFO - Started process 239 to run task
[2024-03-29 08:08:30,952] {standard_task_runner.py:77} INFO - Job 1637: Subtask download_dataset_task
[2024-03-29 08:08:31,063] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:08:31,123] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:08:31,155] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-02T06:00:00+00:00
[2024-03-29 08:08:31,157] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:08:31,158] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet > /opt/***/yellowtaxi_tripdata_2022-02.parquet']
[2024-03-29 08:08:31,182] {subprocess.py:85} INFO - Output:
[2024-03-29 08:08:36,956] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:08:37,167] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220202T060000, start_date=20240329T080830, end_date=20240329T080837
[2024-03-29 08:08:37,284] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:08:37,523] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:10:59,683] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-29 08:10:59,714] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-29 08:10:59,714] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:10:59,717] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:10:59,717] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:10:59,802] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-02-02 06:00:00+00:00
[2024-03-29 08:10:59,868] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-02-02T06:00:00+00:00', '--job-id', '1681', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpr9bft_7h', '--error-file', '/tmp/tmp4lyjxh3v']
[2024-03-29 08:10:59,876] {standard_task_runner.py:77} INFO - Job 1681: Subtask download_dataset_task
[2024-03-29 08:10:59,836] {standard_task_runner.py:52} INFO - Started process 521 to run task
[2024-03-29 08:11:00,245] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:11:00,383] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:11:00,479] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-02T06:00:00+00:00
[2024-03-29 08:11:00,480] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:11:00,481] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet > /opt/***/yellowtaxi_tripdata_2022-02.parquet']
[2024-03-29 08:11:00,524] {subprocess.py:85} INFO - Output:
[2024-03-29 08:11:06,560] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:11:07,241] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220202T060000, start_date=20240329T081059, end_date=20240329T081107
[2024-03-29 08:11:07,482] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:11:07,924] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:30:06,817] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:06,833] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:06,834] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:06,834] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:30:06,834] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:06,857] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-02-02 06:00:00+00:00
[2024-03-30 03:30:06,867] {standard_task_runner.py:52} INFO - Started process 473 to run task
[2024-03-30 03:30:06,897] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-02-02T06:00:00+00:00', '--job-id', '1827', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpsypcptd9', '--error-file', '/tmp/tmp43zk1v2b']
[2024-03-30 03:30:06,908] {standard_task_runner.py:77} INFO - Job 1827: Subtask download_dataset_task
[2024-03-30 03:30:07,003] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:30:07,056] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:30:07,087] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-02T06:00:00+00:00
[2024-03-30 03:30:07,088] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:30:07,090] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet > /opt/***/yellowtaxi_tripdata_2022-02.parquet']
[2024-03-30 03:30:07,108] {subprocess.py:85} INFO - Output:
[2024-03-30 03:30:12,815] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:30:12,950] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220202T060000, start_date=20240330T033006, end_date=20240330T033012
[2024-03-30 03:30:13,163] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:30:13,279] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:42:00,749] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-30 03:42:00,850] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-30 03:42:00,851] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:42:00,851] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:42:00,851] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:42:00,922] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-02-02 06:00:00+00:00
[2024-03-30 03:42:00,978] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-02-02T06:00:00+00:00', '--job-id', '1905', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp78juop6i', '--error-file', '/tmp/tmp9a1lmdcb']
[2024-03-30 03:42:01,007] {standard_task_runner.py:77} INFO - Job 1905: Subtask download_dataset_task
[2024-03-30 03:42:00,959] {standard_task_runner.py:52} INFO - Started process 1307 to run task
[2024-03-30 03:42:01,435] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:42:01,679] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:42:01,774] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-02T06:00:00+00:00
[2024-03-30 03:42:01,782] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:42:01,782] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet > /opt/***/yellowtaxi_tripdata_2022-02.parquet']
[2024-03-30 03:42:01,857] {subprocess.py:85} INFO - Output:
[2024-03-30 03:42:07,666] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:42:07,737] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220202T060000, start_date=20240330T034200, end_date=20240330T034207
[2024-03-30 03:42:07,860] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:42:08,360] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:18:11,486] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:11,551] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:11,551] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:11,551] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:18:11,551] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:11,630] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-02-02 06:00:00+00:00
[2024-03-30 04:18:11,646] {standard_task_runner.py:52} INFO - Started process 3560 to run task
[2024-03-30 04:18:11,691] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-02-02T06:00:00+00:00', '--job-id', '2086', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpv8er18us', '--error-file', '/tmp/tmpf7tc0jw9']
[2024-03-30 04:18:11,716] {standard_task_runner.py:77} INFO - Job 2086: Subtask download_dataset_task
[2024-03-30 04:18:11,997] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:18:12,148] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:18:12,223] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-02T06:00:00+00:00
[2024-03-30 04:18:12,225] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:18:12,226] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet > /opt/***/yellowtaxi_tripdata_2022-02.parquet']
[2024-03-30 04:18:12,273] {subprocess.py:85} INFO - Output:
[2024-03-30 04:18:18,511] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:18:18,774] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220202T060000, start_date=20240330T041811, end_date=20240330T041818
[2024-03-30 04:18:18,880] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:18:19,091] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:24:47,007] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-30 04:24:47,087] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-30 04:24:47,087] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:24:47,087] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:24:47,087] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:24:47,137] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-02-02 06:00:00+00:00
[2024-03-30 04:24:47,198] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-02-02T06:00:00+00:00', '--job-id', '2167', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpn3h4vf08', '--error-file', '/tmp/tmpkws6sbnl']
[2024-03-30 04:24:47,212] {standard_task_runner.py:77} INFO - Job 2167: Subtask download_dataset_task
[2024-03-30 04:24:47,173] {standard_task_runner.py:52} INFO - Started process 4180 to run task
[2024-03-30 04:24:47,364] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:24:47,475] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:24:47,516] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-02T06:00:00+00:00
[2024-03-30 04:24:47,517] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:24:47,518] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet > /opt/***/yellowtaxi_tripdata_2022-02.parquet']
[2024-03-30 04:24:47,568] {subprocess.py:85} INFO - Output:
[2024-03-30 04:24:53,456] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:24:53,601] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220202T060000, start_date=20240330T042447, end_date=20240330T042453
[2024-03-30 04:24:53,758] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:24:54,032] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:38:50,431] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-30 04:38:50,598] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-30 04:38:50,706] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:38:50,707] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:38:50,707] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:38:51,363] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-02-02 06:00:00+00:00
[2024-03-30 04:38:51,503] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-02-02T06:00:00+00:00', '--job-id', '2284', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpir1o1r1w', '--error-file', '/tmp/tmpiuqcrgmz']
[2024-03-30 04:38:51,553] {standard_task_runner.py:77} INFO - Job 2284: Subtask download_dataset_task
[2024-03-30 04:38:51,388] {standard_task_runner.py:52} INFO - Started process 5249 to run task
[2024-03-30 04:38:52,561] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:38:53,141] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:38:53,508] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-02T06:00:00+00:00
[2024-03-30 04:38:53,509] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:38:53,519] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet > /opt/***/yellowtaxi_tripdata_2022-02.parquet']
[2024-03-30 04:38:53,781] {subprocess.py:85} INFO - Output:
[2024-03-30 04:39:00,175] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:39:00,361] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220202T060000, start_date=20240330T043850, end_date=20240330T043900
[2024-03-30 04:39:00,431] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:39:01,063] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:59:27,864] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:27,917] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:27,917] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:27,917] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:59:27,918] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:27,978] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-02-02 06:00:00+00:00
[2024-03-30 04:59:28,016] {standard_task_runner.py:52} INFO - Started process 6638 to run task
[2024-03-30 04:59:28,030] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-02-02T06:00:00+00:00', '--job-id', '2413', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpudqy9sfg', '--error-file', '/tmp/tmp4wu7vw9t']
[2024-03-30 04:59:28,073] {standard_task_runner.py:77} INFO - Job 2413: Subtask download_dataset_task
[2024-03-30 04:59:28,427] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:59:28,833] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:59:28,917] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-02T06:00:00+00:00
[2024-03-30 04:59:28,929] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:59:28,929] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet > /opt/***/yellowtaxi_tripdata_2022-02.parquet']
[2024-03-30 04:59:29,047] {subprocess.py:85} INFO - Output:
[2024-03-30 04:59:34,909] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:59:35,050] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220202T060000, start_date=20240330T045927, end_date=20240330T045935
[2024-03-30 04:59:35,245] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:59:35,725] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:01:33,252] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:33,362] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:33,366] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:33,366] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:01:33,368] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:33,419] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-02-02 06:00:00+00:00
[2024-03-30 09:01:33,443] {standard_task_runner.py:52} INFO - Started process 18149 to run task
[2024-03-30 09:01:33,493] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-02-02T06:00:00+00:00', '--job-id', '2528', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp7i2ur15i', '--error-file', '/tmp/tmpwrecykiz']
[2024-03-30 09:01:33,510] {standard_task_runner.py:77} INFO - Job 2528: Subtask download_dataset_task
[2024-03-30 09:01:33,757] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:01:34,237] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:01:34,391] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-02T06:00:00+00:00
[2024-03-30 09:01:34,399] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 09:01:34,404] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet > /opt/***/yellowtaxi_tripdata_2022-02.parquet']
[2024-03-30 09:01:34,515] {subprocess.py:85} INFO - Output:
[2024-03-30 09:01:40,870] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 09:01:41,200] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220202T060000, start_date=20240330T090133, end_date=20240330T090141
[2024-03-30 09:01:41,333] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:01:41,900] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 10:50:04,939] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-30 10:50:05,054] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-30 10:50:05,055] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:50:05,055] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 10:50:05,055] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:50:05,089] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-02-02 06:00:00+00:00
[2024-03-30 10:50:05,098] {standard_task_runner.py:52} INFO - Started process 23505 to run task
[2024-03-30 10:50:05,141] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-02-02T06:00:00+00:00', '--job-id', '2640', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpwl0_xosd', '--error-file', '/tmp/tmpgi0446fk']
[2024-03-30 10:50:05,163] {standard_task_runner.py:77} INFO - Job 2640: Subtask download_dataset_task
[2024-03-30 10:50:05,404] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 10:50:05,478] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 10:50:05,518] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-02T06:00:00+00:00
[2024-03-30 10:50:05,520] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 10:50:05,521] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet > /opt/***raw_data/yellowtaxi_tripdata_2022-02.parquet']
[2024-03-30 10:50:05,542] {subprocess.py:85} INFO - Output:
[2024-03-30 10:50:05,548] {subprocess.py:89} INFO - bash: /opt/***raw_data/yellowtaxi_tripdata_2022-02.parquet: No such file or directory
[2024-03-30 10:50:05,550] {subprocess.py:93} INFO - Command exited with return code 1
[2024-03-30 10:50:05,744] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:50:05,759] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220202T060000, start_date=20240330T105004, end_date=20240330T105005
[2024-03-30 10:50:05,787] {standard_task_runner.py:92} ERROR - Failed to execute job 2640 for task download_dataset_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:50:05,828] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 10:50:05,912] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 10:54:57,119] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-30 10:54:57,151] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-30 10:54:57,151] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:54:57,152] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 10:54:57,152] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:54:57,189] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-02-02 06:00:00+00:00
[2024-03-30 10:54:57,220] {standard_task_runner.py:52} INFO - Started process 23813 to run task
[2024-03-30 10:54:57,225] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-02-02T06:00:00+00:00', '--job-id', '2656', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpm9vb85p9', '--error-file', '/tmp/tmp7mfcl79q']
[2024-03-30 10:54:57,244] {standard_task_runner.py:77} INFO - Job 2656: Subtask download_dataset_task
[2024-03-30 10:54:57,415] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 10:54:57,471] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 10:54:57,498] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-02T06:00:00+00:00
[2024-03-30 10:54:57,500] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 10:54:57,501] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet > /opt/***raw_data/yellowtaxi_tripdata_2022-02.parquet']
[2024-03-30 10:54:57,519] {subprocess.py:85} INFO - Output:
[2024-03-30 10:54:57,523] {subprocess.py:89} INFO - bash: /opt/***raw_data/yellowtaxi_tripdata_2022-02.parquet: No such file or directory
[2024-03-30 10:54:57,527] {subprocess.py:93} INFO - Command exited with return code 1
[2024-03-30 10:54:57,552] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:54:57,562] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220202T060000, start_date=20240330T105457, end_date=20240330T105457
[2024-03-30 10:54:57,580] {standard_task_runner.py:92} ERROR - Failed to execute job 2656 for task download_dataset_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:54:57,627] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 10:54:57,680] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:04:05,042] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-30 11:04:05,199] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-30 11:04:05,199] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:04:05,199] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:04:05,199] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:04:05,292] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-02-02 06:00:00+00:00
[2024-03-30 11:04:05,393] {standard_task_runner.py:52} INFO - Started process 24398 to run task
[2024-03-30 11:04:05,385] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-02-02T06:00:00+00:00', '--job-id', '2686', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp_tn3frpy', '--error-file', '/tmp/tmpndly7ibl']
[2024-03-30 11:04:05,459] {standard_task_runner.py:77} INFO - Job 2686: Subtask download_dataset_task
[2024-03-30 11:04:05,972] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:04:06,194] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:04:06,342] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-02T06:00:00+00:00
[2024-03-30 11:04:06,347] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:04:06,354] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-02.parquet']
[2024-03-30 11:04:06,527] {subprocess.py:85} INFO - Output:
[2024-03-30 11:04:12,489] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:04:12,827] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220202T060000, start_date=20240330T110405, end_date=20240330T110412
[2024-03-30 11:04:13,170] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:04:13,289] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:15:12,504] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-30 11:15:12,567] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-30 11:15:12,567] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:15:12,567] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:15:12,567] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:15:12,647] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-02-02 06:00:00+00:00
[2024-03-30 11:15:12,667] {standard_task_runner.py:52} INFO - Started process 25298 to run task
[2024-03-30 11:15:12,698] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-02-02T06:00:00+00:00', '--job-id', '2732', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpv6ho7b_1', '--error-file', '/tmp/tmp0njmy6rx']
[2024-03-30 11:15:12,722] {standard_task_runner.py:77} INFO - Job 2732: Subtask download_dataset_task
[2024-03-30 11:15:12,918] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:15:13,047] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:15:13,108] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-02T06:00:00+00:00
[2024-03-30 11:15:13,109] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:15:13,110] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-02.parquet']
[2024-03-30 11:15:13,159] {subprocess.py:85} INFO - Output:
[2024-03-30 11:15:18,976] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:15:19,471] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220202T060000, start_date=20240330T111512, end_date=20240330T111519
[2024-03-30 11:15:19,633] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:15:19,956] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:33:56,061] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-30 11:33:56,099] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-03-30 11:33:56,100] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:33:56,100] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:33:56,100] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:33:56,159] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-02-02 06:00:00+00:00
[2024-03-30 11:33:56,178] {standard_task_runner.py:52} INFO - Started process 26875 to run task
[2024-03-30 11:33:56,205] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-02-02T06:00:00+00:00', '--job-id', '2812', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmppr_ry4zi', '--error-file', '/tmp/tmpx4o4usm6']
[2024-03-30 11:33:56,228] {standard_task_runner.py:77} INFO - Job 2812: Subtask download_dataset_task
[2024-03-30 11:33:56,434] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:33:56,526] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:33:56,593] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-02T06:00:00+00:00
[2024-03-30 11:33:56,595] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:33:56,597] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-02.parquet']
[2024-03-30 11:33:56,646] {subprocess.py:85} INFO - Output:
[2024-03-30 11:34:02,727] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:34:02,884] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220202T060000, start_date=20240330T113356, end_date=20240330T113402
[2024-03-30 11:34:03,138] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:34:03,280] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-28 09:15:32,528] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:32,556] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:32,556] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:32,556] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-28 09:15:32,557] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:32,590] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-02-02 06:00:00+00:00
[2024-04-28 09:15:32,610] {standard_task_runner.py:52} INFO - Started process 1433 to run task
[2024-04-28 09:15:32,643] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-02-02T06:00:00+00:00', '--job-id', '3003', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpzv7tlxem', '--error-file', '/tmp/tmpmxstxzge']
[2024-04-28 09:15:32,661] {standard_task_runner.py:77} INFO - Job 3003: Subtask download_dataset_task
[2024-04-28 09:15:32,793] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [running]> on host 6c6a4ca9ff8e
[2024-04-28 09:15:32,878] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-28 09:15:32,953] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-02T06:00:00+00:00
[2024-04-28 09:15:32,955] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-28 09:15:32,956] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-02.parquet']
[2024-04-28 09:15:32,995] {subprocess.py:85} INFO - Output:
[2024-04-28 09:15:37,750] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-28 09:15:38,283] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220202T060000, start_date=20240428T091532, end_date=20240428T091538
[2024-04-28 09:15:38,843] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-28 09:15:39,385] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:13:48,861] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-04-30 02:13:48,895] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-04-30 02:13:48,895] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:13:48,895] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-30 02:13:48,896] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:13:48,939] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-02-02 06:00:00+00:00
[2024-04-30 02:13:48,968] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-02-02T06:00:00+00:00', '--job-id', '3039', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp03vdn4jl', '--error-file', '/tmp/tmpkqqfmm10']
[2024-04-30 02:13:48,956] {standard_task_runner.py:52} INFO - Started process 362 to run task
[2024-04-30 02:13:48,982] {standard_task_runner.py:77} INFO - Job 3039: Subtask download_dataset_task
[2024-04-30 02:13:49,083] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [running]> on host a1ae6a0259c5
[2024-04-30 02:13:49,139] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:13:49,170] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-02T06:00:00+00:00
[2024-04-30 02:13:49,174] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 02:13:49,175] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-02.parquet']
[2024-04-30 02:13:49,193] {subprocess.py:85} INFO - Output:
[2024-04-30 02:13:53,312] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 02:13:53,479] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220202T060000, start_date=20240430T021348, end_date=20240430T021353
[2024-04-30 02:13:53,678] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 02:13:54,256] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:58:13,607] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:13,659] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:13,659] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:13,659] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 02:58:13,659] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:13,698] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-02-02 06:00:00+00:00
[2024-04-30 02:58:13,725] {standard_task_runner.py:52} INFO - Started process 409 to run task
[2024-04-30 02:58:13,756] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-02-02T06:00:00+00:00', '--job-id', '3103', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpy15ir_iq', '--error-file', '/tmp/tmpt4uclh5w']
[2024-04-30 02:58:13,770] {standard_task_runner.py:77} INFO - Job 3103: Subtask download_dataset_task
[2024-04-30 02:58:13,910] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 02:58:13,986] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:58:14,040] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-02T06:00:00+00:00
[2024-04-30 02:58:14,042] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 02:58:14,045] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-02.parquet']
[2024-04-30 02:58:14,085] {subprocess.py:85} INFO - Output:
[2024-04-30 02:58:18,076] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 02:58:18,233] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220202T060000, start_date=20240430T025813, end_date=20240430T025818
[2024-04-30 02:58:18,324] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 02:58:18,727] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:01:08,560] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:08,701] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:08,701] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:08,701] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:01:08,701] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:08,796] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-02-02 06:00:00+00:00
[2024-04-30 03:01:08,885] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-02-02T06:00:00+00:00', '--job-id', '3137', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpag9olovf', '--error-file', '/tmp/tmpi1f4zxol']
[2024-04-30 03:01:08,904] {standard_task_runner.py:77} INFO - Job 3137: Subtask download_dataset_task
[2024-04-30 03:01:08,866] {standard_task_runner.py:52} INFO - Started process 680 to run task
[2024-04-30 03:01:09,223] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:01:09,445] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:01:09,533] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-02T06:00:00+00:00
[2024-04-30 03:01:09,544] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 03:01:09,547] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet > /opt/***/cleaned_data/yellowtaxi_tripdata_2022-02.parquet']
[2024-04-30 03:01:09,642] {subprocess.py:85} INFO - Output:
[2024-04-30 03:01:13,748] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 03:01:13,977] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220202T060000, start_date=20240430T030108, end_date=20240430T030113
[2024-04-30 03:01:14,243] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:01:14,397] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:30:04,954] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-04-30 04:30:05,021] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [queued]>
[2024-04-30 04:30:05,022] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:30:05,023] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:30:05,023] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:30:05,241] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-02-02 06:00:00+00:00
[2024-04-30 04:30:05,256] {standard_task_runner.py:52} INFO - Started process 5222 to run task
[2024-04-30 04:30:05,276] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-02-02T06:00:00+00:00', '--job-id', '3249', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpqwbdn96o', '--error-file', '/tmp/tmppzgs12ll']
[2024-04-30 04:30:05,293] {standard_task_runner.py:77} INFO - Job 3249: Subtask download_dataset_task
[2024-04-30 04:30:05,585] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-02-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:30:05,761] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:30:05,890] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-02T06:00:00+00:00
[2024-04-30 04:30:05,893] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 04:30:05,896] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-02.parquet']
[2024-04-30 04:30:05,974] {subprocess.py:85} INFO - Output:
[2024-04-30 04:30:10,227] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 04:30:11,079] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220202T060000, start_date=20240430T043004, end_date=20240430T043011
[2024-04-30 04:30:11,431] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 04:30:11,832] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
