[2024-03-29 07:24:31,683] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:31,704] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:31,713] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:31,713] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:24:31,713] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:31,777] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-03-02 06:00:00+00:00
[2024-03-29 07:24:31,802] {standard_task_runner.py:52} INFO - Started process 545 to run task
[2024-03-29 07:24:31,849] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '1452', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpeeno3et8', '--error-file', '/tmp/tmpumlit9ny']
[2024-03-29 07:24:31,876] {standard_task_runner.py:77} INFO - Job 1452: Subtask download_dataset_task
[2024-03-29 07:24:32,273] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:24:32,447] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:24:32,506] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-29 07:24:32,509] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:24:32,510] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet > /opt/***/yellowtaxi_tripdata_2022-03.parquet']
[2024-03-29 07:24:32,559] {subprocess.py:85} INFO - Output:
[2024-03-29 07:24:39,244] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:24:39,880] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220302T060000, start_date=20240329T072431, end_date=20240329T072439
[2024-03-29 07:24:39,992] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:24:40,128] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:30:49,217] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-29 07:30:49,263] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-29 07:30:49,267] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:30:49,268] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:30:49,269] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:30:49,301] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-03-02 06:00:00+00:00
[2024-03-29 07:30:49,312] {standard_task_runner.py:52} INFO - Started process 1044 to run task
[2024-03-29 07:30:49,340] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '1513', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmprk6v5xu_', '--error-file', '/tmp/tmp8swwn88x']
[2024-03-29 07:30:49,348] {standard_task_runner.py:77} INFO - Job 1513: Subtask download_dataset_task
[2024-03-29 07:30:49,472] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:30:49,549] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:30:49,594] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-29 07:30:49,596] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:30:49,597] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet > /opt/***/yellowtaxi_tripdata_2022-03.parquet']
[2024-03-29 07:30:49,631] {subprocess.py:85} INFO - Output:
[2024-03-29 07:30:56,558] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:30:56,780] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220302T060000, start_date=20240329T073049, end_date=20240329T073056
[2024-03-29 07:30:57,010] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:30:57,704] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:37:35,350] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:35,437] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:35,437] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:35,438] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:37:35,438] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:35,468] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-03-02 06:00:00+00:00
[2024-03-29 07:37:35,486] {standard_task_runner.py:52} INFO - Started process 1573 to run task
[2024-03-29 07:37:35,541] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '1577', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmplinvkkse', '--error-file', '/tmp/tmp2f7v49ti']
[2024-03-29 07:37:35,590] {standard_task_runner.py:77} INFO - Job 1577: Subtask download_dataset_task
[2024-03-29 07:37:35,911] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:37:36,186] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:37:36,249] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-29 07:37:36,251] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:37:36,252] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet > /opt/***/yellowtaxi_tripdata_2022-03.parquet']
[2024-03-29 07:37:36,331] {subprocess.py:85} INFO - Output:
[2024-03-29 07:37:43,091] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:37:43,786] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220302T060000, start_date=20240329T073735, end_date=20240329T073743
[2024-03-29 07:37:43,988] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:37:44,516] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:08:30,979] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:30,995] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:30,995] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:30,995] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:08:30,996] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:31,014] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-03-02 06:00:00+00:00
[2024-03-29 08:08:31,030] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '1638', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpr2ha6ftp', '--error-file', '/tmp/tmp40_6fawj']
[2024-03-29 08:08:31,024] {standard_task_runner.py:52} INFO - Started process 241 to run task
[2024-03-29 08:08:31,041] {standard_task_runner.py:77} INFO - Job 1638: Subtask download_dataset_task
[2024-03-29 08:08:31,150] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:08:31,207] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:08:31,234] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-29 08:08:31,236] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:08:31,237] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet > /opt/***/yellowtaxi_tripdata_2022-03.parquet']
[2024-03-29 08:08:31,255] {subprocess.py:85} INFO - Output:
[2024-03-29 08:08:37,871] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:08:38,327] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220302T060000, start_date=20240329T080830, end_date=20240329T080838
[2024-03-29 08:08:38,588] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:08:38,704] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:10:59,701] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-29 08:10:59,771] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-29 08:10:59,772] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:10:59,773] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:10:59,773] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:11:00,034] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-03-02 06:00:00+00:00
[2024-03-29 08:11:00,053] {standard_task_runner.py:52} INFO - Started process 523 to run task
[2024-03-29 08:11:00,072] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '1682', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpruuyajae', '--error-file', '/tmp/tmp3lslx57f']
[2024-03-29 08:11:00,091] {standard_task_runner.py:77} INFO - Job 1682: Subtask download_dataset_task
[2024-03-29 08:11:00,310] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:11:00,429] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:11:00,483] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-29 08:11:00,485] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:11:00,487] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet > /opt/***/yellowtaxi_tripdata_2022-03.parquet']
[2024-03-29 08:11:00,549] {subprocess.py:85} INFO - Output:
[2024-03-29 08:11:07,420] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:11:07,801] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220302T060000, start_date=20240329T081059, end_date=20240329T081107
[2024-03-29 08:11:08,167] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:11:08,517] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:30:07,022] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:07,043] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:07,043] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:07,044] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:30:07,044] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:07,059] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-03-02 06:00:00+00:00
[2024-03-30 03:30:07,067] {standard_task_runner.py:52} INFO - Started process 480 to run task
[2024-03-30 03:30:07,079] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '1828', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpiljel206', '--error-file', '/tmp/tmpy49nidcx']
[2024-03-30 03:30:07,084] {standard_task_runner.py:77} INFO - Job 1828: Subtask download_dataset_task
[2024-03-30 03:30:07,157] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:30:07,196] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:30:07,217] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-30 03:30:07,218] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:30:07,219] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet > /opt/***/yellowtaxi_tripdata_2022-03.parquet']
[2024-03-30 03:30:07,231] {subprocess.py:85} INFO - Output:
[2024-03-30 03:30:14,302] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:30:14,407] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220302T060000, start_date=20240330T033007, end_date=20240330T033014
[2024-03-30 03:30:14,489] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:30:14,944] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:42:02,173] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 03:42:02,211] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 03:42:02,211] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:42:02,211] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:42:02,211] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:42:02,276] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-03-02 06:00:00+00:00
[2024-03-30 03:42:02,286] {standard_task_runner.py:52} INFO - Started process 1316 to run task
[2024-03-30 03:42:02,307] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '1906', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpy6mrp19x', '--error-file', '/tmp/tmpfa_n6vrd']
[2024-03-30 03:42:02,335] {standard_task_runner.py:77} INFO - Job 1906: Subtask download_dataset_task
[2024-03-30 03:42:02,684] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:42:02,854] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:42:02,937] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-30 03:42:02,943] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:42:02,944] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet > /opt/***/yellowtaxi_tripdata_2022-03.parquet']
[2024-03-30 03:42:03,059] {subprocess.py:85} INFO - Output:
[2024-03-30 03:42:09,685] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:42:09,881] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220302T060000, start_date=20240330T034202, end_date=20240330T034209
[2024-03-30 03:42:10,028] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:42:10,125] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:18:10,141] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:10,322] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:10,323] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:10,323] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:18:10,323] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:10,465] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-03-02 06:00:00+00:00
[2024-03-30 04:18:10,550] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '2085', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpw451ku59', '--error-file', '/tmp/tmpdt5dfok5']
[2024-03-30 04:18:10,597] {standard_task_runner.py:77} INFO - Job 2085: Subtask download_dataset_task
[2024-03-30 04:18:10,538] {standard_task_runner.py:52} INFO - Started process 3547 to run task
[2024-03-30 04:18:11,138] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:18:11,315] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:18:11,393] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-30 04:18:11,394] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:18:11,395] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet > /opt/***/yellowtaxi_tripdata_2022-03.parquet']
[2024-03-30 04:18:11,438] {subprocess.py:85} INFO - Output:
[2024-03-30 04:18:18,742] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:18:18,836] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220302T060000, start_date=20240330T041810, end_date=20240330T041818
[2024-03-30 04:18:18,983] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:18:19,461] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:24:47,135] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:24:47,166] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:24:47,166] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:24:47,167] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:24:47,167] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:24:47,187] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-03-02 06:00:00+00:00
[2024-03-30 04:24:47,206] {standard_task_runner.py:52} INFO - Started process 4181 to run task
[2024-03-30 04:24:47,238] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '2168', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmppxn76nja', '--error-file', '/tmp/tmp1tsd6kre']
[2024-03-30 04:24:47,257] {standard_task_runner.py:77} INFO - Job 2168: Subtask download_dataset_task
[2024-03-30 04:24:47,437] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:24:47,560] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:24:47,620] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-30 04:24:47,623] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:24:47,624] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet > /opt/***/yellowtaxi_tripdata_2022-03.parquet']
[2024-03-30 04:24:47,683] {subprocess.py:85} INFO - Output:
[2024-03-30 04:24:54,339] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:24:54,460] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220302T060000, start_date=20240330T042447, end_date=20240330T042454
[2024-03-30 04:24:54,702] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:24:54,951] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:38:43,766] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:38:43,849] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:38:43,850] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:38:43,850] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:38:43,850] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:38:43,877] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-03-02 06:00:00+00:00
[2024-03-30 04:38:43,898] {standard_task_runner.py:52} INFO - Started process 5210 to run task
[2024-03-30 04:38:43,997] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '2277', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpm2_wuc7b', '--error-file', '/tmp/tmphkk1lgtk']
[2024-03-30 04:38:44,031] {standard_task_runner.py:77} INFO - Job 2277: Subtask download_dataset_task
[2024-03-30 04:38:44,229] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:38:44,356] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:38:44,484] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-30 04:38:44,487] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:38:44,487] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet > /opt/***/yellowtaxi_tripdata_2022-03.parquet']
[2024-03-30 04:38:44,855] {subprocess.py:85} INFO - Output:
[2024-03-30 04:38:52,139] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:38:52,822] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220302T060000, start_date=20240330T043843, end_date=20240330T043852
[2024-03-30 04:38:53,195] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:38:53,776] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:59:29,322] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:29,420] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:29,420] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:29,420] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:59:29,421] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:29,487] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-03-02 06:00:00+00:00
[2024-03-30 04:59:29,521] {standard_task_runner.py:52} INFO - Started process 6646 to run task
[2024-03-30 04:59:29,584] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '2414', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpe9g5vykn', '--error-file', '/tmp/tmpub36o179']
[2024-03-30 04:59:29,622] {standard_task_runner.py:77} INFO - Job 2414: Subtask download_dataset_task
[2024-03-30 04:59:30,154] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:59:30,348] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:59:30,425] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-30 04:59:30,426] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:59:30,442] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet > /opt/***/yellowtaxi_tripdata_2022-03.parquet']
[2024-03-30 04:59:30,537] {subprocess.py:85} INFO - Output:
[2024-03-30 04:59:37,120] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:59:37,229] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220302T060000, start_date=20240330T045929, end_date=20240330T045937
[2024-03-30 04:59:37,460] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:59:37,639] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:01:32,739] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:32,847] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:32,850] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:32,851] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:01:32,854] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:32,905] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-03-02 06:00:00+00:00
[2024-03-30 09:01:32,970] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '2526', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpzuecfulp', '--error-file', '/tmp/tmpee8tl3x0']
[2024-03-30 09:01:32,997] {standard_task_runner.py:77} INFO - Job 2526: Subtask download_dataset_task
[2024-03-30 09:01:32,918] {standard_task_runner.py:52} INFO - Started process 18141 to run task
[2024-03-30 09:01:33,473] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:01:33,681] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:01:33,777] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-30 09:01:33,785] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 09:01:33,786] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet > /opt/***/yellowtaxi_tripdata_2022-03.parquet']
[2024-03-30 09:01:33,967] {subprocess.py:85} INFO - Output:
[2024-03-30 09:01:40,905] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 09:01:41,201] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220302T060000, start_date=20240330T090132, end_date=20240330T090141
[2024-03-30 09:01:41,398] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:01:41,850] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 10:50:04,380] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 10:50:04,448] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 10:50:04,448] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:50:04,448] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 10:50:04,448] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:50:04,552] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-03-02 06:00:00+00:00
[2024-03-30 10:50:04,599] {standard_task_runner.py:52} INFO - Started process 23498 to run task
[2024-03-30 10:50:04,631] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '2637', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmplz_j0agn', '--error-file', '/tmp/tmparff8f93']
[2024-03-30 10:50:04,645] {standard_task_runner.py:77} INFO - Job 2637: Subtask download_dataset_task
[2024-03-30 10:50:04,803] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 10:50:04,900] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 10:50:05,007] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-30 10:50:05,008] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 10:50:05,010] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet > /opt/***raw_data/yellowtaxi_tripdata_2022-03.parquet']
[2024-03-30 10:50:05,077] {subprocess.py:85} INFO - Output:
[2024-03-30 10:50:05,101] {subprocess.py:89} INFO - bash: /opt/***raw_data/yellowtaxi_tripdata_2022-03.parquet: No such file or directory
[2024-03-30 10:50:05,102] {subprocess.py:93} INFO - Command exited with return code 1
[2024-03-30 10:50:05,146] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:50:05,184] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220302T060000, start_date=20240330T105004, end_date=20240330T105005
[2024-03-30 10:50:05,226] {standard_task_runner.py:92} ERROR - Failed to execute job 2637 for task download_dataset_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:50:05,287] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 10:50:05,796] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 10:54:56,480] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 10:54:56,547] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 10:54:56,548] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:54:56,548] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 10:54:56,549] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:54:56,613] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-03-02 06:00:00+00:00
[2024-03-30 10:54:56,665] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '2655', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp8rcsfua5', '--error-file', '/tmp/tmp5dmhbfsd']
[2024-03-30 10:54:56,691] {standard_task_runner.py:77} INFO - Job 2655: Subtask download_dataset_task
[2024-03-30 10:54:56,656] {standard_task_runner.py:52} INFO - Started process 23806 to run task
[2024-03-30 10:54:56,885] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 10:54:56,964] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 10:54:56,998] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-30 10:54:57,000] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 10:54:57,001] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet > /opt/***raw_data/yellowtaxi_tripdata_2022-03.parquet']
[2024-03-30 10:54:57,029] {subprocess.py:85} INFO - Output:
[2024-03-30 10:54:57,034] {subprocess.py:89} INFO - bash: /opt/***raw_data/yellowtaxi_tripdata_2022-03.parquet: No such file or directory
[2024-03-30 10:54:57,043] {subprocess.py:93} INFO - Command exited with return code 1
[2024-03-30 10:54:57,122] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:54:57,142] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220302T060000, start_date=20240330T105456, end_date=20240330T105457
[2024-03-30 10:54:57,186] {standard_task_runner.py:92} ERROR - Failed to execute job 2655 for task download_dataset_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:54:57,252] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 10:54:57,354] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:04:08,640] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 11:04:08,798] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 11:04:08,807] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:04:08,820] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:04:08,821] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:04:08,979] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-03-02 06:00:00+00:00
[2024-03-30 11:04:09,050] {standard_task_runner.py:52} INFO - Started process 24421 to run task
[2024-03-30 11:04:09,084] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '2691', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpewru3tn8', '--error-file', '/tmp/tmptm0wsivl']
[2024-03-30 11:04:09,123] {standard_task_runner.py:77} INFO - Job 2691: Subtask download_dataset_task
[2024-03-30 11:04:09,285] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:04:09,417] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:04:09,508] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-30 11:04:09,510] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:04:09,516] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-03.parquet']
[2024-03-30 11:04:09,678] {subprocess.py:85} INFO - Output:
[2024-03-30 11:04:16,879] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:04:17,185] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220302T060000, start_date=20240330T110408, end_date=20240330T110417
[2024-03-30 11:04:17,475] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:04:18,649] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:15:13,853] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 11:15:13,911] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 11:15:13,911] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:15:13,911] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:15:13,911] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:15:13,996] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-03-02 06:00:00+00:00
[2024-03-30 11:15:14,019] {standard_task_runner.py:52} INFO - Started process 25310 to run task
[2024-03-30 11:15:14,095] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '2735', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpesfkicp7', '--error-file', '/tmp/tmpfqigcwjw']
[2024-03-30 11:15:14,102] {standard_task_runner.py:77} INFO - Job 2735: Subtask download_dataset_task
[2024-03-30 11:15:14,245] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:15:14,364] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:15:14,461] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-30 11:15:14,463] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:15:14,465] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-03.parquet']
[2024-03-30 11:15:14,599] {subprocess.py:85} INFO - Output:
[2024-03-30 11:15:21,467] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:15:21,708] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220302T060000, start_date=20240330T111513, end_date=20240330T111521
[2024-03-30 11:15:22,019] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:15:22,210] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:33:55,794] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 11:33:55,838] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 11:33:55,839] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:33:55,841] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:33:55,841] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:33:55,875] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-03-02 06:00:00+00:00
[2024-03-30 11:33:55,890] {standard_task_runner.py:52} INFO - Started process 26871 to run task
[2024-03-30 11:33:55,914] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '2809', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp54evj5z1', '--error-file', '/tmp/tmpkk3tcqt1']
[2024-03-30 11:33:55,921] {standard_task_runner.py:77} INFO - Job 2809: Subtask download_dataset_task
[2024-03-30 11:33:56,106] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:33:56,230] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:33:56,316] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-30 11:33:56,318] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:33:56,324] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-03.parquet']
[2024-03-30 11:33:56,414] {subprocess.py:85} INFO - Output:
[2024-03-30 11:34:03,224] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:34:03,355] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220302T060000, start_date=20240330T113355, end_date=20240330T113403
[2024-03-30 11:34:03,552] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:34:04,042] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-04-28 09:15:32,525] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:32,552] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:32,552] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:32,553] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-28 09:15:32,553] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:32,589] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-03-02 06:00:00+00:00
[2024-04-28 09:15:32,601] {standard_task_runner.py:52} INFO - Started process 1432 to run task
[2024-04-28 09:15:32,618] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '3002', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpkm6rzmq6', '--error-file', '/tmp/tmp2_sefqgm']
[2024-04-28 09:15:32,629] {standard_task_runner.py:77} INFO - Job 3002: Subtask download_dataset_task
[2024-04-28 09:15:32,766] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host 6c6a4ca9ff8e
[2024-04-28 09:15:32,913] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-28 09:15:32,990] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-04-28 09:15:32,991] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-28 09:15:32,992] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-03.parquet']
[2024-04-28 09:15:33,040] {subprocess.py:85} INFO - Output:
[2024-04-28 09:15:38,205] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-28 09:15:38,338] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220302T060000, start_date=20240428T091532, end_date=20240428T091538
[2024-04-28 09:15:38,838] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-28 09:15:39,533] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:13:48,854] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-04-30 02:13:48,876] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-04-30 02:13:48,876] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:13:48,877] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-30 02:13:48,877] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:13:48,907] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-03-02 06:00:00+00:00
[2024-04-30 02:13:48,915] {standard_task_runner.py:52} INFO - Started process 360 to run task
[2024-04-30 02:13:48,924] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '3037', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpctsb40z5', '--error-file', '/tmp/tmpcujax39y']
[2024-04-30 02:13:48,935] {standard_task_runner.py:77} INFO - Job 3037: Subtask download_dataset_task
[2024-04-30 02:13:49,042] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host a1ae6a0259c5
[2024-04-30 02:13:49,096] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:13:49,131] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-04-30 02:13:49,132] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 02:13:49,133] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-03.parquet']
[2024-04-30 02:13:49,155] {subprocess.py:85} INFO - Output:
[2024-04-30 02:13:53,826] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 02:13:54,193] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220302T060000, start_date=20240430T021348, end_date=20240430T021354
[2024-04-30 02:13:54,296] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 02:13:54,447] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:58:14,078] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:14,120] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:14,120] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:14,121] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 02:58:14,121] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:14,152] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-03-02 06:00:00+00:00
[2024-04-30 02:58:14,166] {standard_task_runner.py:52} INFO - Started process 419 to run task
[2024-04-30 02:58:14,206] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '3105', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpxcq6ujpe', '--error-file', '/tmp/tmp5qkt_ipc']
[2024-04-30 02:58:14,224] {standard_task_runner.py:77} INFO - Job 3105: Subtask download_dataset_task
[2024-04-30 02:58:14,436] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 02:58:14,656] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:58:14,745] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-04-30 02:58:14,747] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 02:58:14,749] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-03.parquet']
[2024-04-30 02:58:14,770] {subprocess.py:85} INFO - Output:
[2024-04-30 02:58:19,121] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 02:58:20,192] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220302T060000, start_date=20240430T025814, end_date=20240430T025820
[2024-04-30 02:58:20,305] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 02:58:20,411] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:01:08,561] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:08,732] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:08,734] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:08,742] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:01:08,743] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:08,928] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-03-02 06:00:00+00:00
[2024-04-30 03:01:09,046] {standard_task_runner.py:52} INFO - Started process 682 to run task
[2024-04-30 03:01:09,096] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '3135', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpnkf8qwwi', '--error-file', '/tmp/tmp0gdzodhu']
[2024-04-30 03:01:09,140] {standard_task_runner.py:77} INFO - Job 3135: Subtask download_dataset_task
[2024-04-30 03:01:09,557] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:01:09,696] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:01:09,787] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-04-30 03:01:09,789] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 03:01:09,790] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet > /opt/***/cleaned_data/yellowtaxi_tripdata_2022-03.parquet']
[2024-04-30 03:01:09,878] {subprocess.py:85} INFO - Output:
[2024-04-30 03:01:14,651] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 03:01:14,740] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220302T060000, start_date=20240430T030108, end_date=20240430T030114
[2024-04-30 03:01:14,803] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:01:14,903] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:30:04,942] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-04-30 04:30:05,036] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-04-30 04:30:05,042] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:30:05,043] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:30:05,043] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:30:05,239] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2022-03-02 06:00:00+00:00
[2024-04-30 04:30:05,252] {standard_task_runner.py:52} INFO - Started process 5221 to run task
[2024-04-30 04:30:05,279] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '3251', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpm6oes683', '--error-file', '/tmp/tmptaahinud']
[2024-04-30 04:30:05,299] {standard_task_runner.py:77} INFO - Job 3251: Subtask download_dataset_task
[2024-04-30 04:30:05,589] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:30:05,790] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:30:05,855] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-04-30 04:30:05,857] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 04:30:05,859] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2022-03.parquet']
[2024-04-30 04:30:05,922] {subprocess.py:85} INFO - Output:
[2024-04-30 04:30:11,904] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 04:30:12,598] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20220302T060000, start_date=20240430T043004, end_date=20240430T043012
[2024-04-30 04:30:12,826] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 04:30:12,987] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
