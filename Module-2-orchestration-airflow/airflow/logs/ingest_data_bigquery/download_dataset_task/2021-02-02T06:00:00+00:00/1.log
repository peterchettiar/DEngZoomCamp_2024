[2024-03-29 07:24:26,658] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:26,708] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:26,712] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:26,713] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:24:26,715] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:26,772] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-02-02 06:00:00+00:00
[2024-03-29 07:24:26,806] {standard_task_runner.py:52} INFO - Started process 480 to run task
[2024-03-29 07:24:26,831] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-02-02T06:00:00+00:00', '--job-id', '1441', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpe1fr5bx2', '--error-file', '/tmp/tmp8w9d2sez']
[2024-03-29 07:24:26,880] {standard_task_runner.py:77} INFO - Job 1441: Subtask download_dataset_task
[2024-03-29 07:24:27,194] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:24:27,429] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:24:27,544] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-02-02T06:00:00+00:00
[2024-03-29 07:24:27,548] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:24:27,549] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet > /opt/***/yellowtaxi_tripdata_2021-02.parquet']
[2024-03-29 07:24:27,630] {subprocess.py:85} INFO - Output:
[2024-03-29 07:24:31,583] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:24:31,653] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210202T060000, start_date=20240329T072426, end_date=20240329T072431
[2024-03-29 07:24:31,705] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:24:31,824] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:30:42,341] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-29 07:30:42,531] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-29 07:30:42,548] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:30:42,549] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:30:42,549] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:30:42,625] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-02-02 06:00:00+00:00
[2024-03-29 07:30:42,677] {standard_task_runner.py:52} INFO - Started process 970 to run task
[2024-03-29 07:30:42,738] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-02-02T06:00:00+00:00', '--job-id', '1500', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp2ajjx90d', '--error-file', '/tmp/tmpjd_vpr47']
[2024-03-29 07:30:42,788] {standard_task_runner.py:77} INFO - Job 1500: Subtask download_dataset_task
[2024-03-29 07:30:43,046] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:30:43,269] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:30:43,386] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-02-02T06:00:00+00:00
[2024-03-29 07:30:43,390] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:30:43,401] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet > /opt/***/yellowtaxi_tripdata_2021-02.parquet']
[2024-03-29 07:30:43,513] {subprocess.py:85} INFO - Output:
[2024-03-29 07:30:47,615] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:30:47,722] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210202T060000, start_date=20240329T073042, end_date=20240329T073047
[2024-03-29 07:30:47,866] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:30:48,038] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:37:24,292] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:24,343] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:24,346] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:24,348] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:37:24,349] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:24,403] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-02-02 06:00:00+00:00
[2024-03-29 07:37:24,424] {standard_task_runner.py:52} INFO - Started process 1488 to run task
[2024-03-29 07:37:24,437] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-02-02T06:00:00+00:00', '--job-id', '1562', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpfwf_cccw', '--error-file', '/tmp/tmp11zq9tqp']
[2024-03-29 07:37:24,462] {standard_task_runner.py:77} INFO - Job 1562: Subtask download_dataset_task
[2024-03-29 07:37:24,688] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:37:24,786] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:37:24,880] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-02-02T06:00:00+00:00
[2024-03-29 07:37:24,886] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:37:24,887] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet > /opt/***/yellowtaxi_tripdata_2021-02.parquet']
[2024-03-29 07:37:24,976] {subprocess.py:85} INFO - Output:
[2024-03-29 07:37:29,009] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:37:29,395] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210202T060000, start_date=20240329T073724, end_date=20240329T073729
[2024-03-29 07:37:29,662] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:37:30,308] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:08:28,273] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:28,358] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:28,358] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:28,359] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:08:28,359] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:28,429] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-02-02 06:00:00+00:00
[2024-03-29 08:08:28,464] {standard_task_runner.py:52} INFO - Started process 192 to run task
[2024-03-29 08:08:28,539] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-02-02T06:00:00+00:00', '--job-id', '1627', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmplmtivxk1', '--error-file', '/tmp/tmpwt0wk6vh']
[2024-03-29 08:08:28,581] {standard_task_runner.py:77} INFO - Job 1627: Subtask download_dataset_task
[2024-03-29 08:08:29,059] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:08:29,268] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:08:29,396] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-02-02T06:00:00+00:00
[2024-03-29 08:08:29,398] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:08:29,399] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet > /opt/***/yellowtaxi_tripdata_2021-02.parquet']
[2024-03-29 08:08:29,514] {subprocess.py:85} INFO - Output:
[2024-03-29 08:08:33,469] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:08:33,548] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210202T060000, start_date=20240329T080828, end_date=20240329T080833
[2024-03-29 08:08:33,617] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:08:33,688] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:10:50,137] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-29 08:10:50,220] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-29 08:10:50,221] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:10:50,222] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:10:50,223] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:10:50,284] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-02-02 06:00:00+00:00
[2024-03-29 08:10:50,324] {standard_task_runner.py:52} INFO - Started process 449 to run task
[2024-03-29 08:10:50,363] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-02-02T06:00:00+00:00', '--job-id', '1668', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp1jmdp9ca', '--error-file', '/tmp/tmpz14xq2tb']
[2024-03-29 08:10:50,386] {standard_task_runner.py:77} INFO - Job 1668: Subtask download_dataset_task
[2024-03-29 08:10:50,703] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:10:50,884] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:10:51,018] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-02-02T06:00:00+00:00
[2024-03-29 08:10:51,019] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:10:51,020] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet > /opt/***/yellowtaxi_tripdata_2021-02.parquet']
[2024-03-29 08:10:51,161] {subprocess.py:85} INFO - Output:
[2024-03-29 08:10:55,445] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:10:55,549] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210202T060000, start_date=20240329T081050, end_date=20240329T081055
[2024-03-29 08:10:55,629] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:10:55,772] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:30:03,885] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:03,942] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:03,942] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:03,951] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:30:03,953] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:04,019] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-02-02 06:00:00+00:00
[2024-03-30 03:30:04,077] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-02-02T06:00:00+00:00', '--job-id', '1819', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpicgsrrb1', '--error-file', '/tmp/tmp5k0k51ry']
[2024-03-30 03:30:04,108] {standard_task_runner.py:77} INFO - Job 1819: Subtask download_dataset_task
[2024-03-30 03:30:04,060] {standard_task_runner.py:52} INFO - Started process 428 to run task
[2024-03-30 03:30:04,739] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:30:05,173] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:30:05,321] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-02-02T06:00:00+00:00
[2024-03-30 03:30:05,323] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:30:05,328] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet > /opt/***/yellowtaxi_tripdata_2021-02.parquet']
[2024-03-30 03:30:05,445] {subprocess.py:85} INFO - Output:
[2024-03-30 03:30:09,854] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:30:10,216] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210202T060000, start_date=20240330T033003, end_date=20240330T033010
[2024-03-30 03:30:10,302] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:30:10,424] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:41:52,915] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-30 03:41:52,980] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-30 03:41:52,987] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:41:52,987] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:41:52,988] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:41:53,033] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-02-02 06:00:00+00:00
[2024-03-30 03:41:53,060] {standard_task_runner.py:52} INFO - Started process 1239 to run task
[2024-03-30 03:41:53,089] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-02-02T06:00:00+00:00', '--job-id', '1893', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpxxz6mfwp', '--error-file', '/tmp/tmppyzlodk2']
[2024-03-30 03:41:53,119] {standard_task_runner.py:77} INFO - Job 1893: Subtask download_dataset_task
[2024-03-30 03:41:53,379] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:41:53,577] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:41:53,650] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-02-02T06:00:00+00:00
[2024-03-30 03:41:53,651] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:41:53,652] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet > /opt/***/yellowtaxi_tripdata_2021-02.parquet']
[2024-03-30 03:41:53,737] {subprocess.py:85} INFO - Output:
[2024-03-30 03:41:57,777] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:41:57,884] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210202T060000, start_date=20240330T034152, end_date=20240330T034157
[2024-03-30 03:41:58,003] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:41:58,587] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:17:57,840] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-30 04:17:57,911] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-30 04:17:57,912] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:17:57,912] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:17:57,913] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:17:57,963] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-02-02 06:00:00+00:00
[2024-03-30 04:17:57,993] {standard_task_runner.py:52} INFO - Started process 3467 to run task
[2024-03-30 04:17:58,067] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-02-02T06:00:00+00:00', '--job-id', '2073', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpj38zb26o', '--error-file', '/tmp/tmpxs7gj115']
[2024-03-30 04:17:58,095] {standard_task_runner.py:77} INFO - Job 2073: Subtask download_dataset_task
[2024-03-30 04:17:58,392] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:17:58,601] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:17:58,716] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-02-02T06:00:00+00:00
[2024-03-30 04:17:58,717] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:17:58,722] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet > /opt/***/yellowtaxi_tripdata_2021-02.parquet']
[2024-03-30 04:17:58,849] {subprocess.py:85} INFO - Output:
[2024-03-30 04:18:02,922] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:18:03,337] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210202T060000, start_date=20240330T041757, end_date=20240330T041803
[2024-03-30 04:18:03,521] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:18:04,036] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:24:38,130] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-30 04:24:38,211] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-30 04:24:38,222] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:24:38,223] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:24:38,230] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:24:38,295] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-02-02 06:00:00+00:00
[2024-03-30 04:24:38,348] {standard_task_runner.py:52} INFO - Started process 4111 to run task
[2024-03-30 04:24:38,397] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-02-02T06:00:00+00:00', '--job-id', '2154', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpw_jcg16y', '--error-file', '/tmp/tmp0pe1s1kc']
[2024-03-30 04:24:38,427] {standard_task_runner.py:77} INFO - Job 2154: Subtask download_dataset_task
[2024-03-30 04:24:38,710] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:24:38,989] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:24:39,152] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-02-02T06:00:00+00:00
[2024-03-30 04:24:39,159] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:24:39,169] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet > /opt/***/yellowtaxi_tripdata_2021-02.parquet']
[2024-03-30 04:24:39,315] {subprocess.py:85} INFO - Output:
[2024-03-30 04:24:43,358] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:24:43,605] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210202T060000, start_date=20240330T042438, end_date=20240330T042443
[2024-03-30 04:24:43,776] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:24:44,245] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:38:35,181] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-30 04:38:35,212] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-30 04:38:35,212] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:38:35,213] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:38:35,213] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:38:35,246] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-02-02 06:00:00+00:00
[2024-03-30 04:38:35,262] {standard_task_runner.py:52} INFO - Started process 5176 to run task
[2024-03-30 04:38:35,299] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-02-02T06:00:00+00:00', '--job-id', '2270', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp3aeyanf3', '--error-file', '/tmp/tmphuvck_nw']
[2024-03-30 04:38:35,304] {standard_task_runner.py:77} INFO - Job 2270: Subtask download_dataset_task
[2024-03-30 04:38:35,487] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:38:35,944] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:38:36,161] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-02-02T06:00:00+00:00
[2024-03-30 04:38:36,162] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:38:36,163] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet > /opt/***/yellowtaxi_tripdata_2021-02.parquet']
[2024-03-30 04:38:36,243] {subprocess.py:85} INFO - Output:
[2024-03-30 04:38:40,747] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:38:40,919] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210202T060000, start_date=20240330T043835, end_date=20240330T043840
[2024-03-30 04:38:41,037] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:38:41,148] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:59:18,697] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:18,735] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:18,735] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:18,735] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:59:18,735] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:18,780] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-02-02 06:00:00+00:00
[2024-03-30 04:59:18,838] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-02-02T06:00:00+00:00', '--job-id', '2401', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmphh3u876k', '--error-file', '/tmp/tmpns82q_3b']
[2024-03-30 04:59:18,864] {standard_task_runner.py:77} INFO - Job 2401: Subtask download_dataset_task
[2024-03-30 04:59:18,807] {standard_task_runner.py:52} INFO - Started process 6561 to run task
[2024-03-30 04:59:19,125] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:59:19,201] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:59:19,274] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-02-02T06:00:00+00:00
[2024-03-30 04:59:19,276] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:59:19,278] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet > /opt/***/yellowtaxi_tripdata_2021-02.parquet']
[2024-03-30 04:59:19,338] {subprocess.py:85} INFO - Output:
[2024-03-30 04:59:23,424] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:59:23,585] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210202T060000, start_date=20240330T045918, end_date=20240330T045923
[2024-03-30 04:59:23,758] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:59:23,965] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:01:23,034] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:23,159] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:23,161] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:23,161] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:01:23,162] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:23,239] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-02-02 06:00:00+00:00
[2024-03-30 09:01:23,257] {standard_task_runner.py:52} INFO - Started process 18070 to run task
[2024-03-30 09:01:23,342] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-02-02T06:00:00+00:00', '--job-id', '2515', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp7r5ixv3p', '--error-file', '/tmp/tmpqkym0uhc']
[2024-03-30 09:01:23,382] {standard_task_runner.py:77} INFO - Job 2515: Subtask download_dataset_task
[2024-03-30 09:01:23,857] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:01:24,124] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:01:24,269] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-02-02T06:00:00+00:00
[2024-03-30 09:01:24,271] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 09:01:24,272] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet > /opt/***/yellowtaxi_tripdata_2021-02.parquet']
[2024-03-30 09:01:24,349] {subprocess.py:85} INFO - Output:
[2024-03-30 09:01:28,418] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 09:01:28,749] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210202T060000, start_date=20240330T090123, end_date=20240330T090128
[2024-03-30 09:01:28,939] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:01:29,029] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 10:49:57,300] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-30 10:49:57,411] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-30 10:49:57,411] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:49:57,412] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 10:49:57,412] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:49:57,523] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-02-02 06:00:00+00:00
[2024-03-30 10:49:57,573] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-02-02T06:00:00+00:00', '--job-id', '2627', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpxitqzf30', '--error-file', '/tmp/tmp20c4lhse']
[2024-03-30 10:49:57,603] {standard_task_runner.py:77} INFO - Job 2627: Subtask download_dataset_task
[2024-03-30 10:49:57,564] {standard_task_runner.py:52} INFO - Started process 23460 to run task
[2024-03-30 10:49:57,862] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 10:49:58,142] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 10:49:58,287] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-02-02T06:00:00+00:00
[2024-03-30 10:49:58,289] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 10:49:58,290] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet > /opt/***raw_data/yellowtaxi_tripdata_2021-02.parquet']
[2024-03-30 10:49:58,402] {subprocess.py:85} INFO - Output:
[2024-03-30 10:49:58,467] {subprocess.py:89} INFO - bash: /opt/***raw_data/yellowtaxi_tripdata_2021-02.parquet: No such file or directory
[2024-03-30 10:49:58,470] {subprocess.py:93} INFO - Command exited with return code 1
[2024-03-30 10:49:58,565] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:49:58,612] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210202T060000, start_date=20240330T104957, end_date=20240330T104958
[2024-03-30 10:49:58,686] {standard_task_runner.py:92} ERROR - Failed to execute job 2627 for task download_dataset_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:49:58,755] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 10:49:58,841] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 10:54:50,100] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-30 10:54:50,150] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-30 10:54:50,151] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:54:50,151] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 10:54:50,152] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:54:50,248] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-02-02 06:00:00+00:00
[2024-03-30 10:54:50,305] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-02-02T06:00:00+00:00', '--job-id', '2643', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmppj77g213', '--error-file', '/tmp/tmpz7fhlnu2']
[2024-03-30 10:54:50,334] {standard_task_runner.py:77} INFO - Job 2643: Subtask download_dataset_task
[2024-03-30 10:54:50,266] {standard_task_runner.py:52} INFO - Started process 23749 to run task
[2024-03-30 10:54:50,569] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 10:54:50,748] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 10:54:50,842] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-02-02T06:00:00+00:00
[2024-03-30 10:54:50,844] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 10:54:50,845] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet > /opt/***raw_data/yellowtaxi_tripdata_2021-02.parquet']
[2024-03-30 10:54:50,919] {subprocess.py:85} INFO - Output:
[2024-03-30 10:54:50,940] {subprocess.py:89} INFO - bash: /opt/***raw_data/yellowtaxi_tripdata_2021-02.parquet: No such file or directory
[2024-03-30 10:54:50,942] {subprocess.py:93} INFO - Command exited with return code 1
[2024-03-30 10:54:51,068] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:54:51,091] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210202T060000, start_date=20240330T105450, end_date=20240330T105451
[2024-03-30 10:54:51,184] {standard_task_runner.py:92} ERROR - Failed to execute job 2643 for task download_dataset_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:54:51,287] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 10:54:51,815] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:03:52,196] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-30 11:03:52,267] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-30 11:03:52,274] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:03:52,275] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:03:52,276] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:03:52,323] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-02-02 06:00:00+00:00
[2024-03-30 11:03:52,348] {standard_task_runner.py:52} INFO - Started process 24306 to run task
[2024-03-30 11:03:52,411] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-02-02T06:00:00+00:00', '--job-id', '2673', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp3egq1ljl', '--error-file', '/tmp/tmpzniiejnf']
[2024-03-30 11:03:52,455] {standard_task_runner.py:77} INFO - Job 2673: Subtask download_dataset_task
[2024-03-30 11:03:52,661] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:03:52,790] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:03:52,872] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-02-02T06:00:00+00:00
[2024-03-30 11:03:52,874] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:03:52,876] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-02.parquet']
[2024-03-30 11:03:52,915] {subprocess.py:85} INFO - Output:
[2024-03-30 11:03:56,799] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:03:56,971] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210202T060000, start_date=20240330T110352, end_date=20240330T110356
[2024-03-30 11:03:57,158] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:03:58,002] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:15:02,552] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-30 11:15:02,591] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-30 11:15:02,591] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:15:02,592] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:15:02,592] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:15:02,646] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-02-02 06:00:00+00:00
[2024-03-30 11:15:02,707] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-02-02T06:00:00+00:00', '--job-id', '2720', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpjgb1z3a4', '--error-file', '/tmp/tmpdh167imf']
[2024-03-30 11:15:02,683] {standard_task_runner.py:52} INFO - Started process 25215 to run task
[2024-03-30 11:15:02,742] {standard_task_runner.py:77} INFO - Job 2720: Subtask download_dataset_task
[2024-03-30 11:15:02,892] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:15:02,985] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:15:03,067] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-02-02T06:00:00+00:00
[2024-03-30 11:15:03,068] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:15:03,069] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-02.parquet']
[2024-03-30 11:15:03,124] {subprocess.py:85} INFO - Output:
[2024-03-30 11:15:07,215] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:15:07,646] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210202T060000, start_date=20240330T111502, end_date=20240330T111507
[2024-03-30 11:15:07,714] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:15:07,903] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:33:43,255] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-30 11:33:43,339] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-03-30 11:33:43,340] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:33:43,340] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:33:43,340] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:33:43,410] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-02-02 06:00:00+00:00
[2024-03-30 11:33:43,435] {standard_task_runner.py:52} INFO - Started process 26793 to run task
[2024-03-30 11:33:43,470] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-02-02T06:00:00+00:00', '--job-id', '2796', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp8f39a_ox', '--error-file', '/tmp/tmpi_wb0j3j']
[2024-03-30 11:33:43,492] {standard_task_runner.py:77} INFO - Job 2796: Subtask download_dataset_task
[2024-03-30 11:33:43,739] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:33:43,937] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:33:44,015] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-02-02T06:00:00+00:00
[2024-03-30 11:33:44,016] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:33:44,017] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-02.parquet']
[2024-03-30 11:33:44,138] {subprocess.py:85} INFO - Output:
[2024-03-30 11:33:48,168] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:33:49,584] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210202T060000, start_date=20240330T113343, end_date=20240330T113349
[2024-03-30 11:33:49,748] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:33:49,842] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-28 09:15:29,797] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:29,951] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:29,951] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:29,951] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-28 09:15:29,951] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:30,180] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-02-02 06:00:00+00:00
[2024-04-28 09:15:30,296] {standard_task_runner.py:52} INFO - Started process 1385 to run task
[2024-04-28 09:15:30,408] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-02-02T06:00:00+00:00', '--job-id', '2995', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpikqete3_', '--error-file', '/tmp/tmpj2renie9']
[2024-04-28 09:15:30,464] {standard_task_runner.py:77} INFO - Job 2995: Subtask download_dataset_task
[2024-04-28 09:15:30,778] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [running]> on host 6c6a4ca9ff8e
[2024-04-28 09:15:31,078] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-28 09:15:31,256] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-02-02T06:00:00+00:00
[2024-04-28 09:15:31,257] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-28 09:15:31,257] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-02.parquet']
[2024-04-28 09:15:31,394] {subprocess.py:85} INFO - Output:
[2024-04-28 09:15:34,519] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-28 09:15:34,583] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210202T060000, start_date=20240428T091529, end_date=20240428T091534
[2024-04-28 09:15:34,693] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-28 09:15:34,754] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:13:46,970] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-04-30 02:13:47,049] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-04-30 02:13:47,065] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:13:47,065] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-30 02:13:47,066] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:13:47,105] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-02-02 06:00:00+00:00
[2024-04-30 02:13:47,120] {standard_task_runner.py:52} INFO - Started process 315 to run task
[2024-04-30 02:13:47,210] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-02-02T06:00:00+00:00', '--job-id', '3034', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp6ji96k0r', '--error-file', '/tmp/tmpmu5s007m']
[2024-04-30 02:13:47,246] {standard_task_runner.py:77} INFO - Job 3034: Subtask download_dataset_task
[2024-04-30 02:13:47,653] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [running]> on host a1ae6a0259c5
[2024-04-30 02:13:47,854] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:13:47,953] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-02-02T06:00:00+00:00
[2024-04-30 02:13:47,957] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 02:13:47,958] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-02.parquet']
[2024-04-30 02:13:48,004] {subprocess.py:85} INFO - Output:
[2024-04-30 02:13:51,329] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 02:13:51,389] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210202T060000, start_date=20240430T021346, end_date=20240430T021351
[2024-04-30 02:13:51,467] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 02:13:51,527] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:58:11,104] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:11,145] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:11,146] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:11,147] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 02:58:11,147] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:11,238] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-02-02 06:00:00+00:00
[2024-04-30 02:58:11,247] {standard_task_runner.py:52} INFO - Started process 365 to run task
[2024-04-30 02:58:11,271] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-02-02T06:00:00+00:00', '--job-id', '3094', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp9s3qb7ip', '--error-file', '/tmp/tmpb2gtsmvu']
[2024-04-30 02:58:11,282] {standard_task_runner.py:77} INFO - Job 3094: Subtask download_dataset_task
[2024-04-30 02:58:11,459] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 02:58:11,633] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:58:11,759] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-02-02T06:00:00+00:00
[2024-04-30 02:58:11,761] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 02:58:11,761] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-02.parquet']
[2024-04-30 02:58:11,856] {subprocess.py:85} INFO - Output:
[2024-04-30 02:58:14,579] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 02:58:14,777] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210202T060000, start_date=20240430T025811, end_date=20240430T025814
[2024-04-30 02:58:14,897] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 02:58:14,988] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:00:59,363] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-04-30 03:00:59,432] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-04-30 03:00:59,433] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:00:59,434] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:00:59,434] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:00:59,501] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-02-02 06:00:00+00:00
[2024-04-30 03:00:59,546] {standard_task_runner.py:52} INFO - Started process 622 to run task
[2024-04-30 03:00:59,577] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-02-02T06:00:00+00:00', '--job-id', '3124', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpx6czryq9', '--error-file', '/tmp/tmpiw1er1f3']
[2024-04-30 03:00:59,613] {standard_task_runner.py:77} INFO - Job 3124: Subtask download_dataset_task
[2024-04-30 03:00:59,918] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:01:00,100] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:01:00,241] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-02-02T06:00:00+00:00
[2024-04-30 03:01:00,243] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 03:01:00,244] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet > /opt/***/cleaned_data/yellowtaxi_tripdata_2021-02.parquet']
[2024-04-30 03:01:00,357] {subprocess.py:85} INFO - Output:
[2024-04-30 03:01:03,189] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 03:01:03,321] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210202T060000, start_date=20240430T030059, end_date=20240430T030103
[2024-04-30 03:01:03,450] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:01:03,576] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:29:55,513] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-04-30 04:29:55,550] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [queued]>
[2024-04-30 04:29:55,553] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:29:55,554] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:29:55,555] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:29:55,726] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-02-02 06:00:00+00:00
[2024-04-30 04:29:55,770] {standard_task_runner.py:52} INFO - Started process 5151 to run task
[2024-04-30 04:29:55,817] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-02-02T06:00:00+00:00', '--job-id', '3237', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpmvtlb3f4', '--error-file', '/tmp/tmp6m5mrb91']
[2024-04-30 04:29:55,890] {standard_task_runner.py:77} INFO - Job 3237: Subtask download_dataset_task
[2024-04-30 04:29:56,266] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-02-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:29:56,808] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:29:56,962] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-02-02T06:00:00+00:00
[2024-04-30 04:29:56,964] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 04:29:56,970] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-02.parquet']
[2024-04-30 04:29:57,098] {subprocess.py:85} INFO - Output:
[2024-04-30 04:30:00,048] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 04:30:00,153] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210202T060000, start_date=20240430T042955, end_date=20240430T043000
[2024-04-30 04:30:00,213] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 04:30:00,296] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
