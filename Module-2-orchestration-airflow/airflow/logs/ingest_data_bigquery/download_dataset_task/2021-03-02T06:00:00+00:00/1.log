[2024-03-29 07:24:26,704] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:26,751] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:26,756] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:26,756] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:24:26,757] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:26,849] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-03-02 06:00:00+00:00
[2024-03-29 07:24:26,892] {standard_task_runner.py:52} INFO - Started process 482 to run task
[2024-03-29 07:24:26,934] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '1443', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpu1k7gxcr', '--error-file', '/tmp/tmpriirkixx']
[2024-03-29 07:24:26,958] {standard_task_runner.py:77} INFO - Job 1443: Subtask download_dataset_task
[2024-03-29 07:24:27,227] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:24:27,387] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:24:27,446] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-29 07:24:27,448] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:24:27,449] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet > /opt/***/yellowtaxi_tripdata_2021-03.parquet']
[2024-03-29 07:24:27,495] {subprocess.py:85} INFO - Output:
[2024-03-29 07:24:32,213] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:24:32,596] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210302T060000, start_date=20240329T072426, end_date=20240329T072432
[2024-03-29 07:24:32,796] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:24:33,732] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:30:43,001] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-29 07:30:43,072] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-29 07:30:43,072] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:30:43,072] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:30:43,072] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:30:43,094] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-03-02 06:00:00+00:00
[2024-03-29 07:30:43,117] {standard_task_runner.py:52} INFO - Started process 972 to run task
[2024-03-29 07:30:43,143] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '1501', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp1zp9xl33', '--error-file', '/tmp/tmp7ouf04va']
[2024-03-29 07:30:43,181] {standard_task_runner.py:77} INFO - Job 1501: Subtask download_dataset_task
[2024-03-29 07:30:43,548] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:30:43,772] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:30:43,874] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-29 07:30:43,876] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:30:43,877] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet > /opt/***/yellowtaxi_tripdata_2021-03.parquet']
[2024-03-29 07:30:44,011] {subprocess.py:85} INFO - Output:
[2024-03-29 07:30:51,098] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:30:51,193] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210302T060000, start_date=20240329T073043, end_date=20240329T073051
[2024-03-29 07:30:51,271] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:30:51,453] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:37:24,786] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:24,826] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:24,827] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:24,828] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:37:24,832] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:24,882] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-03-02 06:00:00+00:00
[2024-03-29 07:37:24,892] {standard_task_runner.py:52} INFO - Started process 1493 to run task
[2024-03-29 07:37:24,918] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '1564', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpk60g06d9', '--error-file', '/tmp/tmpy7nfjeun']
[2024-03-29 07:37:24,938] {standard_task_runner.py:77} INFO - Job 1564: Subtask download_dataset_task
[2024-03-29 07:37:25,092] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:37:25,226] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 07:37:25,318] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-29 07:37:25,330] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 07:37:25,337] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet > /opt/***/yellowtaxi_tripdata_2021-03.parquet']
[2024-03-29 07:37:25,457] {subprocess.py:85} INFO - Output:
[2024-03-29 07:37:30,009] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 07:37:30,218] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210302T060000, start_date=20240329T073724, end_date=20240329T073730
[2024-03-29 07:37:30,403] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 07:37:31,044] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:08:27,917] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:27,996] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-29 08:08:27,997] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:27,997] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:08:27,997] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:08:28,090] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-03-02 06:00:00+00:00
[2024-03-29 08:08:28,148] {standard_task_runner.py:52} INFO - Started process 190 to run task
[2024-03-29 08:08:28,212] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '1625', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp2rjbh7_n', '--error-file', '/tmp/tmpair5egt8']
[2024-03-29 08:08:28,240] {standard_task_runner.py:77} INFO - Job 1625: Subtask download_dataset_task
[2024-03-29 08:08:28,683] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:08:28,967] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:08:29,136] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-29 08:08:29,143] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:08:29,144] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet > /opt/***/yellowtaxi_tripdata_2021-03.parquet']
[2024-03-29 08:08:29,249] {subprocess.py:85} INFO - Output:
[2024-03-29 08:08:33,814] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:08:33,864] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210302T060000, start_date=20240329T080827, end_date=20240329T080833
[2024-03-29 08:08:33,904] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:08:33,957] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:10:53,382] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-29 08:10:53,534] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-29 08:10:53,534] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:10:53,535] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:10:53,548] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:10:53,811] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-03-02 06:00:00+00:00
[2024-03-29 08:10:53,863] {standard_task_runner.py:52} INFO - Started process 471 to run task
[2024-03-29 08:10:53,950] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '1672', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpb2rt7viy', '--error-file', '/tmp/tmp5vr1_h9m']
[2024-03-29 08:10:53,986] {standard_task_runner.py:77} INFO - Job 1672: Subtask download_dataset_task
[2024-03-29 08:10:54,514] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:10:54,796] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:10:54,988] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-29 08:10:54,991] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:10:55,019] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet > /opt/***/yellowtaxi_tripdata_2021-03.parquet']
[2024-03-29 08:10:55,178] {subprocess.py:85} INFO - Output:
[2024-03-29 08:10:59,997] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:11:00,106] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210302T060000, start_date=20240329T081053, end_date=20240329T081100
[2024-03-29 08:11:00,237] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:11:00,328] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:30:03,825] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:03,960] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:03,960] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:03,960] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:30:03,961] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:04,131] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-03-02 06:00:00+00:00
[2024-03-30 03:30:04,262] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '1818', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp4rx6jixk', '--error-file', '/tmp/tmp15hd4dtb']
[2024-03-30 03:30:04,316] {standard_task_runner.py:77} INFO - Job 1818: Subtask download_dataset_task
[2024-03-30 03:30:04,250] {standard_task_runner.py:52} INFO - Started process 431 to run task
[2024-03-30 03:30:04,889] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:30:05,290] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:30:05,364] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-30 03:30:05,365] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:30:05,366] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet > /opt/***/yellowtaxi_tripdata_2021-03.parquet']
[2024-03-30 03:30:05,448] {subprocess.py:85} INFO - Output:
[2024-03-30 03:30:10,045] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:30:10,221] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210302T060000, start_date=20240330T033003, end_date=20240330T033010
[2024-03-30 03:30:10,317] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:30:10,427] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:41:53,698] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 03:41:53,758] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 03:41:53,758] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:41:53,759] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:41:53,759] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:41:53,824] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-03-02 06:00:00+00:00
[2024-03-30 03:41:53,877] {standard_task_runner.py:52} INFO - Started process 1245 to run task
[2024-03-30 03:41:53,903] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '1894', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpwbuvoic4', '--error-file', '/tmp/tmpetlcx5mp']
[2024-03-30 03:41:53,937] {standard_task_runner.py:77} INFO - Job 1894: Subtask download_dataset_task
[2024-03-30 03:41:54,161] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:41:54,272] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:41:54,350] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-30 03:41:54,351] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:41:54,353] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet > /opt/***/yellowtaxi_tripdata_2021-03.parquet']
[2024-03-30 03:41:54,402] {subprocess.py:85} INFO - Output:
[2024-03-30 03:41:58,975] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:41:59,294] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210302T060000, start_date=20240330T034153, end_date=20240330T034159
[2024-03-30 03:41:59,344] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:41:59,451] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:17:58,255] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:17:58,345] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:17:58,345] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:17:58,346] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:17:58,351] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:17:58,411] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-03-02 06:00:00+00:00
[2024-03-30 04:17:58,428] {standard_task_runner.py:52} INFO - Started process 3472 to run task
[2024-03-30 04:17:58,525] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '2074', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp68vj7olq', '--error-file', '/tmp/tmpotj5f_fd']
[2024-03-30 04:17:58,584] {standard_task_runner.py:77} INFO - Job 2074: Subtask download_dataset_task
[2024-03-30 04:17:59,072] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:17:59,245] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:17:59,304] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-30 04:17:59,306] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:17:59,307] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet > /opt/***/yellowtaxi_tripdata_2021-03.parquet']
[2024-03-30 04:17:59,393] {subprocess.py:85} INFO - Output:
[2024-03-30 04:18:04,497] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:18:04,601] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210302T060000, start_date=20240330T041758, end_date=20240330T041804
[2024-03-30 04:18:04,825] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:18:04,927] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:24:39,287] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:24:39,400] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:24:39,404] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:24:39,408] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:24:39,411] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:24:39,468] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-03-02 06:00:00+00:00
[2024-03-30 04:24:39,519] {standard_task_runner.py:52} INFO - Started process 4118 to run task
[2024-03-30 04:24:39,555] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '2156', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp04y5x9rl', '--error-file', '/tmp/tmpqwqegzk9']
[2024-03-30 04:24:39,596] {standard_task_runner.py:77} INFO - Job 2156: Subtask download_dataset_task
[2024-03-30 04:24:40,027] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:24:40,732] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:24:40,860] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-30 04:24:40,862] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:24:40,869] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet > /opt/***/yellowtaxi_tripdata_2021-03.parquet']
[2024-03-30 04:24:40,932] {subprocess.py:85} INFO - Output:
[2024-03-30 04:24:45,467] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:24:45,568] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210302T060000, start_date=20240330T042439, end_date=20240330T042445
[2024-03-30 04:24:45,644] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:24:45,736] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:38:43,789] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:38:44,019] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:38:44,020] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:38:44,020] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:38:44,020] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:38:44,262] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-03-02 06:00:00+00:00
[2024-03-30 04:38:44,424] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '2278', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpbj5d60_a', '--error-file', '/tmp/tmpbg31hf23']
[2024-03-30 04:38:44,446] {standard_task_runner.py:77} INFO - Job 2278: Subtask download_dataset_task
[2024-03-30 04:38:44,393] {standard_task_runner.py:52} INFO - Started process 5212 to run task
[2024-03-30 04:38:44,797] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:38:45,401] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:38:45,480] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-30 04:38:45,481] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:38:45,483] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet > /opt/***/yellowtaxi_tripdata_2021-03.parquet']
[2024-03-30 04:38:45,787] {subprocess.py:85} INFO - Output:
[2024-03-30 04:38:51,047] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:38:51,701] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210302T060000, start_date=20240330T043843, end_date=20240330T043851
[2024-03-30 04:38:52,171] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:38:53,025] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:59:22,445] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:22,486] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:22,487] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:22,488] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:59:22,488] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:22,521] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-03-02 06:00:00+00:00
[2024-03-30 04:59:22,553] {standard_task_runner.py:52} INFO - Started process 6584 to run task
[2024-03-30 04:59:22,600] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '2403', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpqcswpv47', '--error-file', '/tmp/tmpvddoa7t1']
[2024-03-30 04:59:22,646] {standard_task_runner.py:77} INFO - Job 2403: Subtask download_dataset_task
[2024-03-30 04:59:23,445] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:59:23,555] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:59:23,744] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-30 04:59:23,746] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:59:23,747] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet > /opt/***/yellowtaxi_tripdata_2021-03.parquet']
[2024-03-30 04:59:23,837] {subprocess.py:85} INFO - Output:
[2024-03-30 04:59:28,492] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:59:28,622] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210302T060000, start_date=20240330T045922, end_date=20240330T045928
[2024-03-30 04:59:28,899] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:59:29,490] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:01:24,248] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:24,386] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:24,387] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:24,387] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:01:24,387] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:24,487] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-03-02 06:00:00+00:00
[2024-03-30 09:01:24,559] {standard_task_runner.py:52} INFO - Started process 18080 to run task
[2024-03-30 09:01:24,646] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '2516', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp8zsb2ksx', '--error-file', '/tmp/tmpeggqotvq']
[2024-03-30 09:01:24,686] {standard_task_runner.py:77} INFO - Job 2516: Subtask download_dataset_task
[2024-03-30 09:01:25,085] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:01:25,336] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:01:25,413] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-30 09:01:25,416] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 09:01:25,417] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet > /opt/***/yellowtaxi_tripdata_2021-03.parquet']
[2024-03-30 09:01:25,511] {subprocess.py:85} INFO - Output:
[2024-03-30 09:01:31,113] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 09:01:31,295] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210302T060000, start_date=20240330T090124, end_date=20240330T090131
[2024-03-30 09:01:31,389] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:01:31,512] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 10:49:58,548] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 10:49:58,664] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 10:49:58,671] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:49:58,671] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 10:49:58,673] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:49:58,807] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-03-02 06:00:00+00:00
[2024-03-30 10:49:58,866] {standard_task_runner.py:52} INFO - Started process 23466 to run task
[2024-03-30 10:49:58,921] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '2629', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpbehm6sdm', '--error-file', '/tmp/tmpyqtoe7o9']
[2024-03-30 10:49:59,001] {standard_task_runner.py:77} INFO - Job 2629: Subtask download_dataset_task
[2024-03-30 10:49:59,214] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 10:49:59,308] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 10:49:59,404] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-30 10:49:59,406] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 10:49:59,407] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet > /opt/***raw_data/yellowtaxi_tripdata_2021-03.parquet']
[2024-03-30 10:49:59,475] {subprocess.py:85} INFO - Output:
[2024-03-30 10:49:59,495] {subprocess.py:89} INFO - bash: /opt/***raw_data/yellowtaxi_tripdata_2021-03.parquet: No such file or directory
[2024-03-30 10:49:59,499] {subprocess.py:93} INFO - Command exited with return code 1
[2024-03-30 10:49:59,550] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:49:59,588] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210302T060000, start_date=20240330T104958, end_date=20240330T104959
[2024-03-30 10:49:59,617] {standard_task_runner.py:92} ERROR - Failed to execute job 2629 for task download_dataset_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:49:59,667] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 10:49:59,828] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 10:54:50,621] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 10:54:50,678] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 10:54:50,682] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:54:50,690] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 10:54:50,690] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 10:54:50,750] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-03-02 06:00:00+00:00
[2024-03-30 10:54:50,798] {standard_task_runner.py:52} INFO - Started process 23751 to run task
[2024-03-30 10:54:50,861] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '2644', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmppmo1btyo', '--error-file', '/tmp/tmp_aebszbk']
[2024-03-30 10:54:50,886] {standard_task_runner.py:77} INFO - Job 2644: Subtask download_dataset_task
[2024-03-30 10:54:51,059] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 10:54:51,178] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 10:54:51,274] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-30 10:54:51,283] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 10:54:51,291] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet > /opt/***raw_data/yellowtaxi_tripdata_2021-03.parquet']
[2024-03-30 10:54:51,386] {subprocess.py:85} INFO - Output:
[2024-03-30 10:54:51,423] {subprocess.py:89} INFO - bash: /opt/***raw_data/yellowtaxi_tripdata_2021-03.parquet: No such file or directory
[2024-03-30 10:54:51,424] {subprocess.py:93} INFO - Command exited with return code 1
[2024-03-30 10:54:51,722] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:54:51,735] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210302T060000, start_date=20240330T105450, end_date=20240330T105451
[2024-03-30 10:54:51,773] {standard_task_runner.py:92} ERROR - Failed to execute job 2644 for task download_dataset_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/bash.py", line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-03-30 10:54:51,846] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 10:54:52,379] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:03:52,951] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 11:03:52,983] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 11:03:52,984] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:03:52,985] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:03:52,985] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:03:53,023] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-03-02 06:00:00+00:00
[2024-03-30 11:03:53,032] {standard_task_runner.py:52} INFO - Started process 24315 to run task
[2024-03-30 11:03:53,049] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '2675', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpdi3_04f0', '--error-file', '/tmp/tmp63x35den']
[2024-03-30 11:03:53,079] {standard_task_runner.py:77} INFO - Job 2675: Subtask download_dataset_task
[2024-03-30 11:03:53,213] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:03:53,285] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:03:53,341] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-30 11:03:53,344] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:03:53,350] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-03.parquet']
[2024-03-30 11:03:53,421] {subprocess.py:85} INFO - Output:
[2024-03-30 11:03:57,966] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:03:58,225] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210302T060000, start_date=20240330T110352, end_date=20240330T110358
[2024-03-30 11:03:58,305] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:03:58,451] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:15:03,715] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 11:15:03,747] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 11:15:03,748] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:15:03,748] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:15:03,749] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:15:03,769] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-03-02 06:00:00+00:00
[2024-03-30 11:15:03,778] {standard_task_runner.py:52} INFO - Started process 25226 to run task
[2024-03-30 11:15:03,797] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '2721', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpfubxtak6', '--error-file', '/tmp/tmp454mmgyy']
[2024-03-30 11:15:03,804] {standard_task_runner.py:77} INFO - Job 2721: Subtask download_dataset_task
[2024-03-30 11:15:04,132] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:15:04,305] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:15:04,379] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-30 11:15:04,380] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:15:04,381] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-03.parquet']
[2024-03-30 11:15:04,423] {subprocess.py:85} INFO - Output:
[2024-03-30 11:15:09,011] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:15:09,111] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210302T060000, start_date=20240330T111503, end_date=20240330T111509
[2024-03-30 11:15:09,212] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:15:09,368] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:33:45,381] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 11:33:45,486] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-03-30 11:33:45,487] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:33:45,487] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:33:45,488] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:33:45,589] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-03-02 06:00:00+00:00
[2024-03-30 11:33:45,659] {standard_task_runner.py:52} INFO - Started process 26809 to run task
[2024-03-30 11:33:45,666] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '2797', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpktfqw_u0', '--error-file', '/tmp/tmpnfrjp9xe']
[2024-03-30 11:33:45,747] {standard_task_runner.py:77} INFO - Job 2797: Subtask download_dataset_task
[2024-03-30 11:33:46,172] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:33:46,811] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:33:47,191] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-03-30 11:33:47,194] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:33:47,219] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-03.parquet']
[2024-03-30 11:33:47,432] {subprocess.py:85} INFO - Output:
[2024-03-30 11:33:52,268] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:33:52,411] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210302T060000, start_date=20240330T113345, end_date=20240330T113352
[2024-03-30 11:33:52,637] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:33:52,798] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-28 09:15:29,756] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:29,899] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-04-28 09:15:29,910] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:29,911] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-28 09:15:29,912] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-28 09:15:30,047] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-03-02 06:00:00+00:00
[2024-04-28 09:15:30,188] {standard_task_runner.py:52} INFO - Started process 1380 to run task
[2024-04-28 09:15:30,270] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '2994', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpb3mij_59', '--error-file', '/tmp/tmpj6zkbo2e']
[2024-04-28 09:15:30,382] {standard_task_runner.py:77} INFO - Job 2994: Subtask download_dataset_task
[2024-04-28 09:15:30,781] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 6c6a4ca9ff8e
[2024-04-28 09:15:31,097] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-28 09:15:31,202] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-04-28 09:15:31,203] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-28 09:15:31,203] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-03.parquet']
[2024-04-28 09:15:31,283] {subprocess.py:85} INFO - Output:
[2024-04-28 09:15:34,815] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-28 09:15:34,905] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210302T060000, start_date=20240428T091529, end_date=20240428T091534
[2024-04-28 09:15:34,990] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-28 09:15:35,845] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:13:46,717] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-04-30 02:13:46,785] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-04-30 02:13:46,788] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:13:46,791] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-04-30 02:13:46,791] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:13:46,855] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-03-02 06:00:00+00:00
[2024-04-30 02:13:46,879] {standard_task_runner.py:52} INFO - Started process 307 to run task
[2024-04-30 02:13:46,940] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '3025', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp60xmm5j4', '--error-file', '/tmp/tmplx4cb6b7']
[2024-04-30 02:13:47,006] {standard_task_runner.py:77} INFO - Job 3025: Subtask download_dataset_task
[2024-04-30 02:13:47,341] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host a1ae6a0259c5
[2024-04-30 02:13:47,633] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:13:47,873] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-04-30 02:13:47,874] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 02:13:47,880] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-03.parquet']
[2024-04-30 02:13:47,941] {subprocess.py:85} INFO - Output:
[2024-04-30 02:13:51,451] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 02:13:51,507] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210302T060000, start_date=20240430T021346, end_date=20240430T021351
[2024-04-30 02:13:51,583] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 02:13:51,645] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 02:58:11,755] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:11,910] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-04-30 02:58:11,910] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:11,910] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 02:58:11,911] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 02:58:12,006] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-03-02 06:00:00+00:00
[2024-04-30 02:58:12,070] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '3096', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpzti1nbzh', '--error-file', '/tmp/tmpm6y1am5h']
[2024-04-30 02:58:12,054] {standard_task_runner.py:52} INFO - Started process 377 to run task
[2024-04-30 02:58:12,105] {standard_task_runner.py:77} INFO - Job 3096: Subtask download_dataset_task
[2024-04-30 02:58:12,357] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 02:58:12,577] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 02:58:12,676] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-04-30 02:58:12,678] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 02:58:12,679] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-03.parquet']
[2024-04-30 02:58:12,752] {subprocess.py:85} INFO - Output:
[2024-04-30 02:58:16,291] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 02:58:16,411] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210302T060000, start_date=20240430T025811, end_date=20240430T025816
[2024-04-30 02:58:16,468] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 02:58:16,661] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:01:00,346] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:00,408] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:00,409] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:00,409] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:01:00,410] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:00,478] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-03-02 06:00:00+00:00
[2024-04-30 03:01:00,507] {standard_task_runner.py:52} INFO - Started process 629 to run task
[2024-04-30 03:01:00,541] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '3125', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp3vo3xkz4', '--error-file', '/tmp/tmpw21jaa8t']
[2024-04-30 03:01:00,583] {standard_task_runner.py:77} INFO - Job 3125: Subtask download_dataset_task
[2024-04-30 03:01:00,839] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:01:01,014] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:01:01,186] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-04-30 03:01:01,192] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 03:01:01,197] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet > /opt/***/cleaned_data/yellowtaxi_tripdata_2021-03.parquet']
[2024-04-30 03:01:01,460] {subprocess.py:85} INFO - Output:
[2024-04-30 03:01:04,966] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 03:01:05,037] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210302T060000, start_date=20240430T030100, end_date=20240430T030105
[2024-04-30 03:01:05,140] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:01:05,257] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:29:56,805] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-04-30 04:29:56,866] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [queued]>
[2024-04-30 04:29:56,867] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:29:56,868] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:29:56,870] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:29:56,928] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2021-03-02 06:00:00+00:00
[2024-04-30 04:29:56,974] {standard_task_runner.py:52} INFO - Started process 5158 to run task
[2024-04-30 04:29:56,996] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2021-03-02T06:00:00+00:00', '--job-id', '3238', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpn72s2sx2', '--error-file', '/tmp/tmpyy5xdaro']
[2024-04-30 04:29:57,038] {standard_task_runner.py:77} INFO - Job 3238: Subtask download_dataset_task
[2024-04-30 04:29:57,456] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2021-03-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:29:57,692] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:29:57,835] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2021-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-02T06:00:00+00:00
[2024-04-30 04:29:57,838] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 04:29:57,846] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2021-03.parquet']
[2024-04-30 04:29:57,969] {subprocess.py:85} INFO - Output:
[2024-04-30 04:30:01,172] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 04:30:01,278] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20210302T060000, start_date=20240430T042956, end_date=20240430T043001
[2024-04-30 04:30:01,346] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 04:30:01,493] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
