[2024-03-29 08:27:20,981] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [queued]>
[2024-03-29 08:27:21,099] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [queued]>
[2024-03-29 08:27:21,105] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:27:21,106] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:27:21,112] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:27:21,223] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-04-02 06:00:00+00:00
[2024-03-29 08:27:21,267] {standard_task_runner.py:52} INFO - Started process 1563 to run task
[2024-03-29 08:27:21,371] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-04-02T06:00:00+00:00', '--job-id', '1778', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp_5r5lgm4', '--error-file', '/tmp/tmpfj81tmfq']
[2024-03-29 08:27:21,410] {standard_task_runner.py:77} INFO - Job 1778: Subtask download_dataset_task
[2024-03-29 08:27:21,664] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:27:21,792] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:27:21,851] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-04-02T06:00:00+00:00
[2024-03-29 08:27:21,856] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-29 08:27:21,861] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-04.parquet > /opt/***/yellowtaxi_tripdata_2023-04.parquet']
[2024-03-29 08:27:21,950] {subprocess.py:85} INFO - Output:
[2024-03-29 08:27:29,509] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-29 08:27:29,615] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230402T060000, start_date=20240329T082720, end_date=20240329T082729
[2024-03-29 08:27:29,773] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-29 08:27:29,887] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:53:23,931] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [queued]>
[2024-03-30 03:53:23,973] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [queued]>
[2024-03-30 03:53:23,974] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:53:23,974] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:53:23,975] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:53:24,004] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-04-02 06:00:00+00:00
[2024-03-30 03:53:24,014] {standard_task_runner.py:52} INFO - Started process 2101 to run task
[2024-03-30 03:53:24,049] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-04-02T06:00:00+00:00', '--job-id', '1988', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp_pcmklt7', '--error-file', '/tmp/tmpaz_nko9_']
[2024-03-30 03:53:24,083] {standard_task_runner.py:77} INFO - Job 1988: Subtask download_dataset_task
[2024-03-30 03:53:24,264] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:53:24,410] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:53:24,503] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-04-02T06:00:00+00:00
[2024-03-30 03:53:24,507] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 03:53:24,511] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-04.parquet > /opt/***/yellowtaxi_tripdata_2023-04.parquet']
[2024-03-30 03:53:24,610] {subprocess.py:85} INFO - Output:
[2024-03-30 03:53:31,747] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 03:53:31,962] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230402T060000, start_date=20240330T035323, end_date=20240330T035331
[2024-03-30 03:53:32,170] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 03:53:32,832] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:18:59,928] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [queued]>
[2024-03-30 04:19:00,125] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [queued]>
[2024-03-30 04:19:00,134] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:19:00,140] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:19:00,142] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:19:00,270] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-04-02 06:00:00+00:00
[2024-03-30 04:19:00,350] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-04-02T06:00:00+00:00', '--job-id', '2133', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpd3wx7qy3', '--error-file', '/tmp/tmpwrh48fi4']
[2024-03-30 04:19:00,320] {standard_task_runner.py:52} INFO - Started process 3766 to run task
[2024-03-30 04:19:00,425] {standard_task_runner.py:77} INFO - Job 2133: Subtask download_dataset_task
[2024-03-30 04:19:00,828] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:19:01,107] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:19:01,246] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-04-02T06:00:00+00:00
[2024-03-30 04:19:01,256] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:19:01,261] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-04.parquet > /opt/***/yellowtaxi_tripdata_2023-04.parquet']
[2024-03-30 04:19:01,360] {subprocess.py:85} INFO - Output:
[2024-03-30 04:19:08,480] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:19:08,603] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230402T060000, start_date=20240330T041859, end_date=20240330T041908
[2024-03-30 04:19:08,686] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:19:08,782] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:25:31,949] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [queued]>
[2024-03-30 04:25:32,007] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [queued]>
[2024-03-30 04:25:32,007] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:25:32,008] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:25:32,008] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:25:32,054] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-04-02 06:00:00+00:00
[2024-03-30 04:25:32,076] {standard_task_runner.py:52} INFO - Started process 4375 to run task
[2024-03-30 04:25:32,118] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-04-02T06:00:00+00:00', '--job-id', '2211', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp3t88bfrf', '--error-file', '/tmp/tmp7luygdor']
[2024-03-30 04:25:32,157] {standard_task_runner.py:77} INFO - Job 2211: Subtask download_dataset_task
[2024-03-30 04:25:32,433] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:25:32,561] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:25:32,637] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-04-02T06:00:00+00:00
[2024-03-30 04:25:32,639] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:25:32,640] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-04.parquet > /opt/***/yellowtaxi_tripdata_2023-04.parquet']
[2024-03-30 04:25:32,700] {subprocess.py:85} INFO - Output:
[2024-03-30 04:25:39,135] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:25:39,291] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230402T060000, start_date=20240330T042531, end_date=20240330T042539
[2024-03-30 04:25:39,508] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:25:39,834] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:44:49,868] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [queued]>
[2024-03-30 04:44:49,948] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [queued]>
[2024-03-30 04:44:49,948] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:44:49,948] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:44:49,949] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:44:50,046] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-04-02 06:00:00+00:00
[2024-03-30 04:44:50,139] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-04-02T06:00:00+00:00', '--job-id', '2355', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpud0_c1qh', '--error-file', '/tmp/tmpf_y7gwfb']
[2024-03-30 04:44:50,202] {standard_task_runner.py:77} INFO - Job 2355: Subtask download_dataset_task
[2024-03-30 04:44:50,078] {standard_task_runner.py:52} INFO - Started process 5766 to run task
[2024-03-30 04:44:50,674] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:44:51,132] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:44:51,315] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-04-02T06:00:00+00:00
[2024-03-30 04:44:51,321] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 04:44:51,324] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-04.parquet > /opt/***/yellowtaxi_tripdata_2023-04.parquet']
[2024-03-30 04:44:51,446] {subprocess.py:85} INFO - Output:
[2024-03-30 04:44:59,112] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 04:44:59,434] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230402T060000, start_date=20240330T044449, end_date=20240330T044459
[2024-03-30 04:44:59,647] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:45:00,208] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 05:00:08,900] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:08,931] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [queued]>
[2024-03-30 05:00:08,931] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:08,931] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 05:00:08,931] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 05:00:08,963] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-04-02 06:00:00+00:00
[2024-03-30 05:00:08,977] {standard_task_runner.py:52} INFO - Started process 6836 to run task
[2024-03-30 05:00:09,051] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-04-02T06:00:00+00:00', '--job-id', '2458', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp2ibatdcf', '--error-file', '/tmp/tmpxm8exage']
[2024-03-30 05:00:09,078] {standard_task_runner.py:77} INFO - Job 2458: Subtask download_dataset_task
[2024-03-30 05:00:09,355] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 05:00:09,566] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 05:00:09,628] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-04-02T06:00:00+00:00
[2024-03-30 05:00:09,633] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 05:00:09,634] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-04.parquet > /opt/***/yellowtaxi_tripdata_2023-04.parquet']
[2024-03-30 05:00:09,716] {subprocess.py:85} INFO - Output:
[2024-03-30 05:00:16,383] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 05:00:17,182] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230402T060000, start_date=20240330T050008, end_date=20240330T050017
[2024-03-30 05:00:17,386] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 05:00:17,514] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:02:20,012] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [queued]>
[2024-03-30 09:02:20,153] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [queued]>
[2024-03-30 09:02:20,153] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:02:20,153] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:02:20,153] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:02:20,275] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-04-02 06:00:00+00:00
[2024-03-30 09:02:20,311] {standard_task_runner.py:52} INFO - Started process 18347 to run task
[2024-03-30 09:02:20,356] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-04-02T06:00:00+00:00', '--job-id', '2572', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpd1hdbd1h', '--error-file', '/tmp/tmpj_r5f533']
[2024-03-30 09:02:20,392] {standard_task_runner.py:77} INFO - Job 2572: Subtask download_dataset_task
[2024-03-30 09:02:20,877] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:02:21,221] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 09:02:21,311] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-04-02T06:00:00+00:00
[2024-03-30 09:02:21,314] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 09:02:21,315] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-04.parquet > /opt/***/yellowtaxi_tripdata_2023-04.parquet']
[2024-03-30 09:02:21,379] {subprocess.py:85} INFO - Output:
[2024-03-30 09:02:27,884] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 09:02:28,652] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230402T060000, start_date=20240330T090220, end_date=20240330T090228
[2024-03-30 09:02:29,240] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:02:31,038] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 11:57:19,391] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [queued]>
[2024-03-30 11:57:19,444] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [queued]>
[2024-03-30 11:57:19,449] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:57:19,449] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 11:57:19,450] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 11:57:19,518] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-04-02 06:00:00+00:00
[2024-03-30 11:57:19,541] {standard_task_runner.py:52} INFO - Started process 28547 to run task
[2024-03-30 11:57:19,579] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-04-02T06:00:00+00:00', '--job-id', '2898', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpgfpx8lo2', '--error-file', '/tmp/tmplgr34_1a']
[2024-03-30 11:57:19,598] {standard_task_runner.py:77} INFO - Job 2898: Subtask download_dataset_task
[2024-03-30 11:57:19,855] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 11:57:20,023] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 11:57:20,115] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-04-02T06:00:00+00:00
[2024-03-30 11:57:20,116] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-03-30 11:57:20,117] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-04.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2023-04.parquet']
[2024-03-30 11:57:20,176] {subprocess.py:85} INFO - Output:
[2024-03-30 11:57:26,520] {subprocess.py:93} INFO - Command exited with return code 0
[2024-03-30 11:57:26,948] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230402T060000, start_date=20240330T115719, end_date=20240330T115726
[2024-03-30 11:57:27,086] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 11:57:27,202] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:01:51,197] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:51,300] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:51,300] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:51,300] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:01:51,300] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:51,366] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-04-02 06:00:00+00:00
[2024-04-30 03:01:51,412] {standard_task_runner.py:52} INFO - Started process 899 to run task
[2024-04-30 03:01:51,490] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-04-02T06:00:00+00:00', '--job-id', '3183', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmppckc9h2b', '--error-file', '/tmp/tmpcwg7xw3d']
[2024-04-30 03:01:51,516] {standard_task_runner.py:77} INFO - Job 3183: Subtask download_dataset_task
[2024-04-30 03:01:51,940] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:01:52,222] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 03:01:52,367] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-04-02T06:00:00+00:00
[2024-04-30 03:01:52,375] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 03:01:52,380] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-04.parquet > /opt/***/cleaned_data/yellowtaxi_tripdata_2023-04.parquet']
[2024-04-30 03:01:52,485] {subprocess.py:85} INFO - Output:
[2024-04-30 03:01:57,558] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 03:01:57,936] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230402T060000, start_date=20240430T030151, end_date=20240430T030157
[2024-04-30 03:01:58,268] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:01:58,514] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:34:36,330] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [queued]>
[2024-04-30 04:34:36,342] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [queued]>
[2024-04-30 04:34:36,342] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:34:36,342] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:34:36,342] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:34:36,352] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2023-04-02 06:00:00+00:00
[2024-04-30 04:34:36,360] {standard_task_runner.py:52} INFO - Started process 5690 to run task
[2024-04-30 04:34:36,364] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'download_dataset_task', 'scheduled__2023-04-02T06:00:00+00:00', '--job-id', '3299', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp5frcoiay', '--error-file', '/tmp/tmpwhxfurdf']
[2024-04-30 04:34:36,369] {standard_task_runner.py:77} INFO - Job 3299: Subtask download_dataset_task
[2024-04-30 04:34:36,434] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.download_dataset_task scheduled__2023-04-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:34:36,474] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-04-30 04:34:36,500] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2023-04-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-04-02T06:00:00+00:00
[2024-04-30 04:34:36,501] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-04-30 04:34:36,501] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-04.parquet > /opt/***/raw_data/yellowtaxi_tripdata_2023-04.parquet']
[2024-04-30 04:34:36,515] {subprocess.py:85} INFO - Output:
[2024-04-30 04:34:41,021] {subprocess.py:93} INFO - Command exited with return code 0
[2024-04-30 04:34:41,305] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=download_dataset_task, execution_date=20230402T060000, start_date=20240430T043436, end_date=20240430T043441
[2024-04-30 04:34:41,362] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 04:34:41,466] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
