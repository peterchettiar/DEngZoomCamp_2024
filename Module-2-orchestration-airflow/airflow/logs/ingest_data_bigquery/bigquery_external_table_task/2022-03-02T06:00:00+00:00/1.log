[2024-03-29 07:24:57,806] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:57,832] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-29 07:24:57,832] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:57,832] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:24:57,832] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:24:57,869] {taskinstance.py:1259} INFO - Executing <Task(BigQueryCreateExternalTableOperator): bigquery_external_table_task> on 2022-03-02 06:00:00+00:00
[2024-03-29 07:24:57,878] {standard_task_runner.py:52} INFO - Started process 652 to run task
[2024-03-29 07:24:57,895] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'bigquery_external_table_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '1483', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmplf2x27hs', '--error-file', '/tmp/tmpfv6zb9uo']
[2024-03-29 07:24:57,905] {standard_task_runner.py:77} INFO - Job 1483: Subtask bigquery_external_table_task
[2024-03-29 07:24:57,999] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:24:58,122] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=bigquery_external_table_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-29 07:24:58,126] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-03-29 07:24:58,814] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1196, in execute
    table_resource=self.table_resource,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/common/hooks/base_google.py", line 430, in inner_wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py", line 408, in create_empty_table
    table=table, exists_ok=exists_ok, retry=retry
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/client.py", line 755, in create_table
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/client.py", line 782, in _call_api
    return call()
  File "/home/airflow/.local/lib/python3.6/site-packages/google/api_core/retry.py", line 291, in retry_wrapped_func
    on_error=on_error,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/_http.py", line 484, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.NotFound: 404 POST https://bigquery.googleapis.com/bigquery/v2/projects/ny-rides-peter-415106/datasets/trips_data_all/tables?prettyPrint=false: Not found: Dataset ny-rides-peter-415106:trips_data_all
[2024-03-29 07:24:58,839] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=bigquery_external_table_task, execution_date=20220302T060000, start_date=20240329T072457, end_date=20240329T072458
[2024-03-29 07:24:58,856] {standard_task_runner.py:92} ERROR - Failed to execute job 1483 for task bigquery_external_table_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1196, in execute
    table_resource=self.table_resource,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/common/hooks/base_google.py", line 430, in inner_wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py", line 408, in create_empty_table
    table=table, exists_ok=exists_ok, retry=retry
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/client.py", line 755, in create_table
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/client.py", line 782, in _call_api
    return call()
  File "/home/airflow/.local/lib/python3.6/site-packages/google/api_core/retry.py", line 291, in retry_wrapped_func
    on_error=on_error,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/_http.py", line 484, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.NotFound: 404 POST https://bigquery.googleapis.com/bigquery/v2/projects/ny-rides-peter-415106/datasets/trips_data_all/tables?prettyPrint=false: Not found: Dataset ny-rides-peter-415106:trips_data_all
[2024-03-29 07:24:58,880] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-29 07:24:59,218] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:31:13,620] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-29 07:31:13,678] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-29 07:31:13,679] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:31:13,679] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:31:13,679] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:31:13,706] {taskinstance.py:1259} INFO - Executing <Task(BigQueryCreateExternalTableOperator): bigquery_external_table_task> on 2022-03-02 06:00:00+00:00
[2024-03-29 07:31:13,715] {standard_task_runner.py:52} INFO - Started process 1140 to run task
[2024-03-29 07:31:13,735] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'bigquery_external_table_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '1539', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp7ka1m8cv', '--error-file', '/tmp/tmpsfulcu6_']
[2024-03-29 07:31:13,760] {standard_task_runner.py:77} INFO - Job 1539: Subtask bigquery_external_table_task
[2024-03-29 07:31:13,931] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:31:14,105] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=bigquery_external_table_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-29 07:31:14,115] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-03-29 07:31:14,147] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1196, in execute
    table_resource=self.table_resource,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/common/hooks/base_google.py", line 430, in inner_wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py", line 404, in create_empty_table
    table_id=table_id,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py", line 172, in _resolve_table_reference
    TableReference.from_api_repr(table_resource["tableReference"])
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/table.py", line 277, in from_api_repr
    return cls(DatasetReference(project, dataset_id), table_id)
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/dataset.py", line 265, in __init__
    raise ValueError("Pass a string for dataset_id")
ValueError: Pass a string for dataset_id
[2024-03-29 07:31:14,218] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=bigquery_external_table_task, execution_date=20220302T060000, start_date=20240329T073113, end_date=20240329T073114
[2024-03-29 07:31:14,260] {standard_task_runner.py:92} ERROR - Failed to execute job 1539 for task bigquery_external_table_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1196, in execute
    table_resource=self.table_resource,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/common/hooks/base_google.py", line 430, in inner_wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py", line 404, in create_empty_table
    table_id=table_id,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py", line 172, in _resolve_table_reference
    TableReference.from_api_repr(table_resource["tableReference"])
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/table.py", line 277, in from_api_repr
    return cls(DatasetReference(project, dataset_id), table_id)
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/dataset.py", line 265, in __init__
    raise ValueError("Pass a string for dataset_id")
ValueError: Pass a string for dataset_id
[2024-03-29 07:31:14,300] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-29 07:31:14,374] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-29 07:37:56,297] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:56,353] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-29 07:37:56,354] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:56,354] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 07:37:56,355] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 07:37:56,386] {taskinstance.py:1259} INFO - Executing <Task(BigQueryCreateExternalTableOperator): bigquery_external_table_task> on 2022-03-02 06:00:00+00:00
[2024-03-29 07:37:56,396] {standard_task_runner.py:52} INFO - Started process 1664 to run task
[2024-03-29 07:37:56,462] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'bigquery_external_table_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '1600', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpr5mnilnr', '--error-file', '/tmp/tmp8u857177']
[2024-03-29 07:37:56,544] {standard_task_runner.py:77} INFO - Job 1600: Subtask bigquery_external_table_task
[2024-03-29 07:37:56,717] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host b8c510ab3cfc
[2024-03-29 07:37:56,846] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=bigquery_external_table_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-29 07:37:56,851] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-03-29 07:37:57,285] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1196, in execute
    table_resource=self.table_resource,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/common/hooks/base_google.py", line 430, in inner_wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py", line 408, in create_empty_table
    table=table, exists_ok=exists_ok, retry=retry
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/client.py", line 755, in create_table
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/client.py", line 782, in _call_api
    return call()
  File "/home/airflow/.local/lib/python3.6/site-packages/google/api_core/retry.py", line 291, in retry_wrapped_func
    on_error=on_error,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/_http.py", line 484, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/bigquery/v2/projects/ny-rides-peter-415106/datasets/test_dataset/tables?prettyPrint=false: Error while reading table: external_table, error message: Failed to expand table external_table with file pattern gs://test_bucket_415106/yellowtaxi_tripdata/{ execution_date.strftime('%Y-%m') }.parquet: matched no files. File: gs://test_bucket_415106/yellowtaxi_tripdata/{ execution_date.strftime('%Y-%m') }.parquet
[2024-03-29 07:37:57,337] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=bigquery_external_table_task, execution_date=20220302T060000, start_date=20240329T073756, end_date=20240329T073757
[2024-03-29 07:37:57,412] {standard_task_runner.py:92} ERROR - Failed to execute job 1600 for task bigquery_external_table_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1196, in execute
    table_resource=self.table_resource,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/common/hooks/base_google.py", line 430, in inner_wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py", line 408, in create_empty_table
    table=table, exists_ok=exists_ok, retry=retry
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/client.py", line 755, in create_table
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/client.py", line 782, in _call_api
    return call()
  File "/home/airflow/.local/lib/python3.6/site-packages/google/api_core/retry.py", line 291, in retry_wrapped_func
    on_error=on_error,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/_http.py", line 484, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/bigquery/v2/projects/ny-rides-peter-415106/datasets/test_dataset/tables?prettyPrint=false: Error while reading table: external_table, error message: Failed to expand table external_table with file pattern gs://test_bucket_415106/yellowtaxi_tripdata/{ execution_date.strftime('%Y-%m') }.parquet: matched no files. File: gs://test_bucket_415106/yellowtaxi_tripdata/{ execution_date.strftime('%Y-%m') }.parquet
[2024-03-29 07:37:57,470] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-29 07:37:57,927] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-29 08:11:29,382] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-29 08:11:29,417] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-29 08:11:29,417] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:11:29,417] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-29 08:11:29,417] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-29 08:11:29,448] {taskinstance.py:1259} INFO - Executing <Task(BigQueryCreateExternalTableOperator): bigquery_external_table_task> on 2022-03-02 06:00:00+00:00
[2024-03-29 08:11:29,466] {standard_task_runner.py:52} INFO - Started process 643 to run task
[2024-03-29 08:11:29,503] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'bigquery_external_table_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '1714', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmps4mf43w_', '--error-file', '/tmp/tmp0ss2umjr']
[2024-03-29 08:11:29,510] {standard_task_runner.py:77} INFO - Job 1714: Subtask bigquery_external_table_task
[2024-03-29 08:11:29,699] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host b5e5a5778b83
[2024-03-29 08:11:29,830] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-29 08:11:29,967] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=bigquery_external_table_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-29 08:11:29,969] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-03-29 08:11:29,995] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/providers/google/cloud/hooks/bigquery.py:637: DeprecationWarning: This method is deprecated. Please use `BigQueryHook.create_empty_table` method with passing the `table_resource` object. This gives more flexibility than this method.
  DeprecationWarning,

[2024-03-29 08:11:30,013] {bigquery.py:700} INFO - Creating external table: test_dataset.external_table
[2024-03-29 08:11:30,257] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1226, in execute
    encryption_configuration=self.encryption_configuration,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/common/hooks/base_google.py", line 430, in inner_wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py", line 702, in create_external_table
    table_resource=table.to_api_repr(), project_id=project_id, location=location, exists_ok=True
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/common/hooks/base_google.py", line 430, in inner_wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py", line 408, in create_empty_table
    table=table, exists_ok=exists_ok, retry=retry
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/client.py", line 755, in create_table
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/client.py", line 782, in _call_api
    return call()
  File "/home/airflow/.local/lib/python3.6/site-packages/google/api_core/retry.py", line 291, in retry_wrapped_func
    on_error=on_error,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/_http.py", line 484, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/bigquery/v2/projects/ny-rides-peter-415106/datasets/test_dataset/tables?prettyPrint=false: When defining a table with an ExternalDataConfiguration, a schema must be present on either the Table or the ExternalDataConfiguration. If the schema is present on both, the schemas must be the same.
[2024-03-29 08:11:30,302] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=bigquery_external_table_task, execution_date=20220302T060000, start_date=20240329T081129, end_date=20240329T081130
[2024-03-29 08:11:30,345] {standard_task_runner.py:92} ERROR - Failed to execute job 1714 for task bigquery_external_table_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1226, in execute
    encryption_configuration=self.encryption_configuration,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/common/hooks/base_google.py", line 430, in inner_wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py", line 702, in create_external_table
    table_resource=table.to_api_repr(), project_id=project_id, location=location, exists_ok=True
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/common/hooks/base_google.py", line 430, in inner_wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py", line 408, in create_empty_table
    table=table, exists_ok=exists_ok, retry=retry
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/client.py", line 755, in create_table
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/client.py", line 782, in _call_api
    return call()
  File "/home/airflow/.local/lib/python3.6/site-packages/google/api_core/retry.py", line 291, in retry_wrapped_func
    on_error=on_error,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/_http.py", line 484, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/bigquery/v2/projects/ny-rides-peter-415106/datasets/test_dataset/tables?prettyPrint=false: When defining a table with an ExternalDataConfiguration, a schema must be present on either the Table or the ExternalDataConfiguration. If the schema is present on both, the schemas must be the same.
[2024-03-29 08:11:30,396] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-29 08:11:30,440] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:30:34,048] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:34,149] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 03:30:34,150] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:34,150] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:30:34,150] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:30:34,246] {taskinstance.py:1259} INFO - Executing <Task(BigQueryCreateExternalTableOperator): bigquery_external_table_task> on 2022-03-02 06:00:00+00:00
[2024-03-30 03:30:34,260] {standard_task_runner.py:52} INFO - Started process 590 to run task
[2024-03-30 03:30:34,301] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'bigquery_external_table_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '1857', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp13r81dl3', '--error-file', '/tmp/tmpv7gkcbub']
[2024-03-30 03:30:34,313] {standard_task_runner.py:77} INFO - Job 1857: Subtask bigquery_external_table_task
[2024-03-30 03:30:34,543] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:30:34,663] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:30:34,751] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=bigquery_external_table_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-30 03:30:34,752] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-03-30 03:30:34,771] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/providers/google/cloud/hooks/bigquery.py:637: DeprecationWarning: This method is deprecated. Please use `BigQueryHook.create_empty_table` method with passing the `table_resource` object. This gives more flexibility than this method.
  DeprecationWarning,

[2024-03-30 03:30:34,779] {bigquery.py:700} INFO - Creating external table: test_dataset.external_table
[2024-03-30 03:30:35,060] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1226, in execute
    encryption_configuration=self.encryption_configuration,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/common/hooks/base_google.py", line 430, in inner_wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py", line 702, in create_external_table
    table_resource=table.to_api_repr(), project_id=project_id, location=location, exists_ok=True
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/common/hooks/base_google.py", line 430, in inner_wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py", line 408, in create_empty_table
    table=table, exists_ok=exists_ok, retry=retry
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/client.py", line 755, in create_table
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/client.py", line 782, in _call_api
    return call()
  File "/home/airflow/.local/lib/python3.6/site-packages/google/api_core/retry.py", line 291, in retry_wrapped_func
    on_error=on_error,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/_http.py", line 484, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/bigquery/v2/projects/ny-rides-peter-415106/datasets/test_dataset/tables?prettyPrint=false: When defining a table with an ExternalDataConfiguration, a schema must be present on either the Table or the ExternalDataConfiguration. If the schema is present on both, the schemas must be the same.
[2024-03-30 03:30:35,121] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=bigquery_external_table_task, execution_date=20220302T060000, start_date=20240330T033034, end_date=20240330T033035
[2024-03-30 03:30:35,182] {standard_task_runner.py:92} ERROR - Failed to execute job 1857 for task bigquery_external_table_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1226, in execute
    encryption_configuration=self.encryption_configuration,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/common/hooks/base_google.py", line 430, in inner_wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py", line 702, in create_external_table
    table_resource=table.to_api_repr(), project_id=project_id, location=location, exists_ok=True
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/common/hooks/base_google.py", line 430, in inner_wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py", line 408, in create_empty_table
    table=table, exists_ok=exists_ok, retry=retry
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/client.py", line 755, in create_table
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/client.py", line 782, in _call_api
    return call()
  File "/home/airflow/.local/lib/python3.6/site-packages/google/api_core/retry.py", line 291, in retry_wrapped_func
    on_error=on_error,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/_http.py", line 484, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/bigquery/v2/projects/ny-rides-peter-415106/datasets/test_dataset/tables?prettyPrint=false: When defining a table with an ExternalDataConfiguration, a schema must be present on either the Table or the ExternalDataConfiguration. If the schema is present on both, the schemas must be the same.
[2024-03-30 03:30:35,235] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 03:30:35,425] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 03:42:27,061] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 03:42:27,078] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 03:42:27,079] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:42:27,079] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 03:42:27,079] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 03:42:27,484] {taskinstance.py:1259} INFO - Executing <Task(BigQueryCreateExternalTableOperator): bigquery_external_table_task> on 2022-03-02 06:00:00+00:00
[2024-03-30 03:42:27,691] {standard_task_runner.py:52} INFO - Started process 1412 to run task
[2024-03-30 03:42:27,709] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'bigquery_external_table_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '1934', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpdwh9wesn', '--error-file', '/tmp/tmpgjaq51tr']
[2024-03-30 03:42:27,721] {standard_task_runner.py:77} INFO - Job 1934: Subtask bigquery_external_table_task
[2024-03-30 03:42:28,447] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 03:42:28,547] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 03:42:28,619] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=bigquery_external_table_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-30 03:42:28,621] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-03-30 03:42:28,635] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/providers/google/cloud/hooks/bigquery.py:637: DeprecationWarning: This method is deprecated. Please use `BigQueryHook.create_empty_table` method with passing the `table_resource` object. This gives more flexibility than this method.
  DeprecationWarning,

[2024-03-30 03:42:28,648] {bigquery.py:700} INFO - Creating external table: test_dataset.external_table
[2024-03-30 03:42:28,777] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1226, in execute
    encryption_configuration=self.encryption_configuration,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/common/hooks/base_google.py", line 430, in inner_wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py", line 702, in create_external_table
    table_resource=table.to_api_repr(), project_id=project_id, location=location, exists_ok=True
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/common/hooks/base_google.py", line 430, in inner_wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py", line 408, in create_empty_table
    table=table, exists_ok=exists_ok, retry=retry
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/client.py", line 755, in create_table
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/client.py", line 782, in _call_api
    return call()
  File "/home/airflow/.local/lib/python3.6/site-packages/google/api_core/retry.py", line 291, in retry_wrapped_func
    on_error=on_error,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/_http.py", line 484, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/bigquery/v2/projects/ny-rides-peter-415106/datasets/test_dataset/tables?prettyPrint=false: Invalid value for type: NUMBER is not a valid value
[2024-03-30 03:42:28,804] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=bigquery_external_table_task, execution_date=20220302T060000, start_date=20240330T034227, end_date=20240330T034228
[2024-03-30 03:42:28,823] {standard_task_runner.py:92} ERROR - Failed to execute job 1934 for task bigquery_external_table_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1226, in execute
    encryption_configuration=self.encryption_configuration,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/common/hooks/base_google.py", line 430, in inner_wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py", line 702, in create_external_table
    table_resource=table.to_api_repr(), project_id=project_id, location=location, exists_ok=True
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/common/hooks/base_google.py", line 430, in inner_wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py", line 408, in create_empty_table
    table=table, exists_ok=exists_ok, retry=retry
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/client.py", line 755, in create_table
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/client.py", line 782, in _call_api
    return call()
  File "/home/airflow/.local/lib/python3.6/site-packages/google/api_core/retry.py", line 291, in retry_wrapped_func
    on_error=on_error,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/_http.py", line 484, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/bigquery/v2/projects/ny-rides-peter-415106/datasets/test_dataset/tables?prettyPrint=false: Invalid value for type: NUMBER is not a valid value
[2024-03-30 03:42:28,842] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 03:42:28,913] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:18:38,596] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:38,640] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:18:38,641] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:38,642] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:18:38,642] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:18:38,680] {taskinstance.py:1259} INFO - Executing <Task(BigQueryCreateExternalTableOperator): bigquery_external_table_task> on 2022-03-02 06:00:00+00:00
[2024-03-30 04:18:38,707] {standard_task_runner.py:52} INFO - Started process 3667 to run task
[2024-03-30 04:18:38,729] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'bigquery_external_table_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '2117', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpi031coaf', '--error-file', '/tmp/tmp3v9pfwf8']
[2024-03-30 04:18:38,769] {standard_task_runner.py:77} INFO - Job 2117: Subtask bigquery_external_table_task
[2024-03-30 04:18:39,171] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:18:39,313] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:18:39,426] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=bigquery_external_table_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-30 04:18:39,434] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-03-30 04:18:39,469] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/providers/google/cloud/hooks/bigquery.py:637: DeprecationWarning: This method is deprecated. Please use `BigQueryHook.create_empty_table` method with passing the `table_resource` object. This gives more flexibility than this method.
  DeprecationWarning,

[2024-03-30 04:18:39,470] {bigquery.py:700} INFO - Creating external table: test_dataset.yellowtaxi_trips
[2024-03-30 04:18:39,944] {bigquery.py:704} INFO - External table created successfully: test_dataset.yellowtaxi_trips
[2024-03-30 04:18:39,974] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=bigquery_external_table_task, execution_date=20220302T060000, start_date=20240330T041838, end_date=20240330T041839
[2024-03-30 04:18:40,058] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:18:40,173] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:25:10,799] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:25:10,865] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:25:10,866] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:25:10,867] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:25:10,868] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:25:10,986] {taskinstance.py:1259} INFO - Executing <Task(BigQueryCreateExternalTableOperator): bigquery_external_table_task> on 2022-03-02 06:00:00+00:00
[2024-03-30 04:25:11,057] {standard_task_runner.py:52} INFO - Started process 4288 to run task
[2024-03-30 04:25:11,077] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'bigquery_external_table_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '2200', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp3bze86ze', '--error-file', '/tmp/tmptti1y_lo']
[2024-03-30 04:25:11,106] {standard_task_runner.py:77} INFO - Job 2200: Subtask bigquery_external_table_task
[2024-03-30 04:25:11,780] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:25:12,144] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:25:12,314] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=bigquery_external_table_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-30 04:25:12,397] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-03-30 04:25:12,410] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/providers/google/cloud/hooks/bigquery.py:637: DeprecationWarning: This method is deprecated. Please use `BigQueryHook.create_empty_table` method with passing the `table_resource` object. This gives more flexibility than this method.
  DeprecationWarning,

[2024-03-30 04:25:12,412] {bigquery.py:700} INFO - Creating external table: test_dataset.yellowtaxi_trips
[2024-03-30 04:25:12,799] {bigquery.py:704} INFO - External table created successfully: test_dataset.yellowtaxi_trips
[2024-03-30 04:25:12,828] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=bigquery_external_table_task, execution_date=20220302T060000, start_date=20240330T042510, end_date=20240330T042512
[2024-03-30 04:25:12,873] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:25:12,925] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:39:26,131] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:39:26,224] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:39:26,224] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:39:26,224] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:39:26,224] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:39:26,327] {taskinstance.py:1259} INFO - Executing <Task(BigQueryCreateExternalTableOperator): bigquery_external_table_task> on 2022-03-02 06:00:00+00:00
[2024-03-30 04:39:26,411] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'bigquery_external_table_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '2308', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp_nzspuk9', '--error-file', '/tmp/tmppl7vszea']
[2024-03-30 04:39:26,377] {standard_task_runner.py:52} INFO - Started process 5346 to run task
[2024-03-30 04:39:26,449] {standard_task_runner.py:77} INFO - Job 2308: Subtask bigquery_external_table_task
[2024-03-30 04:39:26,777] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:39:27,123] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=bigquery_external_table_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-30 04:39:27,140] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-03-30 04:39:27,708] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1196, in execute
    table_resource=self.table_resource,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/common/hooks/base_google.py", line 430, in inner_wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py", line 408, in create_empty_table
    table=table, exists_ok=exists_ok, retry=retry
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/client.py", line 755, in create_table
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/client.py", line 782, in _call_api
    return call()
  File "/home/airflow/.local/lib/python3.6/site-packages/google/api_core/retry.py", line 291, in retry_wrapped_func
    on_error=on_error,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/_http.py", line 484, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/bigquery/v2/projects/ny-rides-peter-415106/datasets/test_dataset/tables?prettyPrint=false: Error while reading table: yellowtaxi_trips, error message: Failed to expand table yellowtaxi_trips with file pattern gs://test_bucket_415106/yellowtaxi_tripdata/{ execution_date.strftime('%Y-%m') }.parquet: matched no files. File: gs://test_bucket_415106/yellowtaxi_tripdata/{ execution_date.strftime('%Y-%m') }.parquet
[2024-03-30 04:39:27,763] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=ingest_data_bigquery, task_id=bigquery_external_table_task, execution_date=20220302T060000, start_date=20240330T043926, end_date=20240330T043927
[2024-03-30 04:39:27,815] {standard_task_runner.py:92} ERROR - Failed to execute job 2308 for task bigquery_external_table_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1196, in execute
    table_resource=self.table_resource,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/common/hooks/base_google.py", line 430, in inner_wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py", line 408, in create_empty_table
    table=table, exists_ok=exists_ok, retry=retry
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/client.py", line 755, in create_table
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/bigquery/client.py", line 782, in _call_api
    return call()
  File "/home/airflow/.local/lib/python3.6/site-packages/google/api_core/retry.py", line 291, in retry_wrapped_func
    on_error=on_error,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/_http.py", line 484, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/bigquery/v2/projects/ny-rides-peter-415106/datasets/test_dataset/tables?prettyPrint=false: Error while reading table: yellowtaxi_trips, error message: Failed to expand table yellowtaxi_trips with file pattern gs://test_bucket_415106/yellowtaxi_tripdata/{ execution_date.strftime('%Y-%m') }.parquet: matched no files. File: gs://test_bucket_415106/yellowtaxi_tripdata/{ execution_date.strftime('%Y-%m') }.parquet
[2024-03-30 04:39:27,880] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-30 04:39:28,011] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 04:59:55,662] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:55,680] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 04:59:55,681] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:55,681] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 04:59:55,682] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 04:59:55,703] {taskinstance.py:1259} INFO - Executing <Task(BigQueryCreateExternalTableOperator): bigquery_external_table_task> on 2022-03-02 06:00:00+00:00
[2024-03-30 04:59:55,716] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'bigquery_external_table_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '2445', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpj8narc2h', '--error-file', '/tmp/tmp7ejmm6_8']
[2024-03-30 04:59:55,723] {standard_task_runner.py:77} INFO - Job 2445: Subtask bigquery_external_table_task
[2024-03-30 04:59:55,710] {standard_task_runner.py:52} INFO - Started process 6751 to run task
[2024-03-30 04:59:55,797] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 04:59:55,843] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-03-30 04:59:55,873] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=bigquery_external_table_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-30 04:59:55,875] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-03-30 04:59:55,887] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/providers/google/cloud/hooks/bigquery.py:637: DeprecationWarning: This method is deprecated. Please use `BigQueryHook.create_empty_table` method with passing the `table_resource` object. This gives more flexibility than this method.
  DeprecationWarning,

[2024-03-30 04:59:55,888] {bigquery.py:700} INFO - Creating external table: test_dataset.yellowtaxi_trips
[2024-03-30 04:59:56,225] {bigquery.py:704} INFO - External table created successfully: test_dataset.yellowtaxi_trips
[2024-03-30 04:59:56,237] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=bigquery_external_table_task, execution_date=20220302T060000, start_date=20240330T045955, end_date=20240330T045956
[2024-03-30 04:59:56,261] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 04:59:56,300] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-30 09:01:59,805] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:59,857] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-03-30 09:01:59,858] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:59,858] {taskinstance.py:1239} INFO - Starting attempt 1 of 4
[2024-03-30 09:01:59,858] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-30 09:01:59,909] {taskinstance.py:1259} INFO - Executing <Task(BigQueryCreateExternalTableOperator): bigquery_external_table_task> on 2022-03-02 06:00:00+00:00
[2024-03-30 09:01:59,937] {standard_task_runner.py:52} INFO - Started process 18260 to run task
[2024-03-30 09:01:59,977] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'bigquery_external_table_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '2560', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpv4u4nrn5', '--error-file', '/tmp/tmp6484cg_m']
[2024-03-30 09:01:59,996] {standard_task_runner.py:77} INFO - Job 2560: Subtask bigquery_external_table_task
[2024-03-30 09:02:00,231] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host 98c5b3fde4c4
[2024-03-30 09:02:00,403] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=bigquery_external_table_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-03-30 09:02:00,412] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-03-30 09:02:00,430] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/providers/google/cloud/hooks/bigquery.py:637: DeprecationWarning: This method is deprecated. Please use `BigQueryHook.create_empty_table` method with passing the `table_resource` object. This gives more flexibility than this method.
  DeprecationWarning,

[2024-03-30 09:02:00,431] {bigquery.py:700} INFO - Creating external table: test_dataset.yellowtaxi_trips
[2024-03-30 09:02:00,925] {bigquery.py:704} INFO - External table created successfully: test_dataset.yellowtaxi_trips
[2024-03-30 09:02:00,940] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=bigquery_external_table_task, execution_date=20220302T060000, start_date=20240330T090159, end_date=20240330T090200
[2024-03-30 09:02:01,003] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-03-30 09:02:01,089] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-04-30 03:01:32,183] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:32,260] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-04-30 03:01:32,261] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:32,261] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 03:01:32,261] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 03:01:32,314] {taskinstance.py:1259} INFO - Executing <Task(BigQueryCreateExternalTableOperator): bigquery_external_table_task> on 2022-03-02 06:00:00+00:00
[2024-04-30 03:01:32,323] {standard_task_runner.py:52} INFO - Started process 794 to run task
[2024-04-30 03:01:32,346] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'bigquery_external_table_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '3168', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp7ic10tq2', '--error-file', '/tmp/tmpktecgmre']
[2024-04-30 03:01:32,373] {standard_task_runner.py:77} INFO - Job 3168: Subtask bigquery_external_table_task
[2024-04-30 03:01:32,558] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 03:01:32,754] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=bigquery_external_table_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-04-30 03:01:32,760] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-04-30 03:01:32,773] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/providers/google/cloud/hooks/bigquery.py:637: DeprecationWarning: This method is deprecated. Please use `BigQueryHook.create_empty_table` method with passing the `table_resource` object. This gives more flexibility than this method.
  DeprecationWarning,

[2024-04-30 03:01:32,778] {bigquery.py:700} INFO - Creating external table: test_dataset.yellowtaxi_trips
[2024-04-30 03:01:33,173] {bigquery.py:704} INFO - External table created successfully: test_dataset.yellowtaxi_trips
[2024-04-30 03:01:33,193] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=bigquery_external_table_task, execution_date=20220302T060000, start_date=20240430T030132, end_date=20240430T030133
[2024-04-30 03:01:33,249] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 03:01:33,428] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-04-30 04:36:18,874] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-04-30 04:36:18,894] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [queued]>
[2024-04-30 04:36:18,895] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:36:18,895] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-04-30 04:36:18,895] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-04-30 04:36:18,910] {taskinstance.py:1259} INFO - Executing <Task(BigQueryCreateExternalTableOperator): bigquery_external_table_task> on 2022-03-02 06:00:00+00:00
[2024-04-30 04:36:18,918] {standard_task_runner.py:52} INFO - Started process 6026 to run task
[2024-04-30 04:36:18,924] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ingest_data_bigquery', 'bigquery_external_table_task', 'scheduled__2022-03-02T06:00:00+00:00', '--job-id', '3339', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpkb1zygqz', '--error-file', '/tmp/tmprrsqp71u']
[2024-04-30 04:36:18,931] {standard_task_runner.py:77} INFO - Job 3339: Subtask bigquery_external_table_task
[2024-04-30 04:36:18,945] {cli_action_loggers.py:105} WARNING - Failed to log action with (psycopg2.errors.DiskFull) could not extend file "base/16384/16445": No space left on device
HINT:  Check free disk space.

[SQL: INSERT INTO log (dttm, dag_id, task_id, event, execution_date, owner, extra) VALUES (%(dttm)s, %(dag_id)s, %(task_id)s, %(event)s, %(execution_date)s, %(owner)s, %(extra)s) RETURNING log.id]
[parameters: {'dttm': datetime.datetime(2024, 4, 30, 4, 36, 18, 932804, tzinfo=Timezone('UTC')), 'dag_id': 'ingest_data_bigquery', 'task_id': 'bigquery_external_table_task', 'event': 'cli_task_run', 'execution_date': None, 'owner': 'default', 'extra': '{"host_name": "02dc49e0e362", "full_command": "[\'/home/airflow/.local/bin/airflow\', \'celery\', \'worker\']"}'}]
(Background on this error at: http://sqlalche.me/e/13/e3q8)
[2024-04-30 04:36:19,010] {logging_mixin.py:109} INFO - Running <TaskInstance: ingest_data_bigquery.bigquery_external_table_task scheduled__2022-03-02T06:00:00+00:00 [running]> on host 02dc49e0e362
[2024-04-30 04:36:19,086] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ingest_data_bigquery
AIRFLOW_CTX_TASK_ID=bigquery_external_table_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-02T06:00:00+00:00
[2024-04-30 04:36:19,092] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-04-30 04:36:19,105] {warnings.py:99} WARNING - /home/***/.local/lib/python3.6/site-packages/***/providers/google/cloud/hooks/bigquery.py:637: DeprecationWarning: This method is deprecated. Please use `BigQueryHook.create_empty_table` method with passing the `table_resource` object. This gives more flexibility than this method.
  DeprecationWarning,

[2024-04-30 04:36:19,107] {bigquery.py:700} INFO - Creating external table: test_dataset.yellowtaxi_trips
[2024-04-30 04:36:19,417] {bigquery.py:704} INFO - External table created successfully: test_dataset.yellowtaxi_trips
[2024-04-30 04:36:19,448] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ingest_data_bigquery, task_id=bigquery_external_table_task, execution_date=20220302T060000, start_date=20240430T043618, end_date=20240430T043619
[2024-04-30 04:36:19,507] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-04-30 04:36:19,551] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
